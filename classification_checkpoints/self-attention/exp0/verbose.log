Command line
python /Users/anastasiakuznecova/PycharmProjects/chemprop-master/Testing Chemprop for project.py
Args
{'activation': 'ReLU',
 'adding_h': False,
 'aggregation': 'self_attention',
 'aggregation_norm': 100,
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_feature_scaling': True,
 'bond_features_path': None,
 'bond_features_size': 0,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': 'tests/data/Halicin_train.csv',
 'data_weights_path': None,
 'dataset_type': 'classification',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 10,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': ['accuracy'],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 3,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'loss_function': 'binary_cross_entropy',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'auc',
 'metrics': ['auc', 'accuracy'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_atom_descriptor_scaling': False,
 'no_bond_features_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 3,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': 'classification_checkpoints/self-attention/exp0',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 42,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_features_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_features_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'show_individual_scores': False,
 'smiles_columns': ['Smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['Active'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Could not write the reproducibility section of the arguments to file, thus omitting this section.
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 42
Total scaffolds = 1,035 | train scaffolds = 760 | val scaffolds = 135 | test scaffolds = 140
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 250 | target average = 0.032000


Scaffold 1
Task 0: count = 191 | target average = 0.010471


Scaffold 2
Task 0: count = 43 | target average = 0.000000


Scaffold 3
Task 0: count = 21 | target average = 0.000000


Scaffold 4
Task 0: count = 19 | target average = 0.000000


Scaffold 5
Task 0: count = 18 | target average = 0.000000


Scaffold 6
Task 0: count = 16 | target average = 0.250000


Scaffold 7
Task 0: count = 14 | target average = 0.000000


Scaffold 8
Task 0: count = 13 | target average = 0.076923


Scaffold 9
Task 0: count = 12 | target average = 0.000000


Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Epoch 0
Loss = 4.3209e-01, PNorm = 38.1783, GNorm = 0.3443, lr_0 = 2.5000e-04
Loss = 2.3257e-01, PNorm = 38.1879, GNorm = 0.2249, lr_0 = 3.8636e-04
Loss = 2.1680e-01, PNorm = 38.1985, GNorm = 0.7962, lr_0 = 5.2273e-04
Validation auc = 0.618508
Validation accuracy = 0.938095
Epoch 1
Loss = 1.7510e-01, PNorm = 38.2157, GNorm = 0.6370, lr_0 = 6.7273e-04
Loss = 1.7294e-01, PNorm = 38.2310, GNorm = 0.7433, lr_0 = 8.0909e-04
Loss = 1.9920e-01, PNorm = 38.2532, GNorm = 0.7487, lr_0 = 9.4545e-04
Validation auc = 0.683327
Validation accuracy = 0.938095
Epoch 2
Loss = 1.3061e-01, PNorm = 38.2862, GNorm = 0.1623, lr_0 = 9.4901e-04
Loss = 1.5807e-01, PNorm = 38.3022, GNorm = 0.3944, lr_0 = 8.6975e-04
Loss = 2.3720e-01, PNorm = 38.3298, GNorm = 0.3160, lr_0 = 7.9710e-04
Loss = 1.3487e-01, PNorm = 38.3639, GNorm = 0.4358, lr_0 = 7.3053e-04
Loss = 3.2231e-02, PNorm = 38.3674, GNorm = 0.6006, lr_0 = 7.2418e-04
Validation auc = 0.534947
Validation accuracy = 0.938095
Epoch 3
Loss = 1.4147e-01, PNorm = 38.4031, GNorm = 0.2270, lr_0 = 6.6370e-04
Loss = 1.6776e-01, PNorm = 38.4316, GNorm = 0.4833, lr_0 = 6.0826e-04
Loss = 1.5547e-01, PNorm = 38.4473, GNorm = 0.6634, lr_0 = 5.5746e-04
Validation auc = 0.669660
Validation accuracy = 0.938095
Epoch 4
Loss = 1.5720e-01, PNorm = 38.4679, GNorm = 0.1458, lr_0 = 5.1090e-04
Loss = 1.4969e-01, PNorm = 38.4946, GNorm = 0.1960, lr_0 = 4.6822e-04
Loss = 1.5005e-01, PNorm = 38.5209, GNorm = 0.4358, lr_0 = 4.2912e-04
Validation auc = 0.677860
Validation accuracy = 0.928571
Epoch 5
Loss = 1.0190e-01, PNorm = 38.5398, GNorm = 0.2663, lr_0 = 3.9328e-04
Loss = 1.1886e-01, PNorm = 38.5531, GNorm = 0.6629, lr_0 = 3.6043e-04
Loss = 1.1569e-01, PNorm = 38.5743, GNorm = 0.2875, lr_0 = 3.3032e-04
Loss = 1.8244e-01, PNorm = 38.5894, GNorm = 0.4430, lr_0 = 3.0273e-04
Validation auc = 0.673175
Validation accuracy = 0.938095
Epoch 6
Loss = 1.6967e-01, PNorm = 38.5980, GNorm = 0.9189, lr_0 = 2.7504e-04
Loss = 1.1494e-01, PNorm = 38.6173, GNorm = 1.0876, lr_0 = 2.5207e-04
Loss = 1.2542e-01, PNorm = 38.6326, GNorm = 0.6340, lr_0 = 2.3101e-04
Validation auc = 0.584537
Validation accuracy = 0.938095
Epoch 7
Loss = 1.0629e-01, PNorm = 38.6451, GNorm = 0.4438, lr_0 = 2.1172e-04
Loss = 1.1340e-01, PNorm = 38.6537, GNorm = 0.6494, lr_0 = 1.9403e-04
Loss = 1.0271e-01, PNorm = 38.6620, GNorm = 0.4651, lr_0 = 1.7783e-04
Validation auc = 0.616947
Validation accuracy = 0.942857
Epoch 8
Loss = 1.2141e-01, PNorm = 38.6691, GNorm = 0.7130, lr_0 = 1.6156e-04
Loss = 1.1327e-01, PNorm = 38.6752, GNorm = 0.6962, lr_0 = 1.4807e-04
Loss = 1.2604e-01, PNorm = 38.6844, GNorm = 1.4928, lr_0 = 1.3570e-04
Loss = 1.1414e-01, PNorm = 38.6905, GNorm = 0.3114, lr_0 = 1.2436e-04
Validation auc = 0.648575
Validation accuracy = 0.933333
Epoch 9
Loss = 1.4752e-01, PNorm = 38.6952, GNorm = 0.3460, lr_0 = 1.1398e-04
Loss = 1.2390e-01, PNorm = 38.6997, GNorm = 1.0315, lr_0 = 1.0446e-04
Loss = 9.2784e-02, PNorm = 38.7063, GNorm = 0.2625, lr_0 = 1.0000e-04
Validation auc = 0.672784
Validation accuracy = 0.933333
Model 0 best validation auc = 0.683327 on epoch 1
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Model 0 test auc = 0.810884
Model 0 test accuracy = 0.928910
Ensemble test auc = 0.810884
Ensemble test accuracy = 0.928910
Fold 1
Splitting data with seed 43
Total scaffolds = 1,035 | train scaffolds = 747 | val scaffolds = 134 | test scaffolds = 154
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 250 | target average = 0.032000


Scaffold 1
Task 0: count = 191 | target average = 0.010471


Scaffold 2
Task 0: count = 43 | target average = 0.000000


Scaffold 3
Task 0: count = 21 | target average = 0.000000


Scaffold 4
Task 0: count = 19 | target average = 0.000000


Scaffold 5
Task 0: count = 18 | target average = 0.000000


Scaffold 6
Task 0: count = 16 | target average = 0.250000


Scaffold 7
Task 0: count = 14 | target average = 0.000000


Scaffold 8
Task 0: count = 13 | target average = 0.076923


Scaffold 9
Task 0: count = 12 | target average = 0.000000


Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Epoch 0
Loss = 4.3523e-01, PNorm = 38.1785, GNorm = 0.5450, lr_0 = 2.5000e-04
Loss = 2.0186e-01, PNorm = 38.1905, GNorm = 2.1942, lr_0 = 3.8636e-04
Loss = 2.1699e-01, PNorm = 38.1926, GNorm = 1.0000, lr_0 = 5.2273e-04
Validation auc = 0.444444
Validation accuracy = 0.885714
Epoch 1
Loss = 1.6795e-01, PNorm = 38.2140, GNorm = 0.3798, lr_0 = 6.7273e-04
Loss = 2.1892e-01, PNorm = 38.2233, GNorm = 0.5038, lr_0 = 8.0909e-04
Loss = 1.5533e-01, PNorm = 38.2513, GNorm = 0.3217, lr_0 = 9.4545e-04
Validation auc = 0.752688
Validation accuracy = 0.885714
Epoch 2
Loss = 1.3423e-01, PNorm = 38.2696, GNorm = 0.2096, lr_0 = 9.4901e-04
Loss = 1.6714e-01, PNorm = 38.2937, GNorm = 0.2660, lr_0 = 8.6975e-04
Loss = 2.1052e-01, PNorm = 38.3199, GNorm = 0.2726, lr_0 = 7.9710e-04
Loss = 1.6683e-01, PNorm = 38.3417, GNorm = 0.2553, lr_0 = 7.3053e-04
Loss = 4.1148e-02, PNorm = 38.3441, GNorm = 0.4622, lr_0 = 7.2418e-04
Validation auc = 0.838038
Validation accuracy = 0.885714
Epoch 3
Loss = 1.6016e-01, PNorm = 38.3626, GNorm = 0.6260, lr_0 = 6.6370e-04
Loss = 1.6362e-01, PNorm = 38.3878, GNorm = 0.2337, lr_0 = 6.0826e-04
Loss = 1.8213e-01, PNorm = 38.4092, GNorm = 0.3222, lr_0 = 5.5746e-04
Validation auc = 0.841622
Validation accuracy = 0.885714
Epoch 4
Loss = 1.3103e-01, PNorm = 38.4350, GNorm = 0.2859, lr_0 = 5.1090e-04
Loss = 1.6611e-01, PNorm = 38.4562, GNorm = 0.3224, lr_0 = 4.6822e-04
Loss = 1.7806e-01, PNorm = 38.4765, GNorm = 0.5089, lr_0 = 4.2912e-04
Validation auc = 0.849686
Validation accuracy = 0.885714
Epoch 5
Loss = 1.4003e-01, PNorm = 38.5006, GNorm = 0.2934, lr_0 = 3.9328e-04
Loss = 1.3828e-01, PNorm = 38.5177, GNorm = 0.4293, lr_0 = 3.6043e-04
Loss = 1.5245e-01, PNorm = 38.5400, GNorm = 0.4201, lr_0 = 3.3032e-04
Loss = 1.7524e-01, PNorm = 38.5537, GNorm = 0.3833, lr_0 = 3.0273e-04
Validation auc = 0.862903
Validation accuracy = 0.885714
Epoch 6
Loss = 1.1183e-01, PNorm = 38.5694, GNorm = 0.4666, lr_0 = 2.7504e-04
Loss = 1.3035e-01, PNorm = 38.5824, GNorm = 0.1727, lr_0 = 2.5207e-04
Loss = 1.9920e-01, PNorm = 38.5942, GNorm = 0.4132, lr_0 = 2.3101e-04
Validation auc = 0.840950
Validation accuracy = 0.885714
Epoch 7
Loss = 1.2190e-01, PNorm = 38.6138, GNorm = 0.3266, lr_0 = 2.1172e-04
Loss = 1.6598e-01, PNorm = 38.6185, GNorm = 0.5164, lr_0 = 1.9403e-04
Loss = 1.4459e-01, PNorm = 38.6316, GNorm = 0.3760, lr_0 = 1.7783e-04
Validation auc = 0.872312
Validation accuracy = 0.885714
Epoch 8
Loss = 8.5901e-02, PNorm = 38.6447, GNorm = 0.1985, lr_0 = 1.6156e-04
Loss = 1.5557e-01, PNorm = 38.6522, GNorm = 0.5504, lr_0 = 1.4807e-04
Loss = 1.4202e-01, PNorm = 38.6645, GNorm = 0.7272, lr_0 = 1.3570e-04
Loss = 1.2900e-01, PNorm = 38.6717, GNorm = 0.7299, lr_0 = 1.2436e-04
Validation auc = 0.861559
Validation accuracy = 0.885714
Epoch 9
Loss = 1.4388e-01, PNorm = 38.6799, GNorm = 0.6631, lr_0 = 1.1398e-04
Loss = 1.3910e-01, PNorm = 38.6892, GNorm = 0.5498, lr_0 = 1.0446e-04
Loss = 1.0562e-01, PNorm = 38.6971, GNorm = 0.7020, lr_0 = 1.0000e-04
Validation auc = 0.876568
Validation accuracy = 0.885714
Model 0 best validation auc = 0.876568 on epoch 9
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Model 0 test auc = 0.840299
Model 0 test accuracy = 0.952607
Ensemble test auc = 0.840299
Ensemble test accuracy = 0.952607
Fold 2
Splitting data with seed 44
Total scaffolds = 1,035 | train scaffolds = 765 | val scaffolds = 142 | test scaffolds = 128
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 250 | target average = 0.032000


Scaffold 1
Task 0: count = 191 | target average = 0.010471


Scaffold 2
Task 0: count = 43 | target average = 0.000000


Scaffold 3
Task 0: count = 21 | target average = 0.000000


Scaffold 4
Task 0: count = 19 | target average = 0.000000


Scaffold 5
Task 0: count = 18 | target average = 0.000000


Scaffold 6
Task 0: count = 16 | target average = 0.250000


Scaffold 7
Task 0: count = 14 | target average = 0.000000


Scaffold 8
Task 0: count = 13 | target average = 0.076923


Scaffold 9
Task 0: count = 12 | target average = 0.000000


Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Epoch 0
Loss = 4.5988e-01, PNorm = 38.1780, GNorm = 0.5187, lr_0 = 2.5000e-04
Loss = 2.1075e-01, PNorm = 38.1879, GNorm = 0.8750, lr_0 = 3.8636e-04
Loss = 1.7967e-01, PNorm = 38.1965, GNorm = 0.2887, lr_0 = 5.2273e-04
Validation auc = 0.574538
Validation accuracy = 0.909524
Epoch 1
Loss = 1.6547e-01, PNorm = 38.2172, GNorm = 0.2895, lr_0 = 6.7273e-04
Loss = 2.1832e-01, PNorm = 38.2306, GNorm = 0.4395, lr_0 = 8.0909e-04
Loss = 2.0344e-01, PNorm = 38.2629, GNorm = 0.6041, lr_0 = 9.4545e-04
Validation auc = 0.611188
Validation accuracy = 0.909524
Epoch 2
Loss = 2.1976e-01, PNorm = 38.2844, GNorm = 0.4298, lr_0 = 9.4901e-04
Loss = 1.9032e-01, PNorm = 38.3088, GNorm = 0.7429, lr_0 = 8.6975e-04
Loss = 1.7568e-01, PNorm = 38.3287, GNorm = 0.1485, lr_0 = 7.9710e-04
Loss = 1.8884e-01, PNorm = 38.3518, GNorm = 0.6042, lr_0 = 7.3053e-04
Loss = 4.3392e-02, PNorm = 38.3535, GNorm = 0.5932, lr_0 = 7.2418e-04
Validation auc = 0.809589
Validation accuracy = 0.909524
Epoch 3
Loss = 2.2620e-01, PNorm = 38.3765, GNorm = 1.0001, lr_0 = 6.6370e-04
Loss = 1.3551e-01, PNorm = 38.4127, GNorm = 0.1396, lr_0 = 6.0826e-04
Loss = 1.5278e-01, PNorm = 38.4265, GNorm = 0.4031, lr_0 = 5.5746e-04
Validation auc = 0.769634
Validation accuracy = 0.909524
Epoch 4
Loss = 2.1708e-01, PNorm = 38.4392, GNorm = 0.5652, lr_0 = 5.1090e-04
Loss = 1.4482e-01, PNorm = 38.4576, GNorm = 0.9054, lr_0 = 4.6822e-04
Loss = 1.7086e-01, PNorm = 38.4696, GNorm = 0.5823, lr_0 = 4.2912e-04
Validation auc = 0.814274
Validation accuracy = 0.909524
Epoch 5
Loss = 2.0600e-01, PNorm = 38.4927, GNorm = 0.4163, lr_0 = 3.9328e-04
Loss = 1.6101e-01, PNorm = 38.5108, GNorm = 0.4736, lr_0 = 3.6043e-04
Loss = 1.4722e-01, PNorm = 38.5323, GNorm = 0.5075, lr_0 = 3.3032e-04
Loss = 1.5385e-01, PNorm = 38.5410, GNorm = 0.8471, lr_0 = 3.0273e-04
Validation auc = 0.832736
Validation accuracy = 0.909524
Epoch 6
Loss = 1.7559e-01, PNorm = 38.5583, GNorm = 0.5323, lr_0 = 2.7504e-04
Loss = 1.3657e-01, PNorm = 38.5687, GNorm = 0.5819, lr_0 = 2.5207e-04
Loss = 1.5036e-01, PNorm = 38.5836, GNorm = 0.7001, lr_0 = 2.3101e-04
Validation auc = 0.829705
Validation accuracy = 0.914286
Epoch 7
Loss = 1.2563e-01, PNorm = 38.6003, GNorm = 0.2822, lr_0 = 2.1172e-04
Loss = 1.6681e-01, PNorm = 38.6137, GNorm = 0.6765, lr_0 = 1.9403e-04
Loss = 1.3426e-01, PNorm = 38.6262, GNorm = 1.0507, lr_0 = 1.7783e-04
Validation auc = 0.846790
Validation accuracy = 0.919048
Epoch 8
Loss = 8.9442e-02, PNorm = 38.6334, GNorm = 0.7741, lr_0 = 1.6156e-04
Loss = 1.7228e-01, PNorm = 38.6431, GNorm = 0.7232, lr_0 = 1.4807e-04
Loss = 1.4784e-01, PNorm = 38.6498, GNorm = 0.5966, lr_0 = 1.3570e-04
Loss = 1.2888e-01, PNorm = 38.6599, GNorm = 0.6922, lr_0 = 1.2436e-04
Validation auc = 0.852025
Validation accuracy = 0.914286
Epoch 9
Loss = 8.7169e-02, PNorm = 38.6720, GNorm = 0.3779, lr_0 = 1.1398e-04
Loss = 1.6349e-01, PNorm = 38.6806, GNorm = 1.4400, lr_0 = 1.0446e-04
Loss = 1.4748e-01, PNorm = 38.6878, GNorm = 0.8839, lr_0 = 1.0000e-04
Validation auc = 0.856434
Validation accuracy = 0.914286
Model 0 best validation auc = 0.856434 on epoch 9
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Model 0 test auc = 0.866246
Model 0 test accuracy = 0.966825
Ensemble test auc = 0.866246
Ensemble test accuracy = 0.966825
3-fold cross validation
	Seed 42 ==> test auc = 0.810884
	Seed 42 ==> test accuracy = 0.928910
	Seed 43 ==> test auc = 0.840299
	Seed 43 ==> test accuracy = 0.952607
	Seed 44 ==> test auc = 0.866246
	Seed 44 ==> test accuracy = 0.966825
Overall test auc = 0.839143 +/- 0.022616
Overall test accuracy = 0.949447 +/- 0.015639
Elapsed time = 0:05:05
Command line
python /Users/anastasiakuznecova/PycharmProjects/chemprop-master/Testing Chemprop for project.py
Args
Command line
python /Users/anastasiakuznecova/PycharmProjects/chemprop-master/Testing Chemprop for project.py
Args
Command line
python /Users/anastasiakuznecova/PycharmProjects/chemprop-master/Testing Chemprop for project.py
Args
Command line
python /Users/anastasiakuznecova/PycharmProjects/chemprop-master/Testing Chemprop for project.py
Args
Command line
python /Users/anastasiakuznecova/PycharmProjects/chemprop-master/Testing Chemprop for project.py
Args
{'activation': 'ReLU',
 'adding_h': False,
 'aggregation': 'self_attention',
 'aggregation_norm': 100,
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_feature_scaling': True,
 'bond_features_path': None,
 'bond_features_size': 0,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': 'tests/data/Halicin_train.csv',
 'data_weights_path': None,
 'dataset_type': 'classification',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 10,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': ['accuracy'],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 3,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'loss_function': 'binary_cross_entropy',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'auc',
 'metrics': ['auc', 'accuracy'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_atom_descriptor_scaling': False,
 'no_bond_features_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 3,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': 'classification_checkpoints/self-attention/exp0',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 42,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_features_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_features_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'show_individual_scores': False,
 'smiles_columns': ['Smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['Active'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
{'activation': 'ReLU',
 'adding_h': False,
 'aggregation': 'self_attention',
 'aggregation_norm': 100,
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_feature_scaling': True,
 'bond_features_path': None,
 'bond_features_size': 0,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': 'tests/data/Halicin_train.csv',
 'data_weights_path': None,
 'dataset_type': 'classification',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 10,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': ['accuracy'],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 3,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'loss_function': 'binary_cross_entropy',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'auc',
 'metrics': ['auc', 'accuracy'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_atom_descriptor_scaling': False,
 'no_bond_features_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 3,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': 'classification_checkpoints/self-attention/exp0',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 42,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_features_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_features_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'show_individual_scores': False,
 'smiles_columns': ['Smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['Active'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
{'activation': 'ReLU',
 'adding_h': False,
 'aggregation': 'self_attention',
 'aggregation_norm': 100,
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_feature_scaling': True,
 'bond_features_path': None,
 'bond_features_size': 0,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': 'tests/data/Halicin_train.csv',
 'data_weights_path': None,
 'dataset_type': 'classification',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 10,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': ['accuracy'],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 3,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'loss_function': 'binary_cross_entropy',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'auc',
 'metrics': ['auc', 'accuracy'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_atom_descriptor_scaling': False,
 'no_bond_features_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 3,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': 'classification_checkpoints/self-attention/exp0',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 42,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_features_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_features_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'show_individual_scores': False,
 'smiles_columns': ['Smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['Active'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
{'activation': 'ReLU',
 'adding_h': False,
 'aggregation': 'self_attention',
 'aggregation_norm': 100,
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_feature_scaling': True,
 'bond_features_path': None,
 'bond_features_size': 0,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': 'tests/data/Halicin_train.csv',
 'data_weights_path': None,
 'dataset_type': 'classification',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 10,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': ['accuracy'],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 3,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'loss_function': 'binary_cross_entropy',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'auc',
 'metrics': ['auc', 'accuracy'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_atom_descriptor_scaling': False,
 'no_bond_features_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 3,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': 'classification_checkpoints/self-attention/exp0',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 42,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_features_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_features_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'show_individual_scores': False,
 'smiles_columns': ['Smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['Active'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
{'activation': 'ReLU',
 'adding_h': False,
 'aggregation': 'self_attention',
 'aggregation_norm': 100,
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_feature_scaling': True,
 'bond_features_path': None,
 'bond_features_size': 0,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': 'tests/data/Halicin_train.csv',
 'data_weights_path': None,
 'dataset_type': 'classification',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 10,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': ['accuracy'],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 3,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'loss_function': 'binary_cross_entropy',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'auc',
 'metrics': ['auc', 'accuracy'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_atom_descriptor_scaling': False,
 'no_bond_features_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 3,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': 'classification_checkpoints/self-attention/exp0',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 42,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_features_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_features_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'show_individual_scores': False,
 'smiles_columns': ['Smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['Active'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Command line
python /Users/anastasiakuznecova/PycharmProjects/chemprop-master/Testing Chemprop for project.py
Args
{'activation': 'ReLU',
 'adding_h': False,
 'aggregation': 'self_attention',
 'aggregation_norm': 100,
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_feature_scaling': True,
 'bond_features_path': None,
 'bond_features_size': 0,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': 'tests/data/Halicin_train.csv',
 'data_weights_path': None,
 'dataset_type': 'classification',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 10,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': ['accuracy'],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 3,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'loss_function': 'binary_cross_entropy',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'auc',
 'metrics': ['auc', 'accuracy'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_atom_descriptor_scaling': False,
 'no_bond_features_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 3,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': 'classification_checkpoints/self-attention/exp0',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 42,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_features_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_features_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'show_individual_scores': False,
 'smiles_columns': ['Smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['Active'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Command line
python /Users/anastasiakuznecova/PycharmProjects/chemprop-master/Testing Chemprop for project.py
Args
Command line
python /Users/anastasiakuznecova/PycharmProjects/chemprop-master/Testing Chemprop for project.py
Args
{'activation': 'ReLU',
 'adding_h': False,
 'aggregation': 'self_attention',
 'aggregation_norm': 100,
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_feature_scaling': True,
 'bond_features_path': None,
 'bond_features_size': 0,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': 'tests/data/Halicin_train.csv',
 'data_weights_path': None,
 'dataset_type': 'classification',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 10,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': ['accuracy'],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 3,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'loss_function': 'binary_cross_entropy',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'auc',
 'metrics': ['auc', 'accuracy'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_atom_descriptor_scaling': False,
 'no_bond_features_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 3,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': 'classification_checkpoints/self-attention/exp0',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 42,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_features_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_features_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'show_individual_scores': False,
 'smiles_columns': ['Smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['Active'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Could not write the reproducibility section of the arguments to file, thus omitting this section.
Could not write the reproducibility section of the arguments to file, thus omitting this section.
Could not write the reproducibility section of the arguments to file, thus omitting this section.
{'activation': 'ReLU',
 'adding_h': False,
 'aggregation': 'self_attention',
 'aggregation_norm': 100,
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_feature_scaling': True,
 'bond_features_path': None,
 'bond_features_size': 0,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': 'tests/data/Halicin_train.csv',
 'data_weights_path': None,
 'dataset_type': 'classification',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 10,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': ['accuracy'],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 3,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'loss_function': 'binary_cross_entropy',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'auc',
 'metrics': ['auc', 'accuracy'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_atom_descriptor_scaling': False,
 'no_bond_features_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 3,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': 'classification_checkpoints/self-attention/exp0',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 42,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_features_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_features_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'show_individual_scores': False,
 'smiles_columns': ['Smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['Active'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Setting molecule featurization parameters to default.
Loading data
Setting molecule featurization parameters to default.
Loading data
Setting molecule featurization parameters to default.
Loading data
Could not write the reproducibility section of the arguments to file, thus omitting this section.
Could not write the reproducibility section of the arguments to file, thus omitting this section.
Setting molecule featurization parameters to default.
Loading data
Setting molecule featurization parameters to default.
Loading data
Could not write the reproducibility section of the arguments to file, thus omitting this section.
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Number of tasks = 1
Fold 0
Splitting data with seed 42
Splitting data with seed 42
Number of tasks = 1
Fold 0
Splitting data with seed 42
Could not write the reproducibility section of the arguments to file, thus omitting this section.
Number of tasks = 1
Fold 0
Splitting data with seed 42
Number of tasks = 1
Fold 0
Splitting data with seed 42
Could not write the reproducibility section of the arguments to file, thus omitting this section.
Setting molecule featurization parameters to default.
Loading data
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 42
Total scaffolds = 1,035 | train scaffolds = 760 | val scaffolds = 135 | test scaffolds = 140
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 250 | target average = 0.032000


Scaffold 1
Task 0: count = 191 | target average = 0.010471


Scaffold 2
Task 0: count = 43 | target average = 0.000000


Scaffold 3
Task 0: count = 21 | target average = 0.000000


Scaffold 4
Task 0: count = 19 | target average = 0.000000


Scaffold 5
Task 0: count = 18 | target average = 0.000000


Scaffold 6
Task 0: count = 16 | target average = 0.250000


Scaffold 7
Task 0: count = 14 | target average = 0.000000


Scaffold 8
Task 0: count = 13 | target average = 0.076923


Scaffold 9
Task 0: count = 12 | target average = 0.000000


Total scaffolds = 1,035 | train scaffolds = 760 | val scaffolds = 135 | test scaffolds = 140
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 250 | target average = 0.032000


Scaffold 1
Task 0: count = 191 | target average = 0.010471


Scaffold 2
Task 0: count = 43 | target average = 0.000000


Scaffold 3
Task 0: count = 21 | target average = 0.000000


Scaffold 4
Task 0: count = 19 | target average = 0.000000


Scaffold 5
Task 0: count = 18 | target average = 0.000000


Scaffold 6
Task 0: count = 16 | target average = 0.250000


Scaffold 7
Task 0: count = 14 | target average = 0.000000


Scaffold 8
Task 0: count = 13 | target average = 0.076923


Class sizes
Active 0: 94.86%, 1: 5.14%
Scaffold 9
Task 0: count = 12 | target average = 0.000000


Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Class sizes
Active 0: 94.86%, 1: 5.14%
Total scaffolds = 1,035 | train scaffolds = 760 | val scaffolds = 135 | test scaffolds = 140
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Scaffold 0
Task 0: count = 250 | target average = 0.032000


Scaffold 1
Task 0: count = 191 | target average = 0.010471


Scaffold 2
Task 0: count = 43 | target average = 0.000000


Scaffold 3
Task 0: count = 21 | target average = 0.000000


Scaffold 4
Task 0: count = 19 | target average = 0.000000


Scaffold 5
Task 0: count = 18 | target average = 0.000000


Scaffold 6
Task 0: count = 16 | target average = 0.250000


Scaffold 7
Task 0: count = 14 | target average = 0.000000


Scaffold 8
Task 0: count = 13 | target average = 0.076923


Scaffold 9
Task 0: count = 12 | target average = 0.000000


Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
Building model 0
Building model 0
Number of tasks = 1
Fold 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Number of tasks = 1
Fold 0
Total scaffolds = 1,035 | train scaffolds = 760 | val scaffolds = 135 | test scaffolds = 140
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 250 | target average = 0.032000


Scaffold 1
Task 0: count = 191 | target average = 0.010471


Scaffold 2
Task 0: count = 43 | target average = 0.000000


Scaffold 3
Task 0: count = 21 | target average = 0.000000


Scaffold 4
Task 0: count = 19 | target average = 0.000000


Scaffold 5
Task 0: count = 18 | target average = 0.000000


Scaffold 6
Task 0: count = 16 | target average = 0.250000


Scaffold 7
Task 0: count = 14 | target average = 0.000000


Splitting data with seed 42
Scaffold 8
Task 0: count = 13 | target average = 0.076923


Scaffold 9
Task 0: count = 12 | target average = 0.000000


Class sizes
Active 0: 94.86%, 1: 5.14%
Splitting data with seed 42
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Total scaffolds = 1,035 | train scaffolds = 760 | val scaffolds = 135 | test scaffolds = 140
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 250 | target average = 0.032000


Scaffold 1
Task 0: count = 191 | target average = 0.010471


Scaffold 2
Task 0: count = 43 | target average = 0.000000


Scaffold 3
Task 0: count = 21 | target average = 0.000000


Scaffold 4
Task 0: count = 19 | target average = 0.000000


Scaffold 5
Task 0: count = 18 | target average = 0.000000


Scaffold 6
Task 0: count = 16 | target average = 0.250000


Scaffold 7
Task 0: count = 14 | target average = 0.000000


Scaffold 8
Task 0: count = 13 | target average = 0.076923


Scaffold 9
Task 0: count = 12 | target average = 0.000000


Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
Epoch 0
Building model 0
Epoch 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Epoch 0
Epoch 0
Epoch 0
Total scaffolds = 1,035 | train scaffolds = 760 | val scaffolds = 135 | test scaffolds = 140
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 250 | target average = 0.032000


Scaffold 1
Task 0: count = 191 | target average = 0.010471


Scaffold 2
Task 0: count = 43 | target average = 0.000000


Scaffold 3
Task 0: count = 21 | target average = 0.000000


Scaffold 4
Task 0: count = 19 | target average = 0.000000


Scaffold 5
Task 0: count = 18 | target average = 0.000000


Scaffold 6
Task 0: count = 16 | target average = 0.250000


Scaffold 7
Task 0: count = 14 | target average = 0.000000


Scaffold 8
Task 0: count = 13 | target average = 0.076923


Scaffold 9
Task 0: count = 12 | target average = 0.000000


Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Epoch 0
Total scaffolds = 1,035 | train scaffolds = 760 | val scaffolds = 135 | test scaffolds = 140
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 250 | target average = 0.032000


Scaffold 1
Task 0: count = 191 | target average = 0.010471


Scaffold 2
Task 0: count = 43 | target average = 0.000000


Scaffold 3
Task 0: count = 21 | target average = 0.000000


Scaffold 4
Task 0: count = 19 | target average = 0.000000


Total scaffolds = 1,035 | train scaffolds = 760 | val scaffolds = 135 | test scaffolds = 140
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 5
Task 0: count = 18 | target average = 0.000000


Scaffold 6
Task 0: count = 16 | target average = 0.250000


Scaffold 7
Task 0: count = 14 | target average = 0.000000


Scaffold 8
Task 0: count = 13 | target average = 0.076923


Scaffold 9
Task 0: count = 12 | target average = 0.000000


Scaffold 0
Task 0: count = 250 | target average = 0.032000


Scaffold 1
Task 0: count = 191 | target average = 0.010471


Scaffold 2
Task 0: count = 43 | target average = 0.000000


Scaffold 3
Task 0: count = 21 | target average = 0.000000


Scaffold 4
Task 0: count = 19 | target average = 0.000000


Scaffold 5
Task 0: count = 18 | target average = 0.000000


Class sizes
Scaffold 6
Task 0: count = 16 | target average = 0.250000
Active 0: 94.86%, 1: 5.14%


Scaffold 7
Task 0: count = 14 | target average = 0.000000


Scaffold 8
Task 0: count = 13 | target average = 0.076923


Scaffold 9
Task 0: count = 12 | target average = 0.000000


Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Class sizes
Active 0: 94.86%, 1: 5.14%
Building model 0
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Epoch 0
Epoch 0
Loss = 4.3209e-01, PNorm = 38.1783, GNorm = 0.3443, lr_0 = 2.5000e-04
Loss = 4.3209e-01, PNorm = 38.1783, GNorm = 0.3443, lr_0 = 2.5000e-04
Loss = 4.3209e-01, PNorm = 38.1783, GNorm = 0.3443, lr_0 = 2.5000e-04
Loss = 4.3209e-01, PNorm = 38.1783, GNorm = 0.3443, lr_0 = 2.5000e-04
Loss = 4.3209e-01, PNorm = 38.1783, GNorm = 0.3443, lr_0 = 2.5000e-04
Loss = 4.3209e-01, PNorm = 38.1783, GNorm = 0.3443, lr_0 = 2.5000e-04
Loss = 4.3209e-01, PNorm = 38.1783, GNorm = 0.3443, lr_0 = 2.5000e-04
Loss = 4.3209e-01, PNorm = 38.1783, GNorm = 0.3443, lr_0 = 2.5000e-04
Loss = 2.3257e-01, PNorm = 38.1879, GNorm = 0.2249, lr_0 = 3.8636e-04
Loss = 2.3257e-01, PNorm = 38.1879, GNorm = 0.2249, lr_0 = 3.8636e-04
Loss = 2.3257e-01, PNorm = 38.1879, GNorm = 0.2249, lr_0 = 3.8636e-04
Loss = 2.3257e-01, PNorm = 38.1879, GNorm = 0.2249, lr_0 = 3.8636e-04
Loss = 2.3257e-01, PNorm = 38.1879, GNorm = 0.2249, lr_0 = 3.8636e-04
Loss = 2.3257e-01, PNorm = 38.1879, GNorm = 0.2249, lr_0 = 3.8636e-04
Loss = 2.3257e-01, PNorm = 38.1879, GNorm = 0.2241, lr_0 = 3.8636e-04
Loss = 2.3257e-01, PNorm = 38.1879, GNorm = 0.2249, lr_0 = 3.8636e-04
Loss = 2.1680e-01, PNorm = 38.1985, GNorm = 0.7962, lr_0 = 5.2273e-04
Loss = 2.1680e-01, PNorm = 38.1985, GNorm = 0.7962, lr_0 = 5.2273e-04
Loss = 2.1680e-01, PNorm = 38.1985, GNorm = 0.7962, lr_0 = 5.2273e-04
Loss = 2.1680e-01, PNorm = 38.1985, GNorm = 0.7962, lr_0 = 5.2273e-04
Loss = 2.1680e-01, PNorm = 38.1985, GNorm = 0.7962, lr_0 = 5.2273e-04
Loss = 2.1684e-01, PNorm = 38.1985, GNorm = 0.7969, lr_0 = 5.2273e-04
Loss = 2.1680e-01, PNorm = 38.1985, GNorm = 0.7962, lr_0 = 5.2273e-04
Loss = 2.1680e-01, PNorm = 38.1985, GNorm = 0.7962, lr_0 = 5.2273e-04
Validation auc = 0.618508
Validation accuracy = 0.938095
Epoch 1
Validation auc = 0.618508
Validation accuracy = 0.938095
Epoch 1
Validation auc = 0.618508
Validation accuracy = 0.938095
Validation auc = 0.618508
Validation accuracy = 0.938095
Validation auc = 0.618508
Validation accuracy = 0.938095
Epoch 1
Epoch 1
Epoch 1
Validation auc = 0.618899
Validation accuracy = 0.938095
Epoch 1
Validation auc = 0.618508
Validation accuracy = 0.938095
Epoch 1
Validation auc = 0.618508
Validation accuracy = 0.938095
Epoch 1
Loss = 1.7510e-01, PNorm = 38.2157, GNorm = 0.6370, lr_0 = 6.7273e-04
Loss = 1.7510e-01, PNorm = 38.2157, GNorm = 0.6370, lr_0 = 6.7273e-04
Loss = 1.7510e-01, PNorm = 38.2157, GNorm = 0.6370, lr_0 = 6.7273e-04
Loss = 1.7510e-01, PNorm = 38.2157, GNorm = 0.6370, lr_0 = 6.7273e-04
Loss = 1.7510e-01, PNorm = 38.2157, GNorm = 0.6370, lr_0 = 6.7273e-04
Loss = 1.7522e-01, PNorm = 38.2156, GNorm = 0.6412, lr_0 = 6.7273e-04
Loss = 1.7510e-01, PNorm = 38.2157, GNorm = 0.6370, lr_0 = 6.7273e-04
Loss = 1.7510e-01, PNorm = 38.2157, GNorm = 0.6370, lr_0 = 6.7273e-04
Loss = 1.7294e-01, PNorm = 38.2310, GNorm = 0.7437, lr_0 = 8.0909e-04
Loss = 1.7294e-01, PNorm = 38.2310, GNorm = 0.7433, lr_0 = 8.0909e-04
Loss = 1.7294e-01, PNorm = 38.2310, GNorm = 0.7437, lr_0 = 8.0909e-04
Loss = 1.7294e-01, PNorm = 38.2310, GNorm = 0.7437, lr_0 = 8.0909e-04
Loss = 1.7294e-01, PNorm = 38.2310, GNorm = 0.7437, lr_0 = 8.0909e-04
Loss = 1.7257e-01, PNorm = 38.2307, GNorm = 0.7435, lr_0 = 8.0909e-04
Loss = 1.7294e-01, PNorm = 38.2310, GNorm = 0.7434, lr_0 = 8.0909e-04
Loss = 1.7294e-01, PNorm = 38.2310, GNorm = 0.7437, lr_0 = 8.0909e-04
Loss = 1.9924e-01, PNorm = 38.2530, GNorm = 0.7510, lr_0 = 9.4545e-04
Loss = 1.9920e-01, PNorm = 38.2532, GNorm = 0.7487, lr_0 = 9.4545e-04
Loss = 1.9924e-01, PNorm = 38.2530, GNorm = 0.7510, lr_0 = 9.4545e-04
Loss = 1.9923e-01, PNorm = 38.2530, GNorm = 0.7508, lr_0 = 9.4545e-04
Loss = 1.9924e-01, PNorm = 38.2530, GNorm = 0.7510, lr_0 = 9.4545e-04
Loss = 1.9974e-01, PNorm = 38.2527, GNorm = 0.7688, lr_0 = 9.4545e-04
Loss = 1.9926e-01, PNorm = 38.2531, GNorm = 0.7498, lr_0 = 9.4545e-04
Loss = 1.9927e-01, PNorm = 38.2531, GNorm = 0.7515, lr_0 = 9.4545e-04
Validation auc = 0.692308
Validation accuracy = 0.938095
Epoch 2
Validation auc = 0.683327
Validation accuracy = 0.938095
Epoch 2
Validation auc = 0.689965
Validation accuracy = 0.938095
Epoch 2
Validation auc = 0.692308
Validation accuracy = 0.938095
Loss = 1.3045e-01, PNorm = 38.2865, GNorm = 0.1632, lr_0 = 9.4901e-04
Epoch 2
Validation auc = 0.692308
Validation accuracy = 0.938095
Epoch 2
Loss = 1.3061e-01, PNorm = 38.2862, GNorm = 0.1623, lr_0 = 9.4901e-04
Validation auc = 0.713003
Validation accuracy = 0.938095
Epoch 2
Loss = 1.3054e-01, PNorm = 38.2865, GNorm = 0.1641, lr_0 = 9.4901e-04
Validation auc = 0.681374
Validation accuracy = 0.938095
Loss = 1.3045e-01, PNorm = 38.2865, GNorm = 0.1632, lr_0 = 9.4901e-04
Validation auc = 0.691917
Validation accuracy = 0.938095
Epoch 2
Epoch 2
Loss = 1.3045e-01, PNorm = 38.2865, GNorm = 0.1632, lr_0 = 9.4901e-04
Loss = 1.3093e-01, PNorm = 38.2840, GNorm = 0.1866, lr_0 = 9.4901e-04
Loss = 1.3089e-01, PNorm = 38.2862, GNorm = 0.1609, lr_0 = 9.4901e-04
Loss = 1.3047e-01, PNorm = 38.2866, GNorm = 0.1638, lr_0 = 9.4901e-04
Loss = 1.5722e-01, PNorm = 38.3030, GNorm = 0.4431, lr_0 = 8.6975e-04
Loss = 1.5807e-01, PNorm = 38.3022, GNorm = 0.3944, lr_0 = 8.6975e-04
Loss = 1.5742e-01, PNorm = 38.3032, GNorm = 0.4282, lr_0 = 8.6975e-04
Loss = 1.5722e-01, PNorm = 38.3030, GNorm = 0.4431, lr_0 = 8.6975e-04
Loss = 1.5722e-01, PNorm = 38.3030, GNorm = 0.4431, lr_0 = 8.6975e-04
Loss = 1.5656e-01, PNorm = 38.3006, GNorm = 0.4897, lr_0 = 8.6975e-04
Loss = 1.5761e-01, PNorm = 38.3028, GNorm = 0.4498, lr_0 = 8.6975e-04
Loss = 1.5786e-01, PNorm = 38.3024, GNorm = 0.4091, lr_0 = 8.6975e-04
Loss = 2.3776e-01, PNorm = 38.3323, GNorm = 0.3418, lr_0 = 7.9710e-04
Loss = 2.3720e-01, PNorm = 38.3298, GNorm = 0.3160, lr_0 = 7.9710e-04
Loss = 2.3761e-01, PNorm = 38.3328, GNorm = 0.3374, lr_0 = 7.9710e-04
Loss = 2.3776e-01, PNorm = 38.3323, GNorm = 0.3418, lr_0 = 7.9710e-04
Loss = 2.3776e-01, PNorm = 38.3323, GNorm = 0.3418, lr_0 = 7.9710e-04
Loss = 2.3835e-01, PNorm = 38.3310, GNorm = 0.3916, lr_0 = 7.9710e-04
Loss = 2.3790e-01, PNorm = 38.3319, GNorm = 0.3307, lr_0 = 7.9710e-04
Loss = 2.3774e-01, PNorm = 38.3299, GNorm = 0.3311, lr_0 = 7.9710e-04
Loss = 1.3426e-01, PNorm = 38.3668, GNorm = 0.4204, lr_0 = 7.3053e-04
Loss = 3.0431e-02, PNorm = 38.3703, GNorm = 0.5733, lr_0 = 7.2418e-04
Loss = 1.3487e-01, PNorm = 38.3639, GNorm = 0.4359, lr_0 = 7.3053e-04
Loss = 1.3425e-01, PNorm = 38.3685, GNorm = 0.4248, lr_0 = 7.3053e-04
Loss = 3.2239e-02, PNorm = 38.3674, GNorm = 0.6008, lr_0 = 7.2418e-04
Loss = 2.9819e-02, PNorm = 38.3720, GNorm = 0.5685, lr_0 = 7.2418e-04
Validation auc = 0.519328
Validation accuracy = 0.938095
Epoch 3
Loss = 1.3426e-01, PNorm = 38.3668, GNorm = 0.4204, lr_0 = 7.3053e-04
Loss = 1.3426e-01, PNorm = 38.3668, GNorm = 0.4204, lr_0 = 7.3053e-04
Loss = 3.0431e-02, PNorm = 38.3703, GNorm = 0.5734, lr_0 = 7.2418e-04
Validation auc = 0.534947
Validation accuracy = 0.938095
Epoch 3
Loss = 3.0431e-02, PNorm = 38.3703, GNorm = 0.5734, lr_0 = 7.2418e-04
Validation auc = 0.518157
Validation accuracy = 0.938095
Epoch 3
Loss = 1.3540e-01, PNorm = 38.3640, GNorm = 0.4465, lr_0 = 7.3053e-04
Loss = 3.3269e-02, PNorm = 38.3674, GNorm = 0.5996, lr_0 = 7.2418e-04
Validation auc = 0.519328
Validation accuracy = 0.938095
Epoch 3
Validation auc = 0.519328
Validation accuracy = 0.938095
Epoch 3
Loss = 1.3479e-01, PNorm = 38.3664, GNorm = 0.4227, lr_0 = 7.3053e-04
Loss = 1.3512e-01, PNorm = 38.3623, GNorm = 0.4314, lr_0 = 7.3053e-04
Loss = 2.9501e-02, PNorm = 38.3699, GNorm = 0.5620, lr_0 = 7.2418e-04
Loss = 3.2134e-02, PNorm = 38.3657, GNorm = 0.5900, lr_0 = 7.2418e-04
Validation auc = 0.532214
Validation accuracy = 0.938095
Epoch 3
Validation auc = 0.529481
Validation accuracy = 0.938095
Epoch 3
Validation auc = 0.534166
Validation accuracy = 0.938095
Epoch 3
Loss = 1.4233e-01, PNorm = 38.4055, GNorm = 0.2348, lr_0 = 6.6370e-04
Loss = 1.4153e-01, PNorm = 38.4032, GNorm = 0.2276, lr_0 = 6.6370e-04
Loss = 1.4295e-01, PNorm = 38.4050, GNorm = 0.2329, lr_0 = 6.6370e-04
Loss = 1.4233e-01, PNorm = 38.4055, GNorm = 0.2345, lr_0 = 6.6370e-04
Loss = 1.4233e-01, PNorm = 38.4055, GNorm = 0.2345, lr_0 = 6.6370e-04
Loss = 1.4184e-01, PNorm = 38.4030, GNorm = 0.2308, lr_0 = 6.6370e-04
Loss = 1.4191e-01, PNorm = 38.4010, GNorm = 0.2157, lr_0 = 6.6370e-04
Loss = 1.4283e-01, PNorm = 38.4039, GNorm = 0.2217, lr_0 = 6.6370e-04
Loss = 1.6685e-01, PNorm = 38.4342, GNorm = 0.4824, lr_0 = 6.0826e-04
Loss = 1.6796e-01, PNorm = 38.4314, GNorm = 0.4802, lr_0 = 6.0826e-04
Loss = 1.6624e-01, PNorm = 38.4331, GNorm = 0.5006, lr_0 = 6.0826e-04
Loss = 1.6688e-01, PNorm = 38.4342, GNorm = 0.4839, lr_0 = 6.0826e-04
Loss = 1.6688e-01, PNorm = 38.4342, GNorm = 0.4807, lr_0 = 6.0826e-04
Loss = 1.6705e-01, PNorm = 38.4308, GNorm = 0.5120, lr_0 = 6.0826e-04
Loss = 1.6719e-01, PNorm = 38.4326, GNorm = 0.4977, lr_0 = 6.0826e-04
Loss = 1.6800e-01, PNorm = 38.4293, GNorm = 0.4903, lr_0 = 6.0826e-04
Loss = 1.5514e-01, PNorm = 38.4503, GNorm = 0.6713, lr_0 = 5.5746e-04
Loss = 1.5532e-01, PNorm = 38.4471, GNorm = 0.6571, lr_0 = 5.5746e-04
Loss = 1.5472e-01, PNorm = 38.4498, GNorm = 0.6467, lr_0 = 5.5746e-04
Loss = 1.5505e-01, PNorm = 38.4503, GNorm = 0.6730, lr_0 = 5.5746e-04
Loss = 1.5529e-01, PNorm = 38.4504, GNorm = 0.6745, lr_0 = 5.5746e-04
Loss = 1.5477e-01, PNorm = 38.4455, GNorm = 0.6052, lr_0 = 5.5746e-04
Validation auc = 0.659508
Validation accuracy = 0.938095
Epoch 4
Loss = 1.5478e-01, PNorm = 38.4441, GNorm = 0.6453, lr_0 = 5.5746e-04
Validation auc = 0.667317
Validation accuracy = 0.938095
Epoch 4
Loss = 1.5485e-01, PNorm = 38.4487, GNorm = 0.6438, lr_0 = 5.5746e-04
Validation auc = 0.660679
Validation accuracy = 0.938095
Epoch 4
Validation auc = 0.662241
Validation accuracy = 0.938095
Epoch 4
Validation auc = 0.658727
Validation accuracy = 0.938095
Epoch 4
Validation auc = 0.667317
Validation accuracy = 0.938095
Epoch 4
Loss = 1.5536e-01, PNorm = 38.4728, GNorm = 0.1655, lr_0 = 5.1090e-04
Validation auc = 0.668879
Validation accuracy = 0.938095
Epoch 4
Loss = 1.5655e-01, PNorm = 38.4678, GNorm = 0.1358, lr_0 = 5.1090e-04
Validation auc = 0.662241
Validation accuracy = 0.938095
Epoch 4
Loss = 1.5473e-01, PNorm = 38.4733, GNorm = 0.1566, lr_0 = 5.1090e-04
Loss = 1.5542e-01, PNorm = 38.4729, GNorm = 0.1655, lr_0 = 5.1090e-04
Loss = 1.5526e-01, PNorm = 38.4730, GNorm = 0.1623, lr_0 = 5.1090e-04
Loss = 1.5569e-01, PNorm = 38.4663, GNorm = 0.2093, lr_0 = 5.1090e-04
Loss = 1.5594e-01, PNorm = 38.4645, GNorm = 0.1573, lr_0 = 5.1090e-04
Loss = 1.5541e-01, PNorm = 38.4703, GNorm = 0.1605, lr_0 = 5.1090e-04
Loss = 1.4847e-01, PNorm = 38.5015, GNorm = 0.1936, lr_0 = 4.6822e-04
Loss = 1.4914e-01, PNorm = 38.4950, GNorm = 0.1891, lr_0 = 4.6822e-04
Loss = 1.4888e-01, PNorm = 38.5015, GNorm = 0.1956, lr_0 = 4.6822e-04
Loss = 1.4853e-01, PNorm = 38.5016, GNorm = 0.1925, lr_0 = 4.6822e-04
Loss = 1.4852e-01, PNorm = 38.5021, GNorm = 0.1894, lr_0 = 4.6822e-04
Loss = 1.4950e-01, PNorm = 38.4925, GNorm = 0.1899, lr_0 = 4.6822e-04
Loss = 1.4819e-01, PNorm = 38.4986, GNorm = 0.1954, lr_0 = 4.6822e-04
Loss = 1.4900e-01, PNorm = 38.4918, GNorm = 0.1929, lr_0 = 4.6822e-04
Loss = 1.5042e-01, PNorm = 38.5271, GNorm = 0.4557, lr_0 = 4.2912e-04
Loss = 1.5030e-01, PNorm = 38.5207, GNorm = 0.4558, lr_0 = 4.2912e-04
Loss = 1.4948e-01, PNorm = 38.5280, GNorm = 0.4350, lr_0 = 4.2912e-04
Loss = 1.5017e-01, PNorm = 38.5277, GNorm = 0.4606, lr_0 = 4.2912e-04
Loss = 1.5051e-01, PNorm = 38.5281, GNorm = 0.4630, lr_0 = 4.2912e-04
Loss = 1.5006e-01, PNorm = 38.5178, GNorm = 0.4389, lr_0 = 4.2912e-04
Loss = 1.5145e-01, PNorm = 38.5175, GNorm = 0.4378, lr_0 = 4.2912e-04
Loss = 1.5063e-01, PNorm = 38.5241, GNorm = 0.4656, lr_0 = 4.2912e-04
Validation auc = 0.671613
Validation accuracy = 0.928571
Epoch 5
Validation auc = 0.677470
Validation accuracy = 0.928571
Epoch 5
Validation auc = 0.675127
Validation accuracy = 0.928571
Epoch 5
Loss = 1.0147e-01, PNorm = 38.5465, GNorm = 0.2756, lr_0 = 3.9328e-04
Validation auc = 0.671613
Validation accuracy = 0.928571
Epoch 5
Validation auc = 0.669660
Validation accuracy = 0.928571
Epoch 5
Loss = 1.0323e-01, PNorm = 38.5396, GNorm = 0.2676, lr_0 = 3.9328e-04
Loss = 1.0151e-01, PNorm = 38.5486, GNorm = 0.2706, lr_0 = 3.9328e-04
Loss = 1.0201e-01, PNorm = 38.5469, GNorm = 0.2737, lr_0 = 3.9328e-04
Validation auc = 0.679813
Validation accuracy = 0.928571
Epoch 5
Loss = 1.0087e-01, PNorm = 38.5471, GNorm = 0.2664, lr_0 = 3.9328e-04
Validation auc = 0.675908
Validation accuracy = 0.928571
Epoch 5
Loss = 1.0244e-01, PNorm = 38.5371, GNorm = 0.2676, lr_0 = 3.9328e-04
Validation auc = 0.670832
Validation accuracy = 0.928571
Epoch 5
Loss = 1.0261e-01, PNorm = 38.5443, GNorm = 0.2810, lr_0 = 3.9328e-04
Loss = 1.0415e-01, PNorm = 38.5372, GNorm = 0.3147, lr_0 = 3.9328e-04
Loss = 1.1822e-01, PNorm = 38.5617, GNorm = 0.6265, lr_0 = 3.6043e-04
Loss = 1.1908e-01, PNorm = 38.5537, GNorm = 0.6678, lr_0 = 3.6043e-04
Loss = 1.1785e-01, PNorm = 38.5636, GNorm = 0.6606, lr_0 = 3.6043e-04
Loss = 1.1834e-01, PNorm = 38.5614, GNorm = 0.6305, lr_0 = 3.6043e-04
Loss = 1.1852e-01, PNorm = 38.5615, GNorm = 0.6128, lr_0 = 3.6043e-04
Loss = 1.1759e-01, PNorm = 38.5521, GNorm = 0.7131, lr_0 = 3.6043e-04
Loss = 1.1906e-01, PNorm = 38.5599, GNorm = 0.6434, lr_0 = 3.6043e-04
Loss = 1.1943e-01, PNorm = 38.5532, GNorm = 0.6745, lr_0 = 3.6043e-04
Loss = 1.1520e-01, PNorm = 38.5833, GNorm = 0.2603, lr_0 = 3.3032e-04
Loss = 1.1503e-01, PNorm = 38.5757, GNorm = 0.2415, lr_0 = 3.3032e-04
Loss = 1.1497e-01, PNorm = 38.5861, GNorm = 0.2436, lr_0 = 3.3032e-04
Loss = 1.1501e-01, PNorm = 38.5830, GNorm = 0.2484, lr_0 = 3.3032e-04
Loss = 1.1544e-01, PNorm = 38.5829, GNorm = 0.2524, lr_0 = 3.3032e-04
Loss = 1.1492e-01, PNorm = 38.5745, GNorm = 0.2611, lr_0 = 3.3032e-04
Loss = 1.1477e-01, PNorm = 38.5826, GNorm = 0.2540, lr_0 = 3.3032e-04
Loss = 1.1521e-01, PNorm = 38.5758, GNorm = 0.2396, lr_0 = 3.3032e-04
Loss = 1.8246e-01, PNorm = 38.5975, GNorm = 0.4075, lr_0 = 3.0273e-04
Loss = 1.8315e-01, PNorm = 38.5905, GNorm = 0.4669, lr_0 = 3.0273e-04
Loss = 1.8286e-01, PNorm = 38.5976, GNorm = 0.4230, lr_0 = 3.0273e-04
Loss = 1.8335e-01, PNorm = 38.6004, GNorm = 0.4787, lr_0 = 3.0273e-04
Loss = 1.8257e-01, PNorm = 38.5976, GNorm = 0.3966, lr_0 = 3.0273e-04
Validation auc = 0.662632
Validation accuracy = 0.938095
Epoch 6
Loss = 1.8305e-01, PNorm = 38.5890, GNorm = 0.4921, lr_0 = 3.0273e-04
Validation auc = 0.672394
Validation accuracy = 0.938095
Epoch 6
Validation auc = 0.665365
Validation accuracy = 0.938095
Epoch 6
Validation auc = 0.666927
Validation accuracy = 0.938095
Epoch 6
Validation auc = 0.666537
Validation accuracy = 0.938095
Epoch 6
Loss = 1.8396e-01, PNorm = 38.5978, GNorm = 0.4668, lr_0 = 3.0273e-04
Loss = 1.8399e-01, PNorm = 38.5901, GNorm = 0.4262, lr_0 = 3.0273e-04
Validation auc = 0.666537
Validation accuracy = 0.938095
Epoch 6
Validation auc = 0.671613
Validation accuracy = 0.938095
Epoch 6
Validation auc = 0.668879
Validation accuracy = 0.938095
Epoch 6
Loss = 1.6817e-01, PNorm = 38.6077, GNorm = 0.9011, lr_0 = 2.7504e-04
Loss = 1.6858e-01, PNorm = 38.5989, GNorm = 0.8725, lr_0 = 2.7504e-04
Loss = 1.6812e-01, PNorm = 38.6074, GNorm = 0.8704, lr_0 = 2.7504e-04
Loss = 1.6898e-01, PNorm = 38.6093, GNorm = 0.7419, lr_0 = 2.7504e-04
Loss = 1.6809e-01, PNorm = 38.6067, GNorm = 0.8429, lr_0 = 2.7504e-04
Loss = 1.6973e-01, PNorm = 38.5969, GNorm = 0.9271, lr_0 = 2.7504e-04
Loss = 1.6932e-01, PNorm = 38.6074, GNorm = 0.8416, lr_0 = 2.7504e-04
Loss = 1.6789e-01, PNorm = 38.5998, GNorm = 0.8230, lr_0 = 2.7504e-04
Loss = 1.1347e-01, PNorm = 38.6277, GNorm = 1.0985, lr_0 = 2.5207e-04
Loss = 1.1371e-01, PNorm = 38.6285, GNorm = 1.0970, lr_0 = 2.5207e-04
Loss = 1.1477e-01, PNorm = 38.6185, GNorm = 1.0856, lr_0 = 2.5207e-04
Loss = 1.1575e-01, PNorm = 38.6311, GNorm = 1.1420, lr_0 = 2.5207e-04
Loss = 1.1422e-01, PNorm = 38.6276, GNorm = 1.1298, lr_0 = 2.5207e-04
Loss = 1.1525e-01, PNorm = 38.6168, GNorm = 1.0693, lr_0 = 2.5207e-04
Loss = 1.1534e-01, PNorm = 38.6286, GNorm = 1.0879, lr_0 = 2.5207e-04
Loss = 1.1441e-01, PNorm = 38.6195, GNorm = 1.0652, lr_0 = 2.5207e-04
Loss = 1.2378e-01, PNorm = 38.6424, GNorm = 0.5676, lr_0 = 2.3101e-04
Loss = 1.2429e-01, PNorm = 38.6434, GNorm = 0.6025, lr_0 = 2.3101e-04
Loss = 1.2487e-01, PNorm = 38.6464, GNorm = 0.6344, lr_0 = 2.3101e-04
Loss = 1.2524e-01, PNorm = 38.6338, GNorm = 0.6385, lr_0 = 2.3101e-04
Loss = 1.2423e-01, PNorm = 38.6425, GNorm = 0.5899, lr_0 = 2.3101e-04
Loss = 1.2512e-01, PNorm = 38.6319, GNorm = 0.6558, lr_0 = 2.3101e-04
Loss = 1.2523e-01, PNorm = 38.6438, GNorm = 0.6438, lr_0 = 2.3101e-04
Validation auc = 0.574385
Validation accuracy = 0.938095
Epoch 7
Validation auc = 0.571652
Validation accuracy = 0.938095
Epoch 7
Loss = 1.2410e-01, PNorm = 38.6345, GNorm = 0.5668, lr_0 = 2.3101e-04
Validation auc = 0.575166
Validation accuracy = 0.938095
Epoch 7
Validation auc = 0.569699
Validation accuracy = 0.938095
Epoch 7
Validation auc = 0.575166
Validation accuracy = 0.938095
Epoch 7
Validation auc = 0.577899
Validation accuracy = 0.938095
Epoch 7
Loss = 1.0746e-01, PNorm = 38.6544, GNorm = 0.4430, lr_0 = 2.1172e-04
Loss = 1.0701e-01, PNorm = 38.6560, GNorm = 0.4351, lr_0 = 2.1172e-04
Validation auc = 0.573214
Validation accuracy = 0.938095
Epoch 7
Loss = 1.0673e-01, PNorm = 38.6457, GNorm = 0.4478, lr_0 = 2.1172e-04
Loss = 1.0685e-01, PNorm = 38.6544, GNorm = 0.4457, lr_0 = 2.1172e-04
Loss = 1.0698e-01, PNorm = 38.6590, GNorm = 0.4587, lr_0 = 2.1172e-04
Validation auc = 0.572823
Validation accuracy = 0.938095
Epoch 7
Loss = 1.0727e-01, PNorm = 38.6440, GNorm = 0.4611, lr_0 = 2.1172e-04
Loss = 1.0713e-01, PNorm = 38.6567, GNorm = 0.4562, lr_0 = 2.1172e-04
Loss = 1.0758e-01, PNorm = 38.6465, GNorm = 0.4514, lr_0 = 2.1172e-04
Loss = 1.1340e-01, PNorm = 38.6629, GNorm = 0.6458, lr_0 = 1.9403e-04
Loss = 1.1382e-01, PNorm = 38.6649, GNorm = 0.6257, lr_0 = 1.9403e-04
Loss = 1.1397e-01, PNorm = 38.6539, GNorm = 0.6762, lr_0 = 1.9403e-04
Loss = 1.1337e-01, PNorm = 38.6628, GNorm = 0.6484, lr_0 = 1.9403e-04
Loss = 1.1358e-01, PNorm = 38.6676, GNorm = 0.6499, lr_0 = 1.9403e-04
Loss = 1.1390e-01, PNorm = 38.6525, GNorm = 0.7129, lr_0 = 1.9403e-04
Loss = 1.1347e-01, PNorm = 38.6657, GNorm = 0.6331, lr_0 = 1.9403e-04
Loss = 1.1444e-01, PNorm = 38.6550, GNorm = 0.6906, lr_0 = 1.9403e-04
Loss = 1.0249e-01, PNorm = 38.6717, GNorm = 0.4868, lr_0 = 1.7783e-04
Loss = 1.0284e-01, PNorm = 38.6732, GNorm = 0.4617, lr_0 = 1.7783e-04
Loss = 1.0271e-01, PNorm = 38.6619, GNorm = 0.5304, lr_0 = 1.7783e-04
Loss = 1.0258e-01, PNorm = 38.6713, GNorm = 0.4632, lr_0 = 1.7783e-04
Loss = 1.0204e-01, PNorm = 38.6760, GNorm = 0.4783, lr_0 = 1.7783e-04
Loss = 1.0267e-01, PNorm = 38.6747, GNorm = 0.4673, lr_0 = 1.7783e-04
Loss = 1.0186e-01, PNorm = 38.6608, GNorm = 0.4932, lr_0 = 1.7783e-04
Loss = 1.0267e-01, PNorm = 38.6636, GNorm = 0.4840, lr_0 = 1.7783e-04
Validation auc = 0.623975
Validation accuracy = 0.942857
Epoch 8
Validation auc = 0.619680
Validation accuracy = 0.942857
Epoch 8
Validation auc = 0.624365
Validation accuracy = 0.942857
Epoch 8
Validation auc = 0.611870
Validation accuracy = 0.942857
Epoch 8
Validation auc = 0.615775
Validation accuracy = 0.942857
Epoch 8
Loss = 1.2190e-01, PNorm = 38.6800, GNorm = 0.7469, lr_0 = 1.6156e-04
Loss = 1.2172e-01, PNorm = 38.6815, GNorm = 0.7502, lr_0 = 1.6156e-04
Loss = 1.2137e-01, PNorm = 38.6793, GNorm = 0.7331, lr_0 = 1.6156e-04
Loss = 1.2154e-01, PNorm = 38.6694, GNorm = 0.7036, lr_0 = 1.6156e-04
Loss = 1.2096e-01, PNorm = 38.6838, GNorm = 0.7142, lr_0 = 1.6156e-04
Validation auc = 0.609528
Validation accuracy = 0.938095
Epoch 8
Validation auc = 0.624365
Validation accuracy = 0.942857
Epoch 8
Loss = 1.2106e-01, PNorm = 38.6679, GNorm = 0.7566, lr_0 = 1.6156e-04
Validation auc = 0.609137
Validation accuracy = 0.942857
Epoch 8
Loss = 1.2163e-01, PNorm = 38.6830, GNorm = 0.7549, lr_0 = 1.6156e-04
Loss = 1.2276e-01, PNorm = 38.6711, GNorm = 0.7695, lr_0 = 1.6156e-04
Loss = 1.1277e-01, PNorm = 38.6881, GNorm = 0.7973, lr_0 = 1.4807e-04
Loss = 1.1287e-01, PNorm = 38.6865, GNorm = 0.7947, lr_0 = 1.4807e-04
Loss = 1.1323e-01, PNorm = 38.6854, GNorm = 0.8237, lr_0 = 1.4807e-04
Loss = 1.1340e-01, PNorm = 38.6756, GNorm = 0.7419, lr_0 = 1.4807e-04
Loss = 1.1317e-01, PNorm = 38.6900, GNorm = 0.7801, lr_0 = 1.4807e-04
Loss = 1.1236e-01, PNorm = 38.6744, GNorm = 0.7286, lr_0 = 1.4807e-04
Loss = 1.1289e-01, PNorm = 38.6896, GNorm = 0.7706, lr_0 = 1.4807e-04
Loss = 1.1359e-01, PNorm = 38.6776, GNorm = 0.6878, lr_0 = 1.4807e-04
Loss = 1.2653e-01, PNorm = 38.6974, GNorm = 1.5400, lr_0 = 1.3570e-04
Loss = 1.2669e-01, PNorm = 38.6958, GNorm = 1.5258, lr_0 = 1.3570e-04
Loss = 1.2716e-01, PNorm = 38.6947, GNorm = 1.5587, lr_0 = 1.3570e-04
Loss = 1.2692e-01, PNorm = 38.6850, GNorm = 1.5183, lr_0 = 1.3570e-04
Loss = 1.2636e-01, PNorm = 38.6993, GNorm = 1.5087, lr_0 = 1.3570e-04
Loss = 1.2574e-01, PNorm = 38.6843, GNorm = 1.4682, lr_0 = 1.3570e-04
Loss = 1.2616e-01, PNorm = 38.6995, GNorm = 1.5254, lr_0 = 1.3570e-04
Loss = 1.2673e-01, PNorm = 38.6874, GNorm = 1.4968, lr_0 = 1.3570e-04
Loss = 1.1444e-01, PNorm = 38.7032, GNorm = 0.3069, lr_0 = 1.2436e-04
Loss = 1.1422e-01, PNorm = 38.6908, GNorm = 0.3165, lr_0 = 1.2436e-04
Loss = 1.1426e-01, PNorm = 38.7016, GNorm = 0.3146, lr_0 = 1.2436e-04
Loss = 1.1407e-01, PNorm = 38.7004, GNorm = 0.3077, lr_0 = 1.2436e-04
Loss = 1.1416e-01, PNorm = 38.7052, GNorm = 0.3082, lr_0 = 1.2436e-04
Validation auc = 0.646622
Validation accuracy = 0.933333
Epoch 9
Loss = 1.1355e-01, PNorm = 38.6903, GNorm = 0.3219, lr_0 = 1.2436e-04
Validation auc = 0.650137
Validation accuracy = 0.933333
Epoch 9
Validation auc = 0.649746
Validation accuracy = 0.933333
Epoch 9
Validation auc = 0.642718
Validation accuracy = 0.933333
Epoch 9
Loss = 1.1450e-01, PNorm = 38.7058, GNorm = 0.3093, lr_0 = 1.2436e-04
Validation auc = 0.647013
Validation accuracy = 0.933333
Epoch 9
Validation auc = 0.640765
Validation accuracy = 0.933333
Epoch 9
Loss = 1.1443e-01, PNorm = 38.6936, GNorm = 0.3199, lr_0 = 1.2436e-04
Validation auc = 0.647013
Validation accuracy = 0.933333
Epoch 9
Validation auc = 0.645061
Validation accuracy = 0.933333
Epoch 9
Loss = 1.4814e-01, PNorm = 38.7071, GNorm = 0.3578, lr_0 = 1.1398e-04
Loss = 1.4757e-01, PNorm = 38.7060, GNorm = 0.3617, lr_0 = 1.1398e-04
Loss = 1.4810e-01, PNorm = 38.6951, GNorm = 0.3437, lr_0 = 1.1398e-04
Loss = 1.4762e-01, PNorm = 38.7048, GNorm = 0.3512, lr_0 = 1.1398e-04
Loss = 1.4764e-01, PNorm = 38.7097, GNorm = 0.3397, lr_0 = 1.1398e-04
Loss = 1.4853e-01, PNorm = 38.6944, GNorm = 0.3787, lr_0 = 1.1398e-04
Loss = 1.4779e-01, PNorm = 38.7103, GNorm = 0.3596, lr_0 = 1.1398e-04
Loss = 1.4819e-01, PNorm = 38.6984, GNorm = 0.3545, lr_0 = 1.1398e-04
Loss = 1.2381e-01, PNorm = 38.7117, GNorm = 0.9801, lr_0 = 1.0446e-04
Loss = 1.2355e-01, PNorm = 38.7107, GNorm = 1.0172, lr_0 = 1.0446e-04
Loss = 1.2344e-01, PNorm = 38.6996, GNorm = 0.9931, lr_0 = 1.0446e-04
Loss = 1.2382e-01, PNorm = 38.7095, GNorm = 1.0154, lr_0 = 1.0446e-04
Loss = 1.2331e-01, PNorm = 38.7141, GNorm = 1.0416, lr_0 = 1.0446e-04
Loss = 1.2281e-01, PNorm = 38.6989, GNorm = 0.9727, lr_0 = 1.0446e-04
Loss = 1.2313e-01, PNorm = 38.7149, GNorm = 0.9894, lr_0 = 1.0446e-04
Loss = 1.2315e-01, PNorm = 38.7029, GNorm = 0.9864, lr_0 = 1.0446e-04
Loss = 9.2028e-02, PNorm = 38.7185, GNorm = 0.2686, lr_0 = 1.0000e-04
Loss = 9.2844e-02, PNorm = 38.7060, GNorm = 0.2737, lr_0 = 1.0000e-04
Loss = 9.1840e-02, PNorm = 38.7175, GNorm = 0.2723, lr_0 = 1.0000e-04
Loss = 9.1824e-02, PNorm = 38.7164, GNorm = 0.2657, lr_0 = 1.0000e-04
Loss = 9.2052e-02, PNorm = 38.7210, GNorm = 0.2436, lr_0 = 1.0000e-04
Loss = 9.1678e-02, PNorm = 38.7056, GNorm = 0.2561, lr_0 = 1.0000e-04
Loss = 9.2482e-02, PNorm = 38.7217, GNorm = 0.2891, lr_0 = 1.0000e-04
Validation auc = 0.672784
Validation accuracy = 0.933333
Model 0 best validation auc = 0.692308 on epoch 1
Loss = 9.2860e-02, PNorm = 38.7096, GNorm = 0.2848, lr_0 = 1.0000e-04
Validation auc = 0.677470
Validation accuracy = 0.933333
Model 0 best validation auc = 0.683327 on epoch 1
Validation auc = 0.675908
Validation accuracy = 0.933333
Model 0 best validation auc = 0.692308 on epoch 1
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Validation auc = 0.672784
Validation accuracy = 0.933333
Model 0 best validation auc = 0.692308 on epoch 1
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Validation auc = 0.672003
Validation accuracy = 0.933333
Model 0 best validation auc = 0.689965 on epoch 1
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Validation auc = 0.667317
Validation accuracy = 0.938095
Model 0 best validation auc = 0.713003 on epoch 1
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Validation auc = 0.672003
Validation accuracy = 0.933333
Model 0 best validation auc = 0.691917 on epoch 1
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Model 0 test auc = 0.814966
Model 0 test accuracy = 0.928910
Ensemble test auc = 0.814966
Ensemble test accuracy = 0.928910
Fold 1
Splitting data with seed 43
Model 0 test auc = 0.814966
Model 0 test accuracy = 0.928910
Ensemble test auc = 0.814966
Ensemble test accuracy = 0.928910
Fold 1
Splitting data with seed 43
Model 0 test auc = 0.814966
Model 0 test accuracy = 0.928910
Ensemble test auc = 0.814966
Ensemble test accuracy = 0.928910
Fold 1
Splitting data with seed 43
Model 0 test auc = 0.814966
Model 0 test accuracy = 0.928910
Ensemble test auc = 0.814966
Ensemble test accuracy = 0.928910
Fold 1
Splitting data with seed 43
Validation auc = 0.670832
Validation accuracy = 0.933333
Model 0 best validation auc = 0.681374 on epoch 1
Model 0 test auc = 0.814966
Model 0 test accuracy = 0.928910
Ensemble test auc = 0.814966
Ensemble test accuracy = 0.928910
Fold 1
Splitting data with seed 43
Total scaffolds = 1,035 | train scaffolds = 747 | val scaffolds = 134 | test scaffolds = 154
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 250 | target average = 0.032000


Scaffold 1
Task 0: count = 191 | target average = 0.010471


Scaffold 2
Task 0: count = 43 | target average = 0.000000


Scaffold 3
Task 0: count = 21 | target average = 0.000000


Scaffold 4
Task 0: count = 19 | target average = 0.000000


Scaffold 5
Task 0: count = 18 | target average = 0.000000


Scaffold 6
Task 0: count = 16 | target average = 0.250000


Scaffold 7
Task 0: count = 14 | target average = 0.000000


Scaffold 8
Task 0: count = 13 | target average = 0.076923


Scaffold 9
Task 0: count = 12 | target average = 0.000000


Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Epoch 0
Total scaffolds = 1,035 | train scaffolds = 747 | val scaffolds = 134 | test scaffolds = 154
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 250 | target average = 0.032000


Scaffold 1
Task 0: count = 191 | target average = 0.010471


Scaffold 2
Task 0: count = 43 | target average = 0.000000


Scaffold 3
Task 0: count = 21 | target average = 0.000000


Scaffold 4
Task 0: count = 19 | target average = 0.000000


Scaffold 5
Task 0: count = 18 | target average = 0.000000


Scaffold 6
Task 0: count = 16 | target average = 0.250000


Scaffold 7
Task 0: count = 14 | target average = 0.000000


Scaffold 8
Task 0: count = 13 | target average = 0.076923


Scaffold 9
Task 0: count = 12 | target average = 0.000000


Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Epoch 0
Total scaffolds = 1,035 | train scaffolds = 747 | val scaffolds = 134 | test scaffolds = 154
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 250 | target average = 0.032000


Scaffold 1
Task 0: count = 191 | target average = 0.010471


Scaffold 2
Task 0: count = 43 | target average = 0.000000


Scaffold 3
Task 0: count = 21 | target average = 0.000000


Scaffold 4
Task 0: count = 19 | target average = 0.000000


Scaffold 5
Task 0: count = 18 | target average = 0.000000


Scaffold 6
Task 0: count = 16 | target average = 0.250000


Scaffold 7
Task 0: count = 14 | target average = 0.000000


Scaffold 8
Task 0: count = 13 | target average = 0.076923


Scaffold 9
Task 0: count = 12 | target average = 0.000000


Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
Model 0 test auc = 0.814966
Model 0 test accuracy = 0.928910
Ensemble test auc = 0.814966
Ensemble test accuracy = 0.928910
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Fold 1
Splitting data with seed 43
Total scaffolds = 1,035 | train scaffolds = 747 | val scaffolds = 134 | test scaffolds = 154
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 250 | target average = 0.032000


Scaffold 1
Task 0: count = 191 | target average = 0.010471


Scaffold 2
Task 0: count = 43 | target average = 0.000000


Scaffold 3
Task 0: count = 21 | target average = 0.000000


Scaffold 4
Task 0: count = 19 | target average = 0.000000


Scaffold 5
Task 0: count = 18 | target average = 0.000000


Scaffold 6
Task 0: count = 16 | target average = 0.250000


Scaffold 7
Task 0: count = 14 | target average = 0.000000


Scaffold 8
Task 0: count = 13 | target average = 0.076923


Scaffold 9
Task 0: count = 12 | target average = 0.000000


Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
Epoch 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Epoch 0
Total scaffolds = 1,035 | train scaffolds = 747 | val scaffolds = 134 | test scaffolds = 154
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 250 | target average = 0.032000


Scaffold 1
Task 0: count = 191 | target average = 0.010471


Scaffold 2
Task 0: count = 43 | target average = 0.000000


Scaffold 3
Task 0: count = 21 | target average = 0.000000


Scaffold 4
Task 0: count = 19 | target average = 0.000000


Scaffold 5
Task 0: count = 18 | target average = 0.000000


Scaffold 6
Task 0: count = 16 | target average = 0.250000


Scaffold 7
Task 0: count = 14 | target average = 0.000000


Scaffold 8
Task 0: count = 13 | target average = 0.076923


Scaffold 9
Task 0: count = 12 | target average = 0.000000


Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Epoch 0
Model 0 test auc = 0.814966
Model 0 test accuracy = 0.928910
Ensemble test auc = 0.814966
Ensemble test accuracy = 0.928910
Fold 1
Splitting data with seed 43
Total scaffolds = 1,035 | train scaffolds = 747 | val scaffolds = 134 | test scaffolds = 154
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 250 | target average = 0.032000


Scaffold 1
Task 0: count = 191 | target average = 0.010471


Scaffold 2
Task 0: count = 43 | target average = 0.000000


Scaffold 3
Task 0: count = 21 | target average = 0.000000


Scaffold 4
Task 0: count = 19 | target average = 0.000000


Scaffold 5
Task 0: count = 18 | target average = 0.000000


Scaffold 6
Task 0: count = 16 | target average = 0.250000


Scaffold 7
Task 0: count = 14 | target average = 0.000000


Scaffold 8
Task 0: count = 13 | target average = 0.076923


Scaffold 9
Task 0: count = 12 | target average = 0.000000


Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Epoch 0
Total scaffolds = 1,035 | train scaffolds = 747 | val scaffolds = 134 | test scaffolds = 154
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 250 | target average = 0.032000


Scaffold 1
Task 0: count = 191 | target average = 0.010471


Scaffold 2
Task 0: count = 43 | target average = 0.000000


Scaffold 3
Task 0: count = 21 | target average = 0.000000


Scaffold 4
Task 0: count = 19 | target average = 0.000000


Scaffold 5
Task 0: count = 18 | target average = 0.000000


Scaffold 6
Task 0: count = 16 | target average = 0.250000


Scaffold 7
Task 0: count = 14 | target average = 0.000000


Scaffold 8
Task 0: count = 13 | target average = 0.076923


Scaffold 9
Task 0: count = 12 | target average = 0.000000


Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Model 0 test auc = 0.814966
Model 0 test accuracy = 0.928910
Ensemble test auc = 0.814966
Ensemble test accuracy = 0.928910
Fold 1
Splitting data with seed 43
Epoch 0
Total scaffolds = 1,035 | train scaffolds = 747 | val scaffolds = 134 | test scaffolds = 154
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 250 | target average = 0.032000


Scaffold 1
Task 0: count = 191 | target average = 0.010471


Scaffold 2
Task 0: count = 43 | target average = 0.000000


Scaffold 3
Task 0: count = 21 | target average = 0.000000


Scaffold 4
Task 0: count = 19 | target average = 0.000000


Scaffold 5
Task 0: count = 18 | target average = 0.000000


Scaffold 6
Task 0: count = 16 | target average = 0.250000


Scaffold 7
Task 0: count = 14 | target average = 0.000000


Scaffold 8
Task 0: count = 13 | target average = 0.076923


Scaffold 9
Task 0: count = 12 | target average = 0.000000


Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Epoch 0
Loss = 4.3523e-01, PNorm = 38.1785, GNorm = 0.5450, lr_0 = 2.5000e-04
Loss = 4.3523e-01, PNorm = 38.1785, GNorm = 0.5450, lr_0 = 2.5000e-04
Loss = 4.3523e-01, PNorm = 38.1785, GNorm = 0.5450, lr_0 = 2.5000e-04
Loss = 4.3523e-01, PNorm = 38.1785, GNorm = 0.5450, lr_0 = 2.5000e-04
Loss = 4.3523e-01, PNorm = 38.1785, GNorm = 0.5450, lr_0 = 2.5000e-04
Loss = 4.3523e-01, PNorm = 38.1785, GNorm = 0.5450, lr_0 = 2.5000e-04
Loss = 4.3523e-01, PNorm = 38.1785, GNorm = 0.5450, lr_0 = 2.5000e-04
Loss = 4.3523e-01, PNorm = 38.1785, GNorm = 0.5450, lr_0 = 2.5000e-04
Loss = 2.0186e-01, PNorm = 38.1905, GNorm = 2.1942, lr_0 = 3.8636e-04
Loss = 2.0186e-01, PNorm = 38.1905, GNorm = 2.1942, lr_0 = 3.8636e-04
Loss = 2.0186e-01, PNorm = 38.1905, GNorm = 2.1942, lr_0 = 3.8636e-04
Loss = 2.0186e-01, PNorm = 38.1905, GNorm = 2.1942, lr_0 = 3.8636e-04
Loss = 2.0186e-01, PNorm = 38.1905, GNorm = 2.1942, lr_0 = 3.8636e-04
Loss = 2.0186e-01, PNorm = 38.1905, GNorm = 2.1942, lr_0 = 3.8636e-04
Loss = 2.0186e-01, PNorm = 38.1905, GNorm = 2.1942, lr_0 = 3.8636e-04
Loss = 2.0186e-01, PNorm = 38.1905, GNorm = 2.1942, lr_0 = 3.8636e-04
Loss = 2.1699e-01, PNorm = 38.1926, GNorm = 1.0000, lr_0 = 5.2273e-04
Loss = 2.1699e-01, PNorm = 38.1926, GNorm = 1.0000, lr_0 = 5.2273e-04
Loss = 2.1699e-01, PNorm = 38.1926, GNorm = 1.0000, lr_0 = 5.2273e-04
Loss = 2.1699e-01, PNorm = 38.1926, GNorm = 1.0000, lr_0 = 5.2273e-04
Loss = 2.1699e-01, PNorm = 38.1926, GNorm = 1.0000, lr_0 = 5.2273e-04
Loss = 2.1699e-01, PNorm = 38.1926, GNorm = 1.0000, lr_0 = 5.2273e-04
Loss = 2.1699e-01, PNorm = 38.1926, GNorm = 1.0000, lr_0 = 5.2273e-04
Validation auc = 0.444444
Validation accuracy = 0.885714
Validation auc = 0.444444
Validation accuracy = 0.885714
Epoch 1
Epoch 1
Loss = 2.1699e-01, PNorm = 38.1926, GNorm = 1.0000, lr_0 = 5.2273e-04
Validation auc = 0.444444
Validation accuracy = 0.885714
Epoch 1
Validation auc = 0.444444
Validation accuracy = 0.885714
Validation auc = 0.444444
Validation accuracy = 0.885714
Epoch 1
Epoch 1
Validation auc = 0.444444
Validation accuracy = 0.885714
Epoch 1
Validation auc = 0.444444
Validation accuracy = 0.885714
Epoch 1
Validation auc = 0.444444
Validation accuracy = 0.885714
Epoch 1
Loss = 1.6795e-01, PNorm = 38.2140, GNorm = 0.3798, lr_0 = 6.7273e-04
Loss = 1.6795e-01, PNorm = 38.2140, GNorm = 0.3797, lr_0 = 6.7273e-04
Loss = 1.6795e-01, PNorm = 38.2140, GNorm = 0.3798, lr_0 = 6.7273e-04
Loss = 1.6795e-01, PNorm = 38.2140, GNorm = 0.3797, lr_0 = 6.7273e-04
Loss = 1.6795e-01, PNorm = 38.2140, GNorm = 0.3797, lr_0 = 6.7273e-04
Loss = 1.6795e-01, PNorm = 38.2140, GNorm = 0.3798, lr_0 = 6.7273e-04
Loss = 1.6795e-01, PNorm = 38.2140, GNorm = 0.3798, lr_0 = 6.7273e-04
Loss = 1.6795e-01, PNorm = 38.2140, GNorm = 0.3797, lr_0 = 6.7273e-04
Loss = 2.1891e-01, PNorm = 38.2233, GNorm = 0.5065, lr_0 = 8.0909e-04
Loss = 2.1892e-01, PNorm = 38.2233, GNorm = 0.5038, lr_0 = 8.0909e-04
Loss = 2.1892e-01, PNorm = 38.2233, GNorm = 0.5038, lr_0 = 8.0909e-04
Loss = 2.1891e-01, PNorm = 38.2233, GNorm = 0.5065, lr_0 = 8.0909e-04
Loss = 2.1891e-01, PNorm = 38.2233, GNorm = 0.5065, lr_0 = 8.0909e-04
Loss = 2.1892e-01, PNorm = 38.2233, GNorm = 0.5037, lr_0 = 8.0909e-04
Loss = 2.1892e-01, PNorm = 38.2233, GNorm = 0.5037, lr_0 = 8.0909e-04
Loss = 2.1889e-01, PNorm = 38.2233, GNorm = 0.5057, lr_0 = 8.0909e-04
Loss = 1.5534e-01, PNorm = 38.2516, GNorm = 0.3228, lr_0 = 9.4545e-04
Loss = 1.5528e-01, PNorm = 38.2513, GNorm = 0.3193, lr_0 = 9.4545e-04
Loss = 1.5533e-01, PNorm = 38.2513, GNorm = 0.3217, lr_0 = 9.4545e-04
Loss = 1.5534e-01, PNorm = 38.2516, GNorm = 0.3228, lr_0 = 9.4545e-04
Loss = 1.5533e-01, PNorm = 38.2513, GNorm = 0.3217, lr_0 = 9.4545e-04
Loss = 1.5534e-01, PNorm = 38.2516, GNorm = 0.3228, lr_0 = 9.4545e-04
Loss = 1.5533e-01, PNorm = 38.2513, GNorm = 0.3217, lr_0 = 9.4545e-04
Loss = 1.5533e-01, PNorm = 38.2516, GNorm = 0.3158, lr_0 = 9.4545e-04
Validation auc = 0.752240
Validation accuracy = 0.885714
Epoch 2
Validation auc = 0.753136
Validation accuracy = 0.885714
Epoch 2
Validation auc = 0.752016
Validation accuracy = 0.885714
Validation auc = 0.752688
Validation accuracy = 0.885714
Epoch 2
Epoch 2
Validation auc = 0.752688
Validation accuracy = 0.885714
Epoch 2
Validation auc = 0.752912
Validation accuracy = 0.885714
Epoch 2
Loss = 1.3329e-01, PNorm = 38.2710, GNorm = 0.1972, lr_0 = 9.4901e-04
Loss = 1.3413e-01, PNorm = 38.2695, GNorm = 0.2087, lr_0 = 9.4901e-04
Validation auc = 0.752688
Validation accuracy = 0.885714
Loss = 1.3423e-01, PNorm = 38.2696, GNorm = 0.2096, lr_0 = 9.4901e-04
Epoch 2
Loss = 1.3327e-01, PNorm = 38.2710, GNorm = 0.1974, lr_0 = 9.4901e-04
Loss = 1.3425e-01, PNorm = 38.2695, GNorm = 0.2108, lr_0 = 9.4901e-04
Loss = 1.3320e-01, PNorm = 38.2710, GNorm = 0.1953, lr_0 = 9.4901e-04
Validation auc = 0.750000
Validation accuracy = 0.885714
Epoch 2
Loss = 1.3425e-01, PNorm = 38.2695, GNorm = 0.2108, lr_0 = 9.4901e-04
Loss = 1.3367e-01, PNorm = 38.2708, GNorm = 0.2053, lr_0 = 9.4901e-04
Loss = 1.6660e-01, PNorm = 38.2944, GNorm = 0.2657, lr_0 = 8.6975e-04
Loss = 1.6705e-01, PNorm = 38.2930, GNorm = 0.2685, lr_0 = 8.6975e-04
Loss = 1.6715e-01, PNorm = 38.2937, GNorm = 0.2660, lr_0 = 8.6975e-04
Loss = 1.6661e-01, PNorm = 38.2943, GNorm = 0.2646, lr_0 = 8.6975e-04
Loss = 1.6706e-01, PNorm = 38.2935, GNorm = 0.2672, lr_0 = 8.6975e-04
Loss = 1.6669e-01, PNorm = 38.2943, GNorm = 0.2662, lr_0 = 8.6975e-04
Loss = 1.6706e-01, PNorm = 38.2935, GNorm = 0.2672, lr_0 = 8.6975e-04
Loss = 1.6672e-01, PNorm = 38.2944, GNorm = 0.2697, lr_0 = 8.6975e-04
Loss = 2.1043e-01, PNorm = 38.3209, GNorm = 0.3050, lr_0 = 7.9710e-04
Loss = 2.1033e-01, PNorm = 38.3186, GNorm = 0.2630, lr_0 = 7.9710e-04
Loss = 2.1056e-01, PNorm = 38.3197, GNorm = 0.2726, lr_0 = 7.9710e-04
Loss = 2.1039e-01, PNorm = 38.3211, GNorm = 0.2972, lr_0 = 7.9710e-04
Loss = 2.1041e-01, PNorm = 38.3191, GNorm = 0.2717, lr_0 = 7.9710e-04
Loss = 2.1060e-01, PNorm = 38.3208, GNorm = 0.2988, lr_0 = 7.9710e-04
Loss = 2.1040e-01, PNorm = 38.3191, GNorm = 0.2709, lr_0 = 7.9710e-04
Loss = 2.1044e-01, PNorm = 38.3209, GNorm = 0.2726, lr_0 = 7.9710e-04
Loss = 1.6618e-01, PNorm = 38.3435, GNorm = 0.2548, lr_0 = 7.3053e-04
Loss = 4.0352e-02, PNorm = 38.3463, GNorm = 0.4522, lr_0 = 7.2418e-04
Loss = 1.6643e-01, PNorm = 38.3417, GNorm = 0.2475, lr_0 = 7.3053e-04
Loss = 1.6679e-01, PNorm = 38.3416, GNorm = 0.2598, lr_0 = 7.3053e-04
Loss = 1.6608e-01, PNorm = 38.3430, GNorm = 0.2549, lr_0 = 7.3053e-04
Loss = 1.6606e-01, PNorm = 38.3448, GNorm = 0.2532, lr_0 = 7.3053e-04
Loss = 3.9844e-02, PNorm = 38.3443, GNorm = 0.4442, lr_0 = 7.2418e-04
Loss = 4.1024e-02, PNorm = 38.3441, GNorm = 0.4635, lr_0 = 7.2418e-04
Loss = 1.6679e-01, PNorm = 38.3412, GNorm = 0.2548, lr_0 = 7.3053e-04
Loss = 4.0719e-02, PNorm = 38.3457, GNorm = 0.4568, lr_0 = 7.2418e-04
Loss = 4.1105e-02, PNorm = 38.3476, GNorm = 0.4570, lr_0 = 7.2418e-04
Validation auc = 0.840726
Validation accuracy = 0.885714
Loss = 4.0887e-02, PNorm = 38.3438, GNorm = 0.4554, lr_0 = 7.2418e-04
Epoch 3
Validation auc = 0.841622
Validation accuracy = 0.885714
Validation auc = 0.838934
Validation accuracy = 0.885714
Validation auc = 0.840502
Validation accuracy = 0.885714
Epoch 3
Epoch 3
Epoch 3
Loss = 1.6677e-01, PNorm = 38.3413, GNorm = 0.2548, lr_0 = 7.3053e-04
Validation auc = 0.842070
Validation accuracy = 0.885714
Epoch 3
Validation auc = 0.843638
Validation accuracy = 0.885714
Loss = 4.0831e-02, PNorm = 38.3438, GNorm = 0.4541, lr_0 = 7.2418e-04
Epoch 3
Loss = 1.6620e-01, PNorm = 38.3449, GNorm = 0.2505, lr_0 = 7.3053e-04
Loss = 4.0645e-02, PNorm = 38.3476, GNorm = 0.4528, lr_0 = 7.2418e-04
Validation auc = 0.845430
Validation accuracy = 0.885714
Epoch 3
Validation auc = 0.846774
Validation accuracy = 0.885714
Epoch 3
Loss = 1.6047e-01, PNorm = 38.3653, GNorm = 0.6288, lr_0 = 6.6370e-04
Loss = 1.6079e-01, PNorm = 38.3646, GNorm = 0.6425, lr_0 = 6.6370e-04
Loss = 1.6042e-01, PNorm = 38.3621, GNorm = 0.6405, lr_0 = 6.6370e-04
Loss = 1.6029e-01, PNorm = 38.3639, GNorm = 0.6289, lr_0 = 6.6370e-04
Loss = 1.6010e-01, PNorm = 38.3684, GNorm = 0.6323, lr_0 = 6.6370e-04
Loss = 1.6018e-01, PNorm = 38.3627, GNorm = 0.6251, lr_0 = 6.6370e-04
Loss = 1.6017e-01, PNorm = 38.3624, GNorm = 0.6247, lr_0 = 6.6370e-04
Loss = 1.6055e-01, PNorm = 38.3673, GNorm = 0.6420, lr_0 = 6.6370e-04
Loss = 1.6340e-01, PNorm = 38.3920, GNorm = 0.2200, lr_0 = 6.0826e-04
Loss = 1.6270e-01, PNorm = 38.3912, GNorm = 0.2156, lr_0 = 6.0826e-04
Loss = 1.6351e-01, PNorm = 38.3874, GNorm = 0.2271, lr_0 = 6.0826e-04
Loss = 1.6266e-01, PNorm = 38.3917, GNorm = 0.2122, lr_0 = 6.0826e-04
Loss = 1.6346e-01, PNorm = 38.3956, GNorm = 0.2149, lr_0 = 6.0826e-04
Loss = 1.6273e-01, PNorm = 38.3889, GNorm = 0.2281, lr_0 = 6.0826e-04
Loss = 1.6299e-01, PNorm = 38.3881, GNorm = 0.2309, lr_0 = 6.0826e-04
Loss = 1.6190e-01, PNorm = 38.3955, GNorm = 0.2159, lr_0 = 6.0826e-04
Loss = 1.8227e-01, PNorm = 38.4154, GNorm = 0.3368, lr_0 = 5.5746e-04
Loss = 1.8225e-01, PNorm = 38.4140, GNorm = 0.3230, lr_0 = 5.5746e-04
Loss = 1.8267e-01, PNorm = 38.4153, GNorm = 0.3331, lr_0 = 5.5746e-04
Loss = 1.8222e-01, PNorm = 38.4100, GNorm = 0.3083, lr_0 = 5.5746e-04
Loss = 1.8280e-01, PNorm = 38.4188, GNorm = 0.3310, lr_0 = 5.5746e-04
Loss = 1.8224e-01, PNorm = 38.4113, GNorm = 0.3164, lr_0 = 5.5746e-04
Loss = 1.8211e-01, PNorm = 38.4105, GNorm = 0.3162, lr_0 = 5.5746e-04
Loss = 1.8205e-01, PNorm = 38.4199, GNorm = 0.3341, lr_0 = 5.5746e-04
Validation auc = 0.837142
Validation accuracy = 0.885714
Epoch 4
Validation auc = 0.849462
Validation accuracy = 0.885714
Epoch 4
Validation auc = 0.845430
Validation accuracy = 0.885714
Validation auc = 0.840502
Validation accuracy = 0.885714
Epoch 4
Epoch 4
Validation auc = 0.831989
Validation accuracy = 0.885714
Epoch 4
Validation auc = 0.852823
Validation accuracy = 0.885714
Epoch 4
Validation auc = 0.854391
Validation accuracy = 0.885714
Epoch 4
Validation auc = 0.844310
Validation accuracy = 0.885714
Epoch 4
Loss = 1.3067e-01, PNorm = 38.4415, GNorm = 0.2960, lr_0 = 5.1090e-04
Loss = 1.3004e-01, PNorm = 38.4423, GNorm = 0.2900, lr_0 = 5.1090e-04
Loss = 1.3054e-01, PNorm = 38.4365, GNorm = 0.2857, lr_0 = 5.1090e-04
Loss = 1.3078e-01, PNorm = 38.4465, GNorm = 0.2800, lr_0 = 5.1090e-04
Loss = 1.3104e-01, PNorm = 38.4408, GNorm = 0.2858, lr_0 = 5.1090e-04
Loss = 1.3120e-01, PNorm = 38.4377, GNorm = 0.3078, lr_0 = 5.1090e-04
Loss = 1.3136e-01, PNorm = 38.4367, GNorm = 0.3058, lr_0 = 5.1090e-04
Loss = 1.3091e-01, PNorm = 38.4491, GNorm = 0.2873, lr_0 = 5.1090e-04
Loss = 1.6521e-01, PNorm = 38.4636, GNorm = 0.3370, lr_0 = 4.6822e-04
Loss = 1.6578e-01, PNorm = 38.4642, GNorm = 0.3485, lr_0 = 4.6822e-04
Loss = 1.6628e-01, PNorm = 38.4576, GNorm = 0.3309, lr_0 = 4.6822e-04
Loss = 1.6652e-01, PNorm = 38.4621, GNorm = 0.3393, lr_0 = 4.6822e-04
Loss = 1.6569e-01, PNorm = 38.4689, GNorm = 0.3481, lr_0 = 4.6822e-04
Loss = 1.6592e-01, PNorm = 38.4591, GNorm = 0.3193, lr_0 = 4.6822e-04
Loss = 1.6620e-01, PNorm = 38.4578, GNorm = 0.3269, lr_0 = 4.6822e-04
Loss = 1.6625e-01, PNorm = 38.4717, GNorm = 0.3598, lr_0 = 4.6822e-04
Loss = 1.7829e-01, PNorm = 38.4842, GNorm = 0.5231, lr_0 = 4.2912e-04
Loss = 1.7826e-01, PNorm = 38.4842, GNorm = 0.5110, lr_0 = 4.2912e-04
Loss = 1.7771e-01, PNorm = 38.4785, GNorm = 0.5047, lr_0 = 4.2912e-04
Loss = 1.7799e-01, PNorm = 38.4833, GNorm = 0.5291, lr_0 = 4.2912e-04
Loss = 1.7777e-01, PNorm = 38.4901, GNorm = 0.5169, lr_0 = 4.2912e-04
Loss = 1.7791e-01, PNorm = 38.4805, GNorm = 0.5176, lr_0 = 4.2912e-04
Loss = 1.7781e-01, PNorm = 38.4793, GNorm = 0.5408, lr_0 = 4.2912e-04
Loss = 1.7811e-01, PNorm = 38.4927, GNorm = 0.5025, lr_0 = 4.2912e-04
Validation auc = 0.849910
Validation accuracy = 0.885714
Epoch 5
Validation auc = 0.850134
Validation accuracy = 0.885714
Validation auc = 0.849238
Validation accuracy = 0.885714
Validation auc = 0.849686
Validation accuracy = 0.885714
Epoch 5
Epoch 5
Epoch 5
Validation auc = 0.846998
Validation accuracy = 0.885714
Epoch 5
Validation auc = 0.847894
Validation accuracy = 0.885714
Loss = 1.3837e-01, PNorm = 38.5077, GNorm = 0.2899, lr_0 = 3.9328e-04
Epoch 5
Loss = 1.3842e-01, PNorm = 38.5074, GNorm = 0.2618, lr_0 = 3.9328e-04
Loss = 1.3882e-01, PNorm = 38.5080, GNorm = 0.2876, lr_0 = 3.9328e-04
Loss = 1.4045e-01, PNorm = 38.5027, GNorm = 0.3086, lr_0 = 3.9328e-04
Loss = 1.3958e-01, PNorm = 38.5049, GNorm = 0.2967, lr_0 = 3.9328e-04
Validation auc = 0.847670
Validation accuracy = 0.885714
Epoch 5
Loss = 1.3845e-01, PNorm = 38.5136, GNorm = 0.2632, lr_0 = 3.9328e-04
Validation auc = 0.851030
Validation accuracy = 0.885714
Epoch 5
Loss = 1.3941e-01, PNorm = 38.5036, GNorm = 0.2974, lr_0 = 3.9328e-04
Loss = 1.3904e-01, PNorm = 38.5167, GNorm = 0.2721, lr_0 = 3.9328e-04
Loss = 1.3790e-01, PNorm = 38.5247, GNorm = 0.3953, lr_0 = 3.6043e-04
Loss = 1.3800e-01, PNorm = 38.5250, GNorm = 0.3913, lr_0 = 3.6043e-04
Loss = 1.3830e-01, PNorm = 38.5254, GNorm = 0.4186, lr_0 = 3.6043e-04
Loss = 1.3829e-01, PNorm = 38.5202, GNorm = 0.4151, lr_0 = 3.6043e-04
Loss = 1.3774e-01, PNorm = 38.5220, GNorm = 0.4186, lr_0 = 3.6043e-04
Loss = 1.3856e-01, PNorm = 38.5325, GNorm = 0.3788, lr_0 = 3.6043e-04
Loss = 1.3786e-01, PNorm = 38.5207, GNorm = 0.4057, lr_0 = 3.6043e-04
Loss = 1.3885e-01, PNorm = 38.5351, GNorm = 0.4037, lr_0 = 3.6043e-04
Loss = 1.5215e-01, PNorm = 38.5470, GNorm = 0.4167, lr_0 = 3.3032e-04
Loss = 1.5209e-01, PNorm = 38.5477, GNorm = 0.4159, lr_0 = 3.3032e-04
Loss = 1.5201e-01, PNorm = 38.5493, GNorm = 0.3860, lr_0 = 3.3032e-04
Loss = 1.5241e-01, PNorm = 38.5440, GNorm = 0.4101, lr_0 = 3.3032e-04
Loss = 1.5265e-01, PNorm = 38.5439, GNorm = 0.4237, lr_0 = 3.3032e-04
Loss = 1.5145e-01, PNorm = 38.5564, GNorm = 0.4209, lr_0 = 3.3032e-04
Loss = 1.5251e-01, PNorm = 38.5431, GNorm = 0.4303, lr_0 = 3.3032e-04
Loss = 1.5200e-01, PNorm = 38.5586, GNorm = 0.4098, lr_0 = 3.3032e-04
Loss = 1.7567e-01, PNorm = 38.5608, GNorm = 0.4071, lr_0 = 3.0273e-04
Loss = 1.7646e-01, PNorm = 38.5615, GNorm = 0.4134, lr_0 = 3.0273e-04
Loss = 1.7549e-01, PNorm = 38.5585, GNorm = 0.3981, lr_0 = 3.0273e-04
Loss = 1.7452e-01, PNorm = 38.5624, GNorm = 0.3584, lr_0 = 3.0273e-04
Loss = 1.7436e-01, PNorm = 38.5715, GNorm = 0.3865, lr_0 = 3.0273e-04
Loss = 1.7568e-01, PNorm = 38.5582, GNorm = 0.3897, lr_0 = 3.0273e-04
Validation auc = 0.859319
Validation accuracy = 0.885714
Validation auc = 0.862231
Validation accuracy = 0.885714
Loss = 1.7708e-01, PNorm = 38.5574, GNorm = 0.4081, lr_0 = 3.0273e-04
Epoch 6
Epoch 6
Validation auc = 0.861111
Validation accuracy = 0.885714
Epoch 6
Validation auc = 0.860439
Validation accuracy = 0.885714
Loss = 1.7407e-01, PNorm = 38.5722, GNorm = 0.3999, lr_0 = 3.0273e-04
Validation auc = 0.858647
Validation accuracy = 0.885714
Epoch 6
Validation auc = 0.862007
Validation accuracy = 0.885714
Epoch 6
Epoch 6
Validation auc = 0.862455
Validation accuracy = 0.885714
Epoch 6
Validation auc = 0.861335
Validation accuracy = 0.885714
Epoch 6
Loss = 1.1241e-01, PNorm = 38.5769, GNorm = 0.4360, lr_0 = 2.7504e-04
Loss = 1.1250e-01, PNorm = 38.5764, GNorm = 0.4457, lr_0 = 2.7504e-04
Loss = 1.1254e-01, PNorm = 38.5740, GNorm = 0.4578, lr_0 = 2.7504e-04
Loss = 1.1174e-01, PNorm = 38.5727, GNorm = 0.4669, lr_0 = 2.7504e-04
Loss = 1.1205e-01, PNorm = 38.5787, GNorm = 0.4716, lr_0 = 2.7504e-04
Loss = 1.1202e-01, PNorm = 38.5887, GNorm = 0.4471, lr_0 = 2.7504e-04
Loss = 1.1202e-01, PNorm = 38.5732, GNorm = 0.4711, lr_0 = 2.7504e-04
Loss = 1.1164e-01, PNorm = 38.5875, GNorm = 0.4510, lr_0 = 2.7504e-04
Loss = 1.2997e-01, PNorm = 38.5901, GNorm = 0.1681, lr_0 = 2.5207e-04
Loss = 1.2982e-01, PNorm = 38.5888, GNorm = 0.1696, lr_0 = 2.5207e-04
Loss = 1.2967e-01, PNorm = 38.5871, GNorm = 0.1669, lr_0 = 2.5207e-04
Loss = 1.3029e-01, PNorm = 38.5850, GNorm = 0.1758, lr_0 = 2.5207e-04
Loss = 1.2996e-01, PNorm = 38.5909, GNorm = 0.1745, lr_0 = 2.5207e-04
Loss = 1.2950e-01, PNorm = 38.6018, GNorm = 0.1715, lr_0 = 2.5207e-04
Loss = 1.2984e-01, PNorm = 38.5859, GNorm = 0.1863, lr_0 = 2.5207e-04
Loss = 1.2951e-01, PNorm = 38.5997, GNorm = 0.1695, lr_0 = 2.5207e-04
Loss = 1.9910e-01, PNorm = 38.6016, GNorm = 0.3970, lr_0 = 2.3101e-04
Loss = 1.9930e-01, PNorm = 38.5998, GNorm = 0.4045, lr_0 = 2.3101e-04
Loss = 1.9924e-01, PNorm = 38.5989, GNorm = 0.3952, lr_0 = 2.3101e-04
Loss = 1.9846e-01, PNorm = 38.6030, GNorm = 0.4287, lr_0 = 2.3101e-04
Loss = 1.9910e-01, PNorm = 38.6139, GNorm = 0.4307, lr_0 = 2.3101e-04
Loss = 1.9943e-01, PNorm = 38.5967, GNorm = 0.4004, lr_0 = 2.3101e-04
Loss = 1.9978e-01, PNorm = 38.5981, GNorm = 0.4432, lr_0 = 2.3101e-04
Loss = 1.9853e-01, PNorm = 38.6108, GNorm = 0.4105, lr_0 = 2.3101e-04
Validation auc = 0.843414
Validation accuracy = 0.885714
Epoch 7
Validation auc = 0.840726
Validation accuracy = 0.885714
Epoch 7
Validation auc = 0.839830
Validation accuracy = 0.885714
Epoch 7
Validation auc = 0.843638
Validation accuracy = 0.885714
Epoch 7
Validation auc = 0.834901
Validation accuracy = 0.885714
Epoch 7
Validation auc = 0.839158
Validation accuracy = 0.885714
Epoch 7
Loss = 1.2160e-01, PNorm = 38.6219, GNorm = 0.3207, lr_0 = 2.1172e-04
Validation auc = 0.845206
Validation accuracy = 0.885714
Epoch 7
Loss = 1.2163e-01, PNorm = 38.6191, GNorm = 0.3170, lr_0 = 2.1172e-04
Validation auc = 0.836694
Validation accuracy = 0.885714
Epoch 7
Loss = 1.2183e-01, PNorm = 38.6193, GNorm = 0.3123, lr_0 = 2.1172e-04
Loss = 1.2181e-01, PNorm = 38.6235, GNorm = 0.3343, lr_0 = 2.1172e-04
Loss = 1.2253e-01, PNorm = 38.6346, GNorm = 0.3220, lr_0 = 2.1172e-04
Loss = 1.2200e-01, PNorm = 38.6166, GNorm = 0.3088, lr_0 = 2.1172e-04
Loss = 1.2096e-01, PNorm = 38.6180, GNorm = 0.3043, lr_0 = 2.1172e-04
Loss = 1.2241e-01, PNorm = 38.6306, GNorm = 0.3104, lr_0 = 2.1172e-04
Loss = 1.6734e-01, PNorm = 38.6264, GNorm = 0.4904, lr_0 = 1.9403e-04
Loss = 1.6635e-01, PNorm = 38.6249, GNorm = 0.4763, lr_0 = 1.9403e-04
Loss = 1.6625e-01, PNorm = 38.6237, GNorm = 0.4740, lr_0 = 1.9403e-04
Loss = 1.6598e-01, PNorm = 38.6398, GNorm = 0.4721, lr_0 = 1.9403e-04
Loss = 1.6635e-01, PNorm = 38.6286, GNorm = 0.5186, lr_0 = 1.9403e-04
Loss = 1.6571e-01, PNorm = 38.6220, GNorm = 0.5025, lr_0 = 1.9403e-04
Loss = 1.6621e-01, PNorm = 38.6235, GNorm = 0.5274, lr_0 = 1.9403e-04
Loss = 1.6635e-01, PNorm = 38.6353, GNorm = 0.5134, lr_0 = 1.9403e-04
Loss = 1.4393e-01, PNorm = 38.6398, GNorm = 0.3744, lr_0 = 1.7783e-04
Loss = 1.4355e-01, PNorm = 38.6386, GNorm = 0.3727, lr_0 = 1.7783e-04
Loss = 1.4428e-01, PNorm = 38.6367, GNorm = 0.3739, lr_0 = 1.7783e-04
Loss = 1.4422e-01, PNorm = 38.6531, GNorm = 0.3682, lr_0 = 1.7783e-04
Loss = 1.4324e-01, PNorm = 38.6427, GNorm = 0.3677, lr_0 = 1.7783e-04
Loss = 1.4380e-01, PNorm = 38.6356, GNorm = 0.3759, lr_0 = 1.7783e-04
Loss = 1.4373e-01, PNorm = 38.6377, GNorm = 0.3740, lr_0 = 1.7783e-04
Loss = 1.4445e-01, PNorm = 38.6490, GNorm = 0.3725, lr_0 = 1.7783e-04
Validation auc = 0.873656
Validation accuracy = 0.885714
Epoch 8
Validation auc = 0.871864
Validation accuracy = 0.885714
Epoch 8
Validation auc = 0.872536
Validation accuracy = 0.885714
Epoch 8
Validation auc = 0.871640
Validation accuracy = 0.885714
Validation auc = 0.872760
Validation accuracy = 0.885714
Epoch 8
Epoch 8
Loss = 8.7017e-02, PNorm = 38.6537, GNorm = 0.2070, lr_0 = 1.6156e-04
Validation auc = 0.871864
Validation accuracy = 0.885714
Loss = 8.6309e-02, PNorm = 38.6531, GNorm = 0.2137, lr_0 = 1.6156e-04
Loss = 8.6495e-02, PNorm = 38.6505, GNorm = 0.1943, lr_0 = 1.6156e-04
Epoch 8
Validation auc = 0.877240
Validation accuracy = 0.885714
Epoch 8
Loss = 8.5944e-02, PNorm = 38.6675, GNorm = 0.2164, lr_0 = 1.6156e-04
Loss = 8.6375e-02, PNorm = 38.6573, GNorm = 0.2197, lr_0 = 1.6156e-04
Validation auc = 0.872088
Validation accuracy = 0.885714
Loss = 8.6060e-02, PNorm = 38.6494, GNorm = 0.2068, lr_0 = 1.6156e-04
Epoch 8
Loss = 8.6795e-02, PNorm = 38.6519, GNorm = 0.2052, lr_0 = 1.6156e-04
Loss = 8.5425e-02, PNorm = 38.6632, GNorm = 0.1927, lr_0 = 1.6156e-04
Loss = 1.5593e-01, PNorm = 38.6616, GNorm = 0.5359, lr_0 = 1.4807e-04
Loss = 1.5539e-01, PNorm = 38.6611, GNorm = 0.5485, lr_0 = 1.4807e-04
Loss = 1.5571e-01, PNorm = 38.6585, GNorm = 0.5476, lr_0 = 1.4807e-04
Loss = 1.5507e-01, PNorm = 38.6653, GNorm = 0.5467, lr_0 = 1.4807e-04
Loss = 1.5566e-01, PNorm = 38.6756, GNorm = 0.5344, lr_0 = 1.4807e-04
Loss = 1.5517e-01, PNorm = 38.6601, GNorm = 0.5771, lr_0 = 1.4807e-04
Loss = 1.5521e-01, PNorm = 38.6573, GNorm = 0.5544, lr_0 = 1.4807e-04
Loss = 1.5537e-01, PNorm = 38.6711, GNorm = 0.5248, lr_0 = 1.4807e-04
Loss = 1.4259e-01, PNorm = 38.6741, GNorm = 0.7357, lr_0 = 1.3570e-04
Loss = 1.4261e-01, PNorm = 38.6736, GNorm = 0.7170, lr_0 = 1.3570e-04
Loss = 1.4236e-01, PNorm = 38.6710, GNorm = 0.7339, lr_0 = 1.3570e-04
Loss = 1.4221e-01, PNorm = 38.6783, GNorm = 0.7585, lr_0 = 1.3570e-04
Loss = 1.4228e-01, PNorm = 38.6884, GNorm = 0.7083, lr_0 = 1.3570e-04
Loss = 1.4239e-01, PNorm = 38.6727, GNorm = 0.8015, lr_0 = 1.3570e-04
Loss = 1.4170e-01, PNorm = 38.6699, GNorm = 0.7622, lr_0 = 1.3570e-04
Loss = 1.4152e-01, PNorm = 38.6835, GNorm = 0.6934, lr_0 = 1.3570e-04
Loss = 1.2885e-01, PNorm = 38.6816, GNorm = 0.6581, lr_0 = 1.2436e-04
Loss = 1.2916e-01, PNorm = 38.6813, GNorm = 0.7292, lr_0 = 1.2436e-04
Loss = 1.2849e-01, PNorm = 38.6861, GNorm = 0.6745, lr_0 = 1.2436e-04
Loss = 1.2921e-01, PNorm = 38.6783, GNorm = 0.6608, lr_0 = 1.2436e-04
Loss = 1.2920e-01, PNorm = 38.6963, GNorm = 0.7292, lr_0 = 1.2436e-04
Validation auc = 0.861335
Validation accuracy = 0.885714
Epoch 9
Validation auc = 0.859767
Validation accuracy = 0.885714
Epoch 9
Loss = 1.2802e-01, PNorm = 38.6802, GNorm = 0.6532, lr_0 = 1.2436e-04
Loss = 1.2826e-01, PNorm = 38.6776, GNorm = 0.6819, lr_0 = 1.2436e-04
Validation auc = 0.862679
Validation accuracy = 0.885714
Epoch 9
Validation auc = 0.860887
Validation accuracy = 0.885714
Epoch 9
Validation auc = 0.859543
Validation accuracy = 0.885714
Epoch 9
Loss = 1.2939e-01, PNorm = 38.6911, GNorm = 0.6746, lr_0 = 1.2436e-04
Validation auc = 0.862679
Validation accuracy = 0.885714
Epoch 9
Validation auc = 0.863799
Validation accuracy = 0.885714
Epoch 9
Validation auc = 0.863575
Validation accuracy = 0.885714
Epoch 9
Loss = 1.4485e-01, PNorm = 38.6901, GNorm = 0.6650, lr_0 = 1.1398e-04
Loss = 1.4460e-01, PNorm = 38.6901, GNorm = 0.6796, lr_0 = 1.1398e-04
Loss = 1.4384e-01, PNorm = 38.6951, GNorm = 0.6673, lr_0 = 1.1398e-04
Loss = 1.4448e-01, PNorm = 38.6867, GNorm = 0.6623, lr_0 = 1.1398e-04
Loss = 1.4448e-01, PNorm = 38.7046, GNorm = 0.6811, lr_0 = 1.1398e-04
Loss = 1.4321e-01, PNorm = 38.6895, GNorm = 0.6463, lr_0 = 1.1398e-04
Loss = 1.4332e-01, PNorm = 38.6864, GNorm = 0.6623, lr_0 = 1.1398e-04
Loss = 1.4397e-01, PNorm = 38.6993, GNorm = 0.6518, lr_0 = 1.1398e-04
Loss = 1.3926e-01, PNorm = 38.6999, GNorm = 0.5395, lr_0 = 1.0446e-04
Loss = 1.3958e-01, PNorm = 38.6999, GNorm = 0.5296, lr_0 = 1.0446e-04
Loss = 1.3871e-01, PNorm = 38.7052, GNorm = 0.5428, lr_0 = 1.0446e-04
Loss = 1.3918e-01, PNorm = 38.6961, GNorm = 0.5579, lr_0 = 1.0446e-04
Loss = 1.3919e-01, PNorm = 38.7147, GNorm = 0.5300, lr_0 = 1.0446e-04
Loss = 1.3907e-01, PNorm = 38.6994, GNorm = 0.5518, lr_0 = 1.0446e-04
Loss = 1.3928e-01, PNorm = 38.6959, GNorm = 0.5552, lr_0 = 1.0446e-04
Loss = 1.3988e-01, PNorm = 38.7093, GNorm = 0.5582, lr_0 = 1.0446e-04
Loss = 1.0607e-01, PNorm = 38.7082, GNorm = 0.6857, lr_0 = 1.0000e-04
Loss = 1.0544e-01, PNorm = 38.7135, GNorm = 0.7227, lr_0 = 1.0000e-04
Loss = 1.0610e-01, PNorm = 38.7082, GNorm = 0.6831, lr_0 = 1.0000e-04
Loss = 1.0587e-01, PNorm = 38.7041, GNorm = 0.6743, lr_0 = 1.0000e-04
Loss = 1.0529e-01, PNorm = 38.7231, GNorm = 0.7006, lr_0 = 1.0000e-04
Loss = 1.0584e-01, PNorm = 38.7073, GNorm = 0.7124, lr_0 = 1.0000e-04
Loss = 1.0556e-01, PNorm = 38.7037, GNorm = 0.7250, lr_0 = 1.0000e-04
Loss = 1.0555e-01, PNorm = 38.7177, GNorm = 0.6949, lr_0 = 1.0000e-04
Validation auc = 0.878360
Validation accuracy = 0.885714
Model 0 best validation auc = 0.878360 on epoch 9
Validation auc = 0.879928
Validation accuracy = 0.885714
Model 0 best validation auc = 0.879928 on epoch 9
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Validation auc = 0.875000
Validation accuracy = 0.885714
Model 0 best validation auc = 0.875000 on epoch 9
Validation auc = 0.877464
Validation accuracy = 0.885714
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Model 0 best validation auc = 0.877464 on epoch 9
Validation auc = 0.875896
Validation accuracy = 0.885714
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Model 0 best validation auc = 0.875896 on epoch 9
Model 0 test auc = 0.840796
Model 0 test accuracy = 0.952607
Ensemble test auc = 0.840796
Ensemble test accuracy = 0.952607
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Fold 2
Splitting data with seed 44
Validation auc = 0.879704
Validation accuracy = 0.885714
Model 0 test auc = 0.838308
Model 0 test accuracy = 0.952607
Model 0 best validation auc = 0.879704 on epoch 9
Ensemble test auc = 0.838308
Ensemble test accuracy = 0.952607
Model 0 test auc = 0.839303
Model 0 test accuracy = 0.952607
Fold 2
Ensemble test auc = 0.839303
Splitting data with seed 44
Ensemble test accuracy = 0.952607
Fold 2
Splitting data with seed 44
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Model 0 test auc = 0.839303
Model 0 test accuracy = 0.952607
Ensemble test auc = 0.839303
Ensemble test accuracy = 0.952607
Fold 2
Splitting data with seed 44
Model 0 test auc = 0.839801
Model 0 test accuracy = 0.952607
Ensemble test auc = 0.839801
Ensemble test accuracy = 0.952607
Fold 2
Splitting data with seed 44
Total scaffolds = 1,035 | train scaffolds = 765 | val scaffolds = 142 | test scaffolds = 128
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 250 | target average = 0.032000


Scaffold 1
Task 0: count = 191 | target average = 0.010471


Scaffold 2
Task 0: count = 43 | target average = 0.000000


Scaffold 3
Task 0: count = 21 | target average = 0.000000


Scaffold 4
Task 0: count = 19 | target average = 0.000000


Scaffold 5
Task 0: count = 18 | target average = 0.000000


Scaffold 6
Task 0: count = 16 | target average = 0.250000


Scaffold 7
Task 0: count = 14 | target average = 0.000000


Scaffold 8
Task 0: count = 13 | target average = 0.076923


Scaffold 9
Task 0: count = 12 | target average = 0.000000


Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
Validation auc = 0.878360
Validation accuracy = 0.885714
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Epoch 0
Model 0 best validation auc = 0.878360 on epoch 9
Total scaffolds = 1,035 | train scaffolds = 765 | val scaffolds = 142 | test scaffolds = 128
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 250 | target average = 0.032000


Scaffold 1
Task 0: count = 191 | target average = 0.010471


Scaffold 2
Task 0: count = 43 | target average = 0.000000


Scaffold 3
Task 0: count = 21 | target average = 0.000000


Scaffold 4
Task 0: count = 19 | target average = 0.000000


Scaffold 5
Task 0: count = 18 | target average = 0.000000


Scaffold 6
Task 0: count = 16 | target average = 0.250000


Scaffold 7
Task 0: count = 14 | target average = 0.000000


Scaffold 8
Task 0: count = 13 | target average = 0.076923


Scaffold 9
Task 0: count = 12 | target average = 0.000000


Total scaffolds = 1,035 | train scaffolds = 765 | val scaffolds = 142 | test scaffolds = 128
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Scaffold 0
Task 0: count = 250 | target average = 0.032000


Scaffold 1
Task 0: count = 191 | target average = 0.010471


Scaffold 2
Task 0: count = 43 | target average = 0.000000


Scaffold 3
Task 0: count = 21 | target average = 0.000000


Scaffold 4
Task 0: count = 19 | target average = 0.000000


Scaffold 5
Task 0: count = 18 | target average = 0.000000


Scaffold 6
Task 0: count = 16 | target average = 0.250000


Scaffold 7
Task 0: count = 14 | target average = 0.000000


Scaffold 8
Task 0: count = 13 | target average = 0.076923


Scaffold 9
Task 0: count = 12 | target average = 0.000000


Class sizes
Active 0: 94.86%, 1: 5.14%
Building model 0
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Model 0 test auc = 0.842289
Model 0 test accuracy = 0.952607
Ensemble test auc = 0.842289
Ensemble test accuracy = 0.952607
Fold 2
Validation auc = 0.877240
Splitting data with seed 44
Validation accuracy = 0.885714
Epoch 0
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Epoch 0
Model 0 best validation auc = 0.877240 on epoch 9
Total scaffolds = 1,035 | train scaffolds = 765 | val scaffolds = 142 | test scaffolds = 128
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 250 | target average = 0.032000


Scaffold 1
Task 0: count = 191 | target average = 0.010471


Scaffold 2
Task 0: count = 43 | target average = 0.000000


Scaffold 3
Task 0: count = 21 | target average = 0.000000


Scaffold 4
Task 0: count = 19 | target average = 0.000000


Scaffold 5
Task 0: count = 18 | target average = 0.000000


Scaffold 6
Task 0: count = 16 | target average = 0.250000


Scaffold 7
Task 0: count = 14 | target average = 0.000000


Scaffold 8
Task 0: count = 13 | target average = 0.076923


Scaffold 9
Task 0: count = 12 | target average = 0.000000


Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Epoch 0
Total scaffolds = 1,035 | train scaffolds = 765 | val scaffolds = 142 | test scaffolds = 128
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 250 | target average = 0.032000


Scaffold 1
Task 0: count = 191 | target average = 0.010471


Scaffold 2
Task 0: count = 43 | target average = 0.000000


Scaffold 3
Task 0: count = 21 | target average = 0.000000


Scaffold 4
Task 0: count = 19 | target average = 0.000000


Scaffold 5
Task 0: count = 18 | target average = 0.000000


Scaffold 6
Task 0: count = 16 | target average = 0.250000


Scaffold 7
Task 0: count = 14 | target average = 0.000000


Scaffold 8
Task 0: count = 13 | target average = 0.076923


Scaffold 9
Task 0: count = 12 | target average = 0.000000


Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Epoch 0
Model 0 test auc = 0.840796
Model 0 test accuracy = 0.952607
Ensemble test auc = 0.840796
Ensemble test accuracy = 0.952607
Fold 2
Splitting data with seed 44
Total scaffolds = 1,035 | train scaffolds = 765 | val scaffolds = 142 | test scaffolds = 128
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 250 | target average = 0.032000


Scaffold 1
Task 0: count = 191 | target average = 0.010471


Scaffold 2
Task 0: count = 43 | target average = 0.000000


Scaffold 3
Task 0: count = 21 | target average = 0.000000


Scaffold 4
Task 0: count = 19 | target average = 0.000000


Scaffold 5
Task 0: count = 18 | target average = 0.000000


Scaffold 6
Task 0: count = 16 | target average = 0.250000


Scaffold 7
Task 0: count = 14 | target average = 0.000000


Scaffold 8
Task 0: count = 13 | target average = 0.076923


Scaffold 9
Task 0: count = 12 | target average = 0.000000


Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Model 0 test auc = 0.841791
Model 0 test accuracy = 0.952607
Ensemble test auc = 0.841791
Ensemble test accuracy = 0.952607
Fold 2
Epoch 0
Splitting data with seed 44
Total scaffolds = 1,035 | train scaffolds = 765 | val scaffolds = 142 | test scaffolds = 128
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 250 | target average = 0.032000


Scaffold 1
Task 0: count = 191 | target average = 0.010471


Scaffold 2
Task 0: count = 43 | target average = 0.000000


Scaffold 3
Task 0: count = 21 | target average = 0.000000


Scaffold 4
Task 0: count = 19 | target average = 0.000000


Scaffold 5
Task 0: count = 18 | target average = 0.000000


Scaffold 6
Task 0: count = 16 | target average = 0.250000


Scaffold 7
Task 0: count = 14 | target average = 0.000000


Scaffold 8
Task 0: count = 13 | target average = 0.076923


Scaffold 9
Task 0: count = 12 | target average = 0.000000


Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Epoch 0
Total scaffolds = 1,035 | train scaffolds = 765 | val scaffolds = 142 | test scaffolds = 128
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 250 | target average = 0.032000


Scaffold 1
Task 0: count = 191 | target average = 0.010471


Scaffold 2
Task 0: count = 43 | target average = 0.000000


Scaffold 3
Task 0: count = 21 | target average = 0.000000


Scaffold 4
Task 0: count = 19 | target average = 0.000000


Scaffold 5
Task 0: count = 18 | target average = 0.000000


Scaffold 6
Task 0: count = 16 | target average = 0.250000


Scaffold 7
Task 0: count = 14 | target average = 0.000000


Scaffold 8
Task 0: count = 13 | target average = 0.076923


Scaffold 9
Task 0: count = 12 | target average = 0.000000


Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Epoch 0
Loss = 4.5988e-01, PNorm = 38.1780, GNorm = 0.5187, lr_0 = 2.5000e-04
Loss = 4.5988e-01, PNorm = 38.1780, GNorm = 0.5187, lr_0 = 2.5000e-04
Loss = 4.5988e-01, PNorm = 38.1780, GNorm = 0.5187, lr_0 = 2.5000e-04
Loss = 4.5988e-01, PNorm = 38.1780, GNorm = 0.5187, lr_0 = 2.5000e-04
Loss = 4.5988e-01, PNorm = 38.1780, GNorm = 0.5187, lr_0 = 2.5000e-04
Loss = 4.5988e-01, PNorm = 38.1780, GNorm = 0.5187, lr_0 = 2.5000e-04
Loss = 4.5988e-01, PNorm = 38.1780, GNorm = 0.5187, lr_0 = 2.5000e-04
Loss = 4.5988e-01, PNorm = 38.1780, GNorm = 0.5187, lr_0 = 2.5000e-04
Loss = 2.1075e-01, PNorm = 38.1879, GNorm = 0.8750, lr_0 = 3.8636e-04
Loss = 2.1075e-01, PNorm = 38.1879, GNorm = 0.8750, lr_0 = 3.8636e-04
Loss = 2.1075e-01, PNorm = 38.1879, GNorm = 0.8750, lr_0 = 3.8636e-04
Loss = 2.1075e-01, PNorm = 38.1879, GNorm = 0.8750, lr_0 = 3.8636e-04
Loss = 2.1075e-01, PNorm = 38.1879, GNorm = 0.8750, lr_0 = 3.8636e-04
Loss = 2.1075e-01, PNorm = 38.1879, GNorm = 0.8750, lr_0 = 3.8636e-04
Loss = 2.1075e-01, PNorm = 38.1879, GNorm = 0.8750, lr_0 = 3.8636e-04
Loss = 2.1075e-01, PNorm = 38.1879, GNorm = 0.8750, lr_0 = 3.8636e-04
Loss = 1.7967e-01, PNorm = 38.1965, GNorm = 0.2887, lr_0 = 5.2273e-04
Loss = 1.7967e-01, PNorm = 38.1965, GNorm = 0.2887, lr_0 = 5.2273e-04
Loss = 1.7967e-01, PNorm = 38.1965, GNorm = 0.2887, lr_0 = 5.2273e-04
Loss = 1.7967e-01, PNorm = 38.1965, GNorm = 0.2887, lr_0 = 5.2273e-04
Loss = 1.7967e-01, PNorm = 38.1965, GNorm = 0.2887, lr_0 = 5.2273e-04
Loss = 1.7967e-01, PNorm = 38.1965, GNorm = 0.2887, lr_0 = 5.2273e-04
Validation auc = 0.574538
Validation accuracy = 0.909524
Loss = 1.7967e-01, PNorm = 38.1965, GNorm = 0.2887, lr_0 = 5.2273e-04
Validation auc = 0.574538
Validation accuracy = 0.909524
Epoch 1
Validation auc = 0.574538
Validation accuracy = 0.909524
Epoch 1
Epoch 1
Loss = 1.7967e-01, PNorm = 38.1965, GNorm = 0.2887, lr_0 = 5.2273e-04
Validation auc = 0.574538
Validation accuracy = 0.909524
Epoch 1
Validation auc = 0.574538
Validation accuracy = 0.909524
Validation auc = 0.574538
Validation accuracy = 0.909524
Epoch 1
Epoch 1
Validation auc = 0.574538
Validation accuracy = 0.909524
Epoch 1
Validation auc = 0.574538
Validation accuracy = 0.909524
Epoch 1
Loss = 1.6547e-01, PNorm = 38.2171, GNorm = 0.2911, lr_0 = 6.7273e-04
Loss = 1.6547e-01, PNorm = 38.2171, GNorm = 0.2911, lr_0 = 6.7273e-04
Loss = 1.6547e-01, PNorm = 38.2172, GNorm = 0.2895, lr_0 = 6.7273e-04
Loss = 1.6547e-01, PNorm = 38.2171, GNorm = 0.2911, lr_0 = 6.7273e-04
Loss = 1.6547e-01, PNorm = 38.2172, GNorm = 0.2895, lr_0 = 6.7273e-04
Loss = 1.6547e-01, PNorm = 38.2172, GNorm = 0.2895, lr_0 = 6.7273e-04
Loss = 1.6547e-01, PNorm = 38.2172, GNorm = 0.2895, lr_0 = 6.7273e-04
Loss = 1.6547e-01, PNorm = 38.2171, GNorm = 0.2911, lr_0 = 6.7273e-04
Loss = 2.1833e-01, PNorm = 38.2304, GNorm = 0.4438, lr_0 = 8.0909e-04
Loss = 2.1833e-01, PNorm = 38.2304, GNorm = 0.4438, lr_0 = 8.0909e-04
Loss = 2.1832e-01, PNorm = 38.2306, GNorm = 0.4395, lr_0 = 8.0909e-04
Loss = 2.1833e-01, PNorm = 38.2304, GNorm = 0.4434, lr_0 = 8.0909e-04
Loss = 2.1832e-01, PNorm = 38.2306, GNorm = 0.4395, lr_0 = 8.0909e-04
Loss = 2.1832e-01, PNorm = 38.2306, GNorm = 0.4395, lr_0 = 8.0909e-04
Loss = 2.1832e-01, PNorm = 38.2306, GNorm = 0.4395, lr_0 = 8.0909e-04
Loss = 2.1833e-01, PNorm = 38.2304, GNorm = 0.4438, lr_0 = 8.0909e-04
Loss = 2.0354e-01, PNorm = 38.2620, GNorm = 0.6229, lr_0 = 9.4545e-04
Loss = 2.0349e-01, PNorm = 38.2620, GNorm = 0.6259, lr_0 = 9.4545e-04
Loss = 2.0344e-01, PNorm = 38.2629, GNorm = 0.6041, lr_0 = 9.4545e-04
Loss = 2.0348e-01, PNorm = 38.2622, GNorm = 0.6276, lr_0 = 9.4545e-04
Loss = 2.0344e-01, PNorm = 38.2629, GNorm = 0.6041, lr_0 = 9.4545e-04
Loss = 2.0344e-01, PNorm = 38.2629, GNorm = 0.6043, lr_0 = 9.4545e-04
Loss = 2.0344e-01, PNorm = 38.2629, GNorm = 0.6043, lr_0 = 9.4545e-04
Loss = 2.0354e-01, PNorm = 38.2620, GNorm = 0.6225, lr_0 = 9.4545e-04
Validation auc = 0.607054
Validation accuracy = 0.909524
Epoch 2
Validation auc = 0.611188
Validation accuracy = 0.909524
Epoch 2
Validation auc = 0.610361
Validation accuracy = 0.909524
Epoch 2
Validation auc = 0.612565
Validation accuracy = 0.909524
Epoch 2
Validation auc = 0.611188
Validation accuracy = 0.909524
Loss = 2.1983e-01, PNorm = 38.2837, GNorm = 0.4008, lr_0 = 9.4901e-04
Loss = 2.1976e-01, PNorm = 38.2844, GNorm = 0.4298, lr_0 = 9.4901e-04
Epoch 2
Validation auc = 0.610361
Validation accuracy = 0.909524
Epoch 2
Loss = 2.1966e-01, PNorm = 38.2844, GNorm = 0.4162, lr_0 = 9.4901e-04
Validation auc = 0.610361
Validation accuracy = 0.909524
Epoch 2
Loss = 2.1893e-01, PNorm = 38.2847, GNorm = 0.4231, lr_0 = 9.4901e-04
Loss = 2.1976e-01, PNorm = 38.2844, GNorm = 0.4298, lr_0 = 9.4901e-04
Loss = 2.1982e-01, PNorm = 38.2844, GNorm = 0.4359, lr_0 = 9.4901e-04
Validation auc = 0.608432
Validation accuracy = 0.909524
Epoch 2
Loss = 2.1982e-01, PNorm = 38.2844, GNorm = 0.4359, lr_0 = 9.4901e-04
Loss = 2.1968e-01, PNorm = 38.2836, GNorm = 0.4042, lr_0 = 9.4901e-04
Loss = 1.8983e-01, PNorm = 38.3088, GNorm = 0.7243, lr_0 = 8.6975e-04
Loss = 1.9032e-01, PNorm = 38.3088, GNorm = 0.7429, lr_0 = 8.6975e-04
Loss = 1.9000e-01, PNorm = 38.3103, GNorm = 0.7250, lr_0 = 8.6975e-04
Loss = 1.8975e-01, PNorm = 38.3102, GNorm = 0.7246, lr_0 = 8.6975e-04
Loss = 1.9032e-01, PNorm = 38.3088, GNorm = 0.7429, lr_0 = 8.6975e-04
Loss = 1.9048e-01, PNorm = 38.3098, GNorm = 0.7458, lr_0 = 8.6975e-04
Loss = 1.9048e-01, PNorm = 38.3098, GNorm = 0.7458, lr_0 = 8.6975e-04
Loss = 1.8958e-01, PNorm = 38.3091, GNorm = 0.7243, lr_0 = 8.6975e-04
Loss = 1.7600e-01, PNorm = 38.3290, GNorm = 0.1340, lr_0 = 7.9710e-04
Loss = 1.7568e-01, PNorm = 38.3287, GNorm = 0.1489, lr_0 = 7.9710e-04
Loss = 1.7591e-01, PNorm = 38.3310, GNorm = 0.1390, lr_0 = 7.9710e-04
Loss = 1.7560e-01, PNorm = 38.3307, GNorm = 0.1256, lr_0 = 7.9710e-04
Loss = 1.7568e-01, PNorm = 38.3287, GNorm = 0.1485, lr_0 = 7.9710e-04
Loss = 1.7584e-01, PNorm = 38.3305, GNorm = 0.1461, lr_0 = 7.9710e-04
Loss = 1.7584e-01, PNorm = 38.3305, GNorm = 0.1460, lr_0 = 7.9710e-04
Loss = 1.7569e-01, PNorm = 38.3295, GNorm = 0.1340, lr_0 = 7.9710e-04
Loss = 1.8903e-01, PNorm = 38.3521, GNorm = 0.6351, lr_0 = 7.3053e-04
Loss = 4.4489e-02, PNorm = 38.3537, GNorm = 0.6101, lr_0 = 7.2418e-04
Loss = 1.8883e-01, PNorm = 38.3518, GNorm = 0.6028, lr_0 = 7.3053e-04
Validation auc = 0.801598
Validation accuracy = 0.909524
Epoch 3
Loss = 4.3378e-02, PNorm = 38.3535, GNorm = 0.5933, lr_0 = 7.2418e-04
Loss = 1.8896e-01, PNorm = 38.3530, GNorm = 0.6090, lr_0 = 7.3053e-04
Loss = 4.6867e-02, PNorm = 38.3546, GNorm = 0.6399, lr_0 = 7.2418e-04
Loss = 1.8885e-01, PNorm = 38.3530, GNorm = 0.6007, lr_0 = 7.3053e-04
Validation auc = 0.809589
Validation accuracy = 0.909524
Loss = 1.8884e-01, PNorm = 38.3518, GNorm = 0.6041, lr_0 = 7.3053e-04
Loss = 4.6269e-02, PNorm = 38.3546, GNorm = 0.6327, lr_0 = 7.2418e-04
Epoch 3
Loss = 4.3406e-02, PNorm = 38.3535, GNorm = 0.5935, lr_0 = 7.2418e-04
Loss = 1.8920e-01, PNorm = 38.3534, GNorm = 0.6044, lr_0 = 7.3053e-04
Validation auc = 0.807936
Validation accuracy = 0.909524
Epoch 3
Loss = 4.5354e-02, PNorm = 38.3549, GNorm = 0.6174, lr_0 = 7.2418e-04
Validation auc = 0.806558
Validation accuracy = 0.909524
Validation auc = 0.809589
Validation accuracy = 0.909524
Epoch 3
Epoch 3
Loss = 1.8920e-01, PNorm = 38.3534, GNorm = 0.6044, lr_0 = 7.3053e-04
Loss = 4.5354e-02, PNorm = 38.3549, GNorm = 0.6172, lr_0 = 7.2418e-04
Validation auc = 0.809589
Validation accuracy = 0.909524
Epoch 3
Loss = 1.8902e-01, PNorm = 38.3520, GNorm = 0.6146, lr_0 = 7.3053e-04
Loss = 4.7721e-02, PNorm = 38.3536, GNorm = 0.6561, lr_0 = 7.2418e-04
Validation auc = 0.809589
Validation accuracy = 0.909524
Epoch 3
Validation auc = 0.806283
Validation accuracy = 0.909524
Epoch 3
Loss = 2.2706e-01, PNorm = 38.3772, GNorm = 1.0045, lr_0 = 6.6370e-04
Loss = 2.2611e-01, PNorm = 38.3763, GNorm = 0.9941, lr_0 = 6.6370e-04
Loss = 2.2687e-01, PNorm = 38.3771, GNorm = 1.0535, lr_0 = 6.6370e-04
Loss = 2.2619e-01, PNorm = 38.3765, GNorm = 0.9978, lr_0 = 6.6370e-04
Loss = 2.2633e-01, PNorm = 38.3780, GNorm = 1.0450, lr_0 = 6.6370e-04
Loss = 2.2608e-01, PNorm = 38.3774, GNorm = 0.9911, lr_0 = 6.6370e-04
Loss = 2.2608e-01, PNorm = 38.3774, GNorm = 0.9909, lr_0 = 6.6370e-04
Loss = 2.2647e-01, PNorm = 38.3771, GNorm = 1.0568, lr_0 = 6.6370e-04
Loss = 1.3659e-01, PNorm = 38.4134, GNorm = 0.1604, lr_0 = 6.0826e-04
Loss = 1.3545e-01, PNorm = 38.4121, GNorm = 0.1403, lr_0 = 6.0826e-04
Loss = 1.3683e-01, PNorm = 38.4128, GNorm = 0.1445, lr_0 = 6.0826e-04
Loss = 1.3624e-01, PNorm = 38.4127, GNorm = 0.1381, lr_0 = 6.0826e-04
Loss = 1.3544e-01, PNorm = 38.4127, GNorm = 0.1386, lr_0 = 6.0826e-04
Loss = 1.3594e-01, PNorm = 38.4141, GNorm = 0.1361, lr_0 = 6.0826e-04
Loss = 1.3594e-01, PNorm = 38.4141, GNorm = 0.1349, lr_0 = 6.0826e-04
Loss = 1.3687e-01, PNorm = 38.4127, GNorm = 0.1459, lr_0 = 6.0826e-04
Loss = 1.5190e-01, PNorm = 38.4283, GNorm = 0.3788, lr_0 = 5.5746e-04
Loss = 1.5319e-01, PNorm = 38.4278, GNorm = 0.4020, lr_0 = 5.5746e-04
Loss = 1.5242e-01, PNorm = 38.4259, GNorm = 0.4022, lr_0 = 5.5746e-04
Loss = 1.5268e-01, PNorm = 38.4283, GNorm = 0.4070, lr_0 = 5.5746e-04
Loss = 1.5204e-01, PNorm = 38.4280, GNorm = 0.4035, lr_0 = 5.5746e-04
Loss = 1.5295e-01, PNorm = 38.4264, GNorm = 0.4068, lr_0 = 5.5746e-04
Loss = 1.5199e-01, PNorm = 38.4278, GNorm = 0.4014, lr_0 = 5.5746e-04
Validation auc = 0.778451
Validation accuracy = 0.909524
Epoch 4
Validation auc = 0.779002
Validation accuracy = 0.909524
Epoch 4
Validation auc = 0.769909
Validation accuracy = 0.909524
Epoch 4
Validation auc = 0.777074
Validation accuracy = 0.909524
Epoch 4
Loss = 1.5267e-01, PNorm = 38.4272, GNorm = 0.3969, lr_0 = 5.5746e-04
Validation auc = 0.772940
Validation accuracy = 0.909524
Epoch 4
Validation auc = 0.769082
Validation accuracy = 0.909524
Epoch 4
Validation auc = 0.772940
Validation accuracy = 0.909524
Epoch 4
Loss = 2.1452e-01, PNorm = 38.4393, GNorm = 0.4831, lr_0 = 5.1090e-04
Loss = 2.1487e-01, PNorm = 38.4401, GNorm = 0.4473, lr_0 = 5.1090e-04
Loss = 2.1647e-01, PNorm = 38.4386, GNorm = 0.5793, lr_0 = 5.1090e-04
Loss = 2.1419e-01, PNorm = 38.4409, GNorm = 0.4965, lr_0 = 5.1090e-04
Validation auc = 0.779278
Validation accuracy = 0.909524
Epoch 4
Loss = 2.1691e-01, PNorm = 38.4390, GNorm = 0.5725, lr_0 = 5.1090e-04
Loss = 2.1504e-01, PNorm = 38.4400, GNorm = 0.5487, lr_0 = 5.1090e-04
Loss = 2.1490e-01, PNorm = 38.4397, GNorm = 0.5522, lr_0 = 5.1090e-04
Loss = 2.1434e-01, PNorm = 38.4403, GNorm = 0.4648, lr_0 = 5.1090e-04
Loss = 1.4355e-01, PNorm = 38.4555, GNorm = 0.7720, lr_0 = 4.6822e-04
Loss = 1.4283e-01, PNorm = 38.4568, GNorm = 0.7614, lr_0 = 4.6822e-04
Loss = 1.4467e-01, PNorm = 38.4570, GNorm = 0.9122, lr_0 = 4.6822e-04
Loss = 1.4353e-01, PNorm = 38.4589, GNorm = 0.8108, lr_0 = 4.6822e-04
Loss = 1.4520e-01, PNorm = 38.4578, GNorm = 0.9311, lr_0 = 4.6822e-04
Loss = 1.4433e-01, PNorm = 38.4574, GNorm = 0.8864, lr_0 = 4.6822e-04
Loss = 1.4425e-01, PNorm = 38.4571, GNorm = 0.8849, lr_0 = 4.6822e-04
Loss = 1.4297e-01, PNorm = 38.4578, GNorm = 0.7984, lr_0 = 4.6822e-04
Loss = 1.7116e-01, PNorm = 38.4678, GNorm = 0.5336, lr_0 = 4.2912e-04
Loss = 1.7101e-01, PNorm = 38.4694, GNorm = 0.5323, lr_0 = 4.2912e-04
Loss = 1.7098e-01, PNorm = 38.4698, GNorm = 0.5789, lr_0 = 4.2912e-04
Loss = 1.7073e-01, PNorm = 38.4718, GNorm = 0.5400, lr_0 = 4.2912e-04
Loss = 1.7084e-01, PNorm = 38.4703, GNorm = 0.5820, lr_0 = 4.2912e-04
Loss = 1.7162e-01, PNorm = 38.4703, GNorm = 0.5574, lr_0 = 4.2912e-04
Loss = 1.7159e-01, PNorm = 38.4700, GNorm = 0.5572, lr_0 = 4.2912e-04
Loss = 1.7043e-01, PNorm = 38.4714, GNorm = 0.5711, lr_0 = 4.2912e-04
Validation auc = 0.808763
Validation accuracy = 0.909524
Epoch 5
Validation auc = 0.811794
Validation accuracy = 0.909524
Loss = 2.0459e-01, PNorm = 38.4900, GNorm = 0.3983, lr_0 = 3.9328e-04
Epoch 5
Validation auc = 0.813447
Validation accuracy = 0.909524
Validation auc = 0.813998
Validation accuracy = 0.909524
Epoch 5
Epoch 5
Loss = 2.0476e-01, PNorm = 38.4916, GNorm = 0.4034, lr_0 = 3.9328e-04
Loss = 2.0498e-01, PNorm = 38.4940, GNorm = 0.4191, lr_0 = 3.9328e-04
Loss = 2.0482e-01, PNorm = 38.4948, GNorm = 0.4109, lr_0 = 3.9328e-04
Validation auc = 0.814549
Validation accuracy = 0.909524
Validation auc = 0.812896
Validation accuracy = 0.909524
Epoch 5
Epoch 5
Validation auc = 0.813447
Validation accuracy = 0.909524
Epoch 5
Loss = 2.0594e-01, PNorm = 38.4939, GNorm = 0.4222, lr_0 = 3.9328e-04
Loss = 2.0555e-01, PNorm = 38.4935, GNorm = 0.4175, lr_0 = 3.9328e-04
Loss = 2.0547e-01, PNorm = 38.4930, GNorm = 0.4133, lr_0 = 3.9328e-04
Validation auc = 0.812345
Validation accuracy = 0.909524
Epoch 5
Loss = 2.0544e-01, PNorm = 38.4943, GNorm = 0.3901, lr_0 = 3.9328e-04
Loss = 1.6245e-01, PNorm = 38.5069, GNorm = 0.4721, lr_0 = 3.6043e-04
Loss = 1.6186e-01, PNorm = 38.5083, GNorm = 0.4788, lr_0 = 3.6043e-04
Loss = 1.6123e-01, PNorm = 38.5135, GNorm = 0.4879, lr_0 = 3.6043e-04
Loss = 1.6142e-01, PNorm = 38.5123, GNorm = 0.4220, lr_0 = 3.6043e-04
Loss = 1.6138e-01, PNorm = 38.5125, GNorm = 0.4693, lr_0 = 3.6043e-04
Loss = 1.6169e-01, PNorm = 38.5116, GNorm = 0.4426, lr_0 = 3.6043e-04
Loss = 1.6172e-01, PNorm = 38.5109, GNorm = 0.4448, lr_0 = 3.6043e-04
Loss = 1.6126e-01, PNorm = 38.5121, GNorm = 0.4653, lr_0 = 3.6043e-04
Loss = 1.4887e-01, PNorm = 38.5281, GNorm = 0.4766, lr_0 = 3.3032e-04
Loss = 1.4808e-01, PNorm = 38.5292, GNorm = 0.4713, lr_0 = 3.3032e-04
Loss = 1.4724e-01, PNorm = 38.5361, GNorm = 0.5322, lr_0 = 3.3032e-04
Loss = 1.4812e-01, PNorm = 38.5332, GNorm = 0.4667, lr_0 = 3.3032e-04
Loss = 1.4793e-01, PNorm = 38.5334, GNorm = 0.4706, lr_0 = 3.3032e-04
Loss = 1.4734e-01, PNorm = 38.5344, GNorm = 0.5006, lr_0 = 3.3032e-04
Loss = 1.4801e-01, PNorm = 38.5323, GNorm = 0.4862, lr_0 = 3.3032e-04
Loss = 1.4774e-01, PNorm = 38.5349, GNorm = 0.4803, lr_0 = 3.3032e-04
Loss = 1.5641e-01, PNorm = 38.5355, GNorm = 0.6796, lr_0 = 3.0273e-04
Loss = 1.5652e-01, PNorm = 38.5367, GNorm = 0.7109, lr_0 = 3.0273e-04
Loss = 1.5399e-01, PNorm = 38.5451, GNorm = 0.8098, lr_0 = 3.0273e-04
Loss = 1.5646e-01, PNorm = 38.5405, GNorm = 0.6873, lr_0 = 3.0273e-04
Validation auc = 0.826674
Validation accuracy = 0.909524
Epoch 6
Loss = 1.5551e-01, PNorm = 38.5416, GNorm = 0.7343, lr_0 = 3.0273e-04
Validation auc = 0.825572
Validation accuracy = 0.909524
Loss = 1.5458e-01, PNorm = 38.5436, GNorm = 0.8212, lr_0 = 3.0273e-04
Epoch 6
Loss = 1.5562e-01, PNorm = 38.5426, GNorm = 0.7373, lr_0 = 3.0273e-04
Validation auc = 0.836594
Validation accuracy = 0.909524
Epoch 6
Validation auc = 0.830256
Validation accuracy = 0.909524
Epoch 6
Loss = 1.5544e-01, PNorm = 38.5437, GNorm = 0.7373, lr_0 = 3.0273e-04
Validation auc = 0.836043
Validation accuracy = 0.909524
Validation auc = 0.830256
Validation accuracy = 0.909524
Validation auc = 0.830532
Validation accuracy = 0.909524
Epoch 6
Epoch 6
Epoch 6
Validation auc = 0.829430
Validation accuracy = 0.909524
Epoch 6
Loss = 1.7426e-01, PNorm = 38.5543, GNorm = 0.4730, lr_0 = 2.7504e-04
Loss = 1.7455e-01, PNorm = 38.5534, GNorm = 0.4654, lr_0 = 2.7504e-04
Loss = 1.7388e-01, PNorm = 38.5631, GNorm = 0.5125, lr_0 = 2.7504e-04
Loss = 1.7419e-01, PNorm = 38.5581, GNorm = 0.4690, lr_0 = 2.7504e-04
Loss = 1.7316e-01, PNorm = 38.5603, GNorm = 0.4834, lr_0 = 2.7504e-04
Loss = 1.7351e-01, PNorm = 38.5608, GNorm = 0.4946, lr_0 = 2.7504e-04
Loss = 1.7481e-01, PNorm = 38.5613, GNorm = 0.5075, lr_0 = 2.7504e-04
Loss = 1.7467e-01, PNorm = 38.5616, GNorm = 0.5045, lr_0 = 2.7504e-04
Loss = 1.3587e-01, PNorm = 38.5639, GNorm = 0.5065, lr_0 = 2.5207e-04
Loss = 1.3542e-01, PNorm = 38.5649, GNorm = 0.5052, lr_0 = 2.5207e-04
Loss = 1.3599e-01, PNorm = 38.5738, GNorm = 0.5715, lr_0 = 2.5207e-04
Loss = 1.3501e-01, PNorm = 38.5686, GNorm = 0.4897, lr_0 = 2.5207e-04
Loss = 1.3522e-01, PNorm = 38.5720, GNorm = 0.5253, lr_0 = 2.5207e-04
Loss = 1.3522e-01, PNorm = 38.5719, GNorm = 0.5292, lr_0 = 2.5207e-04
Loss = 1.3630e-01, PNorm = 38.5719, GNorm = 0.5752, lr_0 = 2.5207e-04
Loss = 1.3548e-01, PNorm = 38.5717, GNorm = 0.5345, lr_0 = 2.5207e-04
Loss = 1.5041e-01, PNorm = 38.5784, GNorm = 0.7471, lr_0 = 2.3101e-04
Loss = 1.5002e-01, PNorm = 38.5881, GNorm = 0.7696, lr_0 = 2.3101e-04
Loss = 1.5008e-01, PNorm = 38.5792, GNorm = 0.7504, lr_0 = 2.3101e-04
Loss = 1.4963e-01, PNorm = 38.5825, GNorm = 0.7472, lr_0 = 2.3101e-04
Loss = 1.4971e-01, PNorm = 38.5866, GNorm = 0.7916, lr_0 = 2.3101e-04
Loss = 1.5016e-01, PNorm = 38.5868, GNorm = 0.7315, lr_0 = 2.3101e-04
Loss = 1.4978e-01, PNorm = 38.5866, GNorm = 0.7699, lr_0 = 2.3101e-04
Validation auc = 0.829430
Validation accuracy = 0.919048
Epoch 7
Validation auc = 0.830532
Validation accuracy = 0.919048
Epoch 7
Validation auc = 0.829430
Validation accuracy = 0.914286
Epoch 7
Loss = 1.4986e-01, PNorm = 38.5864, GNorm = 0.7418, lr_0 = 2.3101e-04
Validation auc = 0.827501
Validation accuracy = 0.914286
Epoch 7
Validation auc = 0.828878
Validation accuracy = 0.914286
Epoch 7
Validation auc = 0.831359
Validation accuracy = 0.914286
Epoch 7
Validation auc = 0.828052
Validation accuracy = 0.914286
Epoch 7
Loss = 1.2376e-01, PNorm = 38.5962, GNorm = 0.3570, lr_0 = 2.1172e-04
Loss = 1.2341e-01, PNorm = 38.6051, GNorm = 0.3383, lr_0 = 2.1172e-04
Loss = 1.2369e-01, PNorm = 38.5961, GNorm = 0.3633, lr_0 = 2.1172e-04
Validation auc = 0.826950
Validation accuracy = 0.914286
Epoch 7
Loss = 1.2331e-01, PNorm = 38.5994, GNorm = 0.3736, lr_0 = 2.1172e-04
Loss = 1.2453e-01, PNorm = 38.6039, GNorm = 0.3173, lr_0 = 2.1172e-04
Loss = 1.2316e-01, PNorm = 38.6037, GNorm = 0.3571, lr_0 = 2.1172e-04
Loss = 1.2384e-01, PNorm = 38.6033, GNorm = 0.3479, lr_0 = 2.1172e-04
Loss = 1.2333e-01, PNorm = 38.6035, GNorm = 0.3379, lr_0 = 2.1172e-04
Loss = 1.6919e-01, PNorm = 38.6096, GNorm = 0.6671, lr_0 = 1.9403e-04
Loss = 1.6759e-01, PNorm = 38.6182, GNorm = 0.7131, lr_0 = 1.9403e-04
Loss = 1.6824e-01, PNorm = 38.6085, GNorm = 0.6566, lr_0 = 1.9403e-04
Loss = 1.6854e-01, PNorm = 38.6122, GNorm = 0.6932, lr_0 = 1.9403e-04
Loss = 1.6712e-01, PNorm = 38.6175, GNorm = 0.6870, lr_0 = 1.9403e-04
Loss = 1.6807e-01, PNorm = 38.6172, GNorm = 0.7182, lr_0 = 1.9403e-04
Loss = 1.6758e-01, PNorm = 38.6164, GNorm = 0.6886, lr_0 = 1.9403e-04
Loss = 1.6783e-01, PNorm = 38.6165, GNorm = 0.6746, lr_0 = 1.9403e-04
Loss = 1.3581e-01, PNorm = 38.6212, GNorm = 1.0634, lr_0 = 1.7783e-04
Loss = 1.3513e-01, PNorm = 38.6195, GNorm = 1.0451, lr_0 = 1.7783e-04
Loss = 1.3388e-01, PNorm = 38.6309, GNorm = 1.0489, lr_0 = 1.7783e-04
Loss = 1.3499e-01, PNorm = 38.6240, GNorm = 1.0359, lr_0 = 1.7783e-04
Loss = 1.3469e-01, PNorm = 38.6290, GNorm = 1.0575, lr_0 = 1.7783e-04
Loss = 1.3436e-01, PNorm = 38.6298, GNorm = 1.0637, lr_0 = 1.7783e-04
Loss = 1.3476e-01, PNorm = 38.6299, GNorm = 1.0908, lr_0 = 1.7783e-04
Loss = 1.3454e-01, PNorm = 38.6290, GNorm = 1.0606, lr_0 = 1.7783e-04
Validation auc = 0.845688
Validation accuracy = 0.923810
Epoch 8
Validation auc = 0.845412
Validation accuracy = 0.914286
Validation auc = 0.850372
Validation accuracy = 0.919048
Epoch 8
Epoch 8
Loss = 8.9746e-02, PNorm = 38.6282, GNorm = 0.7518, lr_0 = 1.6156e-04
Validation auc = 0.846239
Validation accuracy = 0.914286
Epoch 8
Loss = 8.9413e-02, PNorm = 38.6266, GNorm = 0.7518, lr_0 = 1.6156e-04
Validation auc = 0.847065
Validation accuracy = 0.919048
Validation auc = 0.846514
Validation accuracy = 0.919048
Loss = 8.8663e-02, PNorm = 38.6383, GNorm = 0.7675, lr_0 = 1.6156e-04
Epoch 8
Epoch 8
Validation auc = 0.846790
Validation accuracy = 0.919048
Epoch 8
Loss = 8.9407e-02, PNorm = 38.6306, GNorm = 0.7386, lr_0 = 1.6156e-04
Loss = 8.8368e-02, PNorm = 38.6367, GNorm = 0.7639, lr_0 = 1.6156e-04
Loss = 8.8508e-02, PNorm = 38.6363, GNorm = 0.7374, lr_0 = 1.6156e-04
Loss = 8.9377e-02, PNorm = 38.6369, GNorm = 0.7526, lr_0 = 1.6156e-04
Validation auc = 0.846239
Validation accuracy = 0.923810
Epoch 8
Loss = 8.9410e-02, PNorm = 38.6367, GNorm = 0.7660, lr_0 = 1.6156e-04
Loss = 1.7333e-01, PNorm = 38.6374, GNorm = 0.6765, lr_0 = 1.4807e-04
Loss = 1.7249e-01, PNorm = 38.6356, GNorm = 0.7017, lr_0 = 1.4807e-04
Loss = 1.7170e-01, PNorm = 38.6485, GNorm = 0.7298, lr_0 = 1.4807e-04
Loss = 1.7224e-01, PNorm = 38.6397, GNorm = 0.6974, lr_0 = 1.4807e-04
Loss = 1.7227e-01, PNorm = 38.6463, GNorm = 0.7346, lr_0 = 1.4807e-04
Loss = 1.7184e-01, PNorm = 38.6460, GNorm = 0.6965, lr_0 = 1.4807e-04
Loss = 1.7187e-01, PNorm = 38.6468, GNorm = 0.7188, lr_0 = 1.4807e-04
Loss = 1.7236e-01, PNorm = 38.6462, GNorm = 0.7038, lr_0 = 1.4807e-04
Loss = 1.4876e-01, PNorm = 38.6420, GNorm = 0.5655, lr_0 = 1.3570e-04
Loss = 1.4748e-01, PNorm = 38.6554, GNorm = 0.5875, lr_0 = 1.3570e-04
Loss = 1.4882e-01, PNorm = 38.6439, GNorm = 0.5662, lr_0 = 1.3570e-04
Loss = 1.4803e-01, PNorm = 38.6463, GNorm = 0.5320, lr_0 = 1.3570e-04
Loss = 1.4796e-01, PNorm = 38.6536, GNorm = 0.6073, lr_0 = 1.3570e-04
Loss = 1.4818e-01, PNorm = 38.6540, GNorm = 0.6002, lr_0 = 1.3570e-04
Loss = 1.4802e-01, PNorm = 38.6530, GNorm = 0.5874, lr_0 = 1.3570e-04
Loss = 1.4826e-01, PNorm = 38.6528, GNorm = 0.5769, lr_0 = 1.3570e-04
Loss = 1.2913e-01, PNorm = 38.6511, GNorm = 0.6652, lr_0 = 1.2436e-04
Loss = 1.2923e-01, PNorm = 38.6533, GNorm = 0.6681, lr_0 = 1.2436e-04
Loss = 1.2848e-01, PNorm = 38.6655, GNorm = 0.6858, lr_0 = 1.2436e-04
Loss = 1.2921e-01, PNorm = 38.6638, GNorm = 0.7406, lr_0 = 1.2436e-04
Loss = 1.2844e-01, PNorm = 38.6556, GNorm = 0.6509, lr_0 = 1.2436e-04
Validation auc = 0.849270
Validation accuracy = 0.914286
Loss = 1.2919e-01, PNorm = 38.6639, GNorm = 0.7276, lr_0 = 1.2436e-04
Epoch 9
Loss = 1.2888e-01, PNorm = 38.6628, GNorm = 0.7280, lr_0 = 1.2436e-04
Validation auc = 0.856434
Validation accuracy = 0.914286
Validation auc = 0.850096
Validation accuracy = 0.914286
Epoch 9
Epoch 9
Validation auc = 0.853128
Validation accuracy = 0.914286
Validation auc = 0.848443
Validation accuracy = 0.914286
Validation auc = 0.854230
Validation accuracy = 0.914286
Epoch 9
Validation auc = 0.856159
Validation accuracy = 0.914286
Epoch 9
Epoch 9
Epoch 9
Loss = 1.2872e-01, PNorm = 38.6623, GNorm = 0.6632, lr_0 = 1.2436e-04
Validation auc = 0.850372
Validation accuracy = 0.914286
Epoch 9
Loss = 8.8013e-02, PNorm = 38.6623, GNorm = 0.3654, lr_0 = 1.1398e-04
Loss = 8.7902e-02, PNorm = 38.6651, GNorm = 0.3721, lr_0 = 1.1398e-04
Loss = 8.6222e-02, PNorm = 38.6774, GNorm = 0.3752, lr_0 = 1.1398e-04
Loss = 8.7234e-02, PNorm = 38.6756, GNorm = 0.3849, lr_0 = 1.1398e-04
Loss = 8.7640e-02, PNorm = 38.6758, GNorm = 0.3866, lr_0 = 1.1398e-04
Loss = 8.7233e-02, PNorm = 38.6672, GNorm = 0.3615, lr_0 = 1.1398e-04
Loss = 8.7465e-02, PNorm = 38.6747, GNorm = 0.3814, lr_0 = 1.1398e-04
Loss = 8.7615e-02, PNorm = 38.6741, GNorm = 0.3752, lr_0 = 1.1398e-04
Loss = 1.6446e-01, PNorm = 38.6705, GNorm = 1.4119, lr_0 = 1.0446e-04
Loss = 1.6489e-01, PNorm = 38.6734, GNorm = 1.4935, lr_0 = 1.0446e-04
Loss = 1.6295e-01, PNorm = 38.6855, GNorm = 1.3813, lr_0 = 1.0446e-04
Loss = 1.6422e-01, PNorm = 38.6830, GNorm = 1.4308, lr_0 = 1.0446e-04
Loss = 1.6312e-01, PNorm = 38.6842, GNorm = 1.4129, lr_0 = 1.0446e-04
Loss = 1.6353e-01, PNorm = 38.6754, GNorm = 1.4353, lr_0 = 1.0446e-04
Loss = 1.6398e-01, PNorm = 38.6842, GNorm = 1.4115, lr_0 = 1.0446e-04
Loss = 1.6410e-01, PNorm = 38.6826, GNorm = 1.4195, lr_0 = 1.0446e-04
Loss = 1.4806e-01, PNorm = 38.6768, GNorm = 0.8959, lr_0 = 1.0000e-04
Loss = 1.4832e-01, PNorm = 38.6800, GNorm = 0.9539, lr_0 = 1.0000e-04
Loss = 1.4708e-01, PNorm = 38.6928, GNorm = 0.8862, lr_0 = 1.0000e-04
Loss = 1.4716e-01, PNorm = 38.6915, GNorm = 0.9623, lr_0 = 1.0000e-04
Loss = 1.4815e-01, PNorm = 38.6822, GNorm = 0.9256, lr_0 = 1.0000e-04
Loss = 1.4717e-01, PNorm = 38.6903, GNorm = 0.9515, lr_0 = 1.0000e-04
Loss = 1.4725e-01, PNorm = 38.6915, GNorm = 0.8986, lr_0 = 1.0000e-04
Loss = 1.4792e-01, PNorm = 38.6894, GNorm = 0.9410, lr_0 = 1.0000e-04
Validation auc = 0.855056
Validation accuracy = 0.914286
Model 0 best validation auc = 0.855056 on epoch 9
Validation auc = 0.856985
Validation accuracy = 0.914286
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Model 0 best validation auc = 0.856985 on epoch 9
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Validation auc = 0.858088
Validation accuracy = 0.914286
Model 0 best validation auc = 0.858088 on epoch 9
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Model 0 test auc = 0.862745
Model 0 test accuracy = 0.966825
Ensemble test auc = 0.862745
Ensemble test accuracy = 0.966825
3-fold cross validation
	Seed 42 ==> test auc = 0.814966
	Seed 42 ==> test accuracy = 0.928910
	Seed 43 ==> test auc = 0.838308
	Seed 43 ==> test accuracy = 0.952607
	Seed 44 ==> test auc = 0.862745
	Seed 44 ==> test accuracy = 0.966825
Overall test auc = 0.838673 +/- 0.019507
Overall test accuracy = 0.949447 +/- 0.015639
Elapsed time = 0:28:43
Validation auc = 0.858914
Validation accuracy = 0.914286
Model 0 test auc = 0.862045
Model 0 test accuracy = 0.966825
Ensemble test auc = 0.862045
Ensemble test accuracy = 0.966825
3-fold cross validation
	Seed 42 ==> test auc = 0.814966
	Seed 42 ==> test accuracy = 0.928910
	Seed 43 ==> test auc = 0.840796
	Seed 43 ==> test accuracy = 0.952607
	Seed 44 ==> test auc = 0.862045
	Seed 44 ==> test accuracy = 0.966825
Overall test auc = 0.839269 +/- 0.019250
Overall test accuracy = 0.949447 +/- 0.015639
Elapsed time = 0:28:43
Model 0 best validation auc = 0.858914 on epoch 9
Validation auc = 0.857812
Validation accuracy = 0.914286
Validation auc = 0.855608
Validation accuracy = 0.914286
Model 0 best validation auc = 0.857812 on epoch 9
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Model 0 best validation auc = 0.855608 on epoch 9
Validation auc = 0.860017
Validation accuracy = 0.914286
Model 0 test auc = 0.859944
Model 0 test accuracy = 0.966825
Ensemble test auc = 0.859944
Ensemble test accuracy = 0.966825
3-fold cross validation
	Seed 42 ==> test auc = 0.814966
	Seed 42 ==> test accuracy = 0.928910
	Seed 43 ==> test auc = 0.839303
	Seed 43 ==> test accuracy = 0.952607
	Seed 44 ==> test auc = 0.859944
	Seed 44 ==> test accuracy = 0.966825
Overall test auc = 0.838071 +/- 0.018383
Overall test accuracy = 0.949447 +/- 0.015639
Model 0 best validation auc = 0.860017 on epoch 9
Elapsed time = 0:28:45
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Model 0 test auc = 0.864146
Model 0 test accuracy = 0.966825
Ensemble test auc = 0.864146
Ensemble test accuracy = 0.966825
3-fold cross validation
	Seed 42 ==> test auc = 0.814966
	Seed 42 ==> test accuracy = 0.928910
	Seed 43 ==> test auc = 0.840796
	Seed 43 ==> test accuracy = 0.952607
	Seed 44 ==> test auc = 0.864146
	Seed 44 ==> test accuracy = 0.966825
Overall test auc = 0.839969 +/- 0.020086
Overall test accuracy = 0.949447 +/- 0.015639
Elapsed time = 0:28:46
Model 0 test auc = 0.864146
Model 0 test accuracy = 0.966825
Ensemble test auc = 0.864146
Ensemble test accuracy = 0.966825
3-fold cross validation
	Seed 42 ==> test auc = 0.814966
	Seed 42 ==> test accuracy = 0.928910
	Seed 43 ==> test auc = 0.839303
	Seed 43 ==> test accuracy = 0.952607
	Seed 44 ==> test auc = 0.864146
	Seed 44 ==> test accuracy = 0.966825
Overall test auc = 0.839472 +/- 0.020078
Overall test accuracy = 0.949447 +/- 0.015639
Elapsed time = 0:28:48
Validation auc = 0.857261
Validation accuracy = 0.914286
Model 0 test auc = 0.865546
Model 0 test accuracy = 0.966825
Ensemble test auc = 0.865546
Ensemble test accuracy = 0.966825
3-fold cross validation
	Seed 42 ==> test auc = 0.814966
	Seed 42 ==> test accuracy = 0.928910
	Seed 43 ==> test auc = 0.842289
	Seed 43 ==> test accuracy = 0.952607
	Seed 44 ==> test auc = 0.865546
	Seed 44 ==> test accuracy = 0.966825
Overall test auc = 0.840934 +/- 0.020672
Overall test accuracy = 0.949447 +/- 0.015639
Elapsed time = 0:28:48
Model 0 best validation auc = 0.857261 on epoch 9
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Model 0 test auc = 0.866947
Model 0 test accuracy = 0.966825
Ensemble test auc = 0.866947
Ensemble test accuracy = 0.966825
3-fold cross validation
	Seed 42 ==> test auc = 0.814966
	Seed 42 ==> test accuracy = 0.928910
	Seed 43 ==> test auc = 0.841791
	Seed 43 ==> test accuracy = 0.952607
	Seed 44 ==> test auc = 0.866947
	Seed 44 ==> test accuracy = 0.966825
Overall test auc = 0.841235 +/- 0.021225
Overall test accuracy = 0.949447 +/- 0.015639
Elapsed time = 0:28:52
Command line
python /Users/anastasiakuznecova/PycharmProjects/chemprop-master/Testing Chemprop for project.py
Args
{'activation': 'ReLU',
 'adding_h': False,
 'aggregation': 'self_attention',
 'aggregation_norm': 100,
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_feature_scaling': True,
 'bond_features_path': None,
 'bond_features_size': 0,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': 'tests/data/Halicin_train.csv',
 'data_weights_path': None,
 'dataset_type': 'classification',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 3,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': ['accuracy'],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 3,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'loss_function': 'binary_cross_entropy',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'auc',
 'metrics': ['auc', 'accuracy'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_atom_descriptor_scaling': False,
 'no_bond_features_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 3,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': 'classification_checkpoints/self-attention/exp0',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 42,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_features_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_features_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'show_individual_scores': False,
 'smiles_columns': ['Smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['Active'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Could not write the reproducibility section of the arguments to file, thus omitting this section.
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 42
Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Epoch 0
Loss = 4.2931e-01, PNorm = 38.1783, GNorm = 0.2635, lr_0 = 2.5000e-04
Loss = 1.9386e-01, PNorm = 38.1896, GNorm = 1.2399, lr_0 = 3.8636e-04
Loss = 2.7720e-01, PNorm = 38.1941, GNorm = 1.6067, lr_0 = 5.2273e-04
Validation auc = 0.513162
Validation accuracy = 0.928571
Epoch 1
Loss = 2.1455e-01, PNorm = 38.2111, GNorm = 0.4061, lr_0 = 6.7273e-04
Loss = 2.1046e-01, PNorm = 38.2228, GNorm = 0.6154, lr_0 = 8.0909e-04
Loss = 2.1205e-01, PNorm = 38.2452, GNorm = 0.4168, lr_0 = 9.4545e-04
Validation auc = 0.794188
Validation accuracy = 0.928571
Epoch 2
Loss = 3.1321e-01, PNorm = 38.2663, GNorm = 1.0325, lr_0 = 6.5793e-04
Loss = 2.1232e-01, PNorm = 38.2776, GNorm = 0.1569, lr_0 = 3.2745e-04
Loss = 1.7544e-01, PNorm = 38.2838, GNorm = 0.9836, lr_0 = 1.6298e-04
Loss = 1.5572e-01, PNorm = 38.2832, GNorm = 0.1602, lr_0 = 1.0000e-04
Loss = 1.4048e-01, PNorm = 38.2835, GNorm = 0.2161, lr_0 = 1.0000e-04
Validation auc = 0.850940
Validation accuracy = 0.928571
Model 0 best validation auc = 0.850940 on epoch 2
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Model 0 test auc = 0.936576
Model 0 test accuracy = 0.962085
Ensemble test auc = 0.936576
Ensemble test accuracy = 0.962085
Fold 1
Splitting data with seed 43
Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Epoch 0
Loss = 4.3906e-01, PNorm = 38.1786, GNorm = 0.4530, lr_0 = 2.5000e-04
Loss = 2.3332e-01, PNorm = 38.1876, GNorm = 0.1307, lr_0 = 3.8636e-04
Loss = 2.2616e-01, PNorm = 38.1988, GNorm = 0.4589, lr_0 = 5.2273e-04
Validation auc = 0.564400
Validation accuracy = 0.957143
Epoch 1
Loss = 2.0295e-01, PNorm = 38.2176, GNorm = 0.5655, lr_0 = 6.7273e-04
Loss = 1.9505e-01, PNorm = 38.2370, GNorm = 0.2445, lr_0 = 8.0909e-04
Loss = 2.0999e-01, PNorm = 38.2659, GNorm = 0.3253, lr_0 = 9.4545e-04
Validation auc = 0.742952
Validation accuracy = 0.957143
Epoch 2
Loss = 1.4529e-01, PNorm = 38.2949, GNorm = 0.6760, lr_0 = 6.5793e-04
Loss = 1.3843e-01, PNorm = 38.3172, GNorm = 0.8745, lr_0 = 3.2745e-04
Loss = 2.3630e-01, PNorm = 38.3199, GNorm = 1.5305, lr_0 = 1.6298e-04
Loss = 2.0762e-01, PNorm = 38.3231, GNorm = 0.5623, lr_0 = 1.0000e-04
Loss = 2.3156e-01, PNorm = 38.3231, GNorm = 0.7594, lr_0 = 1.0000e-04
Validation auc = 0.759536
Validation accuracy = 0.957143
Model 0 best validation auc = 0.759536 on epoch 2
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Model 0 test auc = 0.786179
Model 0 test accuracy = 0.971564
Ensemble test auc = 0.786179
Ensemble test accuracy = 0.971564
Fold 2
Splitting data with seed 44
Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Epoch 0
Loss = 4.6295e-01, PNorm = 38.1779, GNorm = 1.2361, lr_0 = 2.5000e-04
Loss = 2.6434e-01, PNorm = 38.1862, GNorm = 0.3759, lr_0 = 3.8636e-04
Loss = 2.2232e-01, PNorm = 38.2013, GNorm = 0.3794, lr_0 = 5.2273e-04
Validation auc = 0.639105
Validation accuracy = 0.947619
Epoch 1
Loss = 2.0575e-01, PNorm = 38.2183, GNorm = 0.5082, lr_0 = 6.7273e-04
Loss = 1.7838e-01, PNorm = 38.2426, GNorm = 0.1697, lr_0 = 8.0909e-04
Loss = 2.1711e-01, PNorm = 38.2661, GNorm = 0.1823, lr_0 = 9.4545e-04
Validation auc = 0.550937
Validation accuracy = 0.947619
Epoch 2
Loss = 2.4741e-01, PNorm = 38.2783, GNorm = 0.3632, lr_0 = 6.5793e-04
Loss = 1.7707e-01, PNorm = 38.3078, GNorm = 0.5573, lr_0 = 3.2745e-04
Loss = 1.4906e-01, PNorm = 38.3111, GNorm = 0.2193, lr_0 = 1.6298e-04
Loss = 2.5878e-01, PNorm = 38.3089, GNorm = 0.2380, lr_0 = 1.0000e-04
Loss = 2.0415e-01, PNorm = 38.3089, GNorm = 0.1454, lr_0 = 1.0000e-04
Validation auc = 0.532663
Validation accuracy = 0.947619
Model 0 best validation auc = 0.639105 on epoch 0
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Model 0 test auc = 0.579675
Model 0 test accuracy = 0.971564
Ensemble test auc = 0.579675
Ensemble test accuracy = 0.971564
3-fold cross validation
	Seed 42 ==> test auc = 0.936576
	Seed 42 ==> test accuracy = 0.962085
	Seed 43 ==> test auc = 0.786179
	Seed 43 ==> test accuracy = 0.971564
	Seed 44 ==> test auc = 0.579675
	Seed 44 ==> test accuracy = 0.971564
Overall test auc = 0.767477 +/- 0.146303
Overall test accuracy = 0.968404 +/- 0.004468
Elapsed time = 0:01:31
Command line
python /Users/anastasiakuznecova/PycharmProjects/chemprop-master/Testing Chemprop for project.py
Args
Command line
python /Users/anastasiakuznecova/PycharmProjects/chemprop-master/Testing Chemprop for project.py
Args
Command line
python /Users/anastasiakuznecova/PycharmProjects/chemprop-master/Testing Chemprop for project.py
Args
Command line
python /Users/anastasiakuznecova/PycharmProjects/chemprop-master/Testing Chemprop for project.py
Args
Command line
python /Users/anastasiakuznecova/PycharmProjects/chemprop-master/Testing Chemprop for project.py
Args
{'activation': 'ReLU',
 'adding_h': False,
 'aggregation': 'self_attention',
 'aggregation_norm': 100,
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_feature_scaling': True,
 'bond_features_path': None,
 'bond_features_size': 0,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': 'tests/data/Halicin_train.csv',
 'data_weights_path': None,
 'dataset_type': 'classification',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 3,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': ['accuracy'],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 3,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'loss_function': 'binary_cross_entropy',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'auc',
 'metrics': ['auc', 'accuracy'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_atom_descriptor_scaling': False,
 'no_bond_features_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 3,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': 'classification_checkpoints/self-attention/exp0',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 42,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_features_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_features_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'show_individual_scores': False,
 'smiles_columns': ['Smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['Active'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
{'activation': 'ReLU',
 'adding_h': False,
 'aggregation': 'self_attention',
 'aggregation_norm': 100,
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_feature_scaling': True,
 'bond_features_path': None,
 'bond_features_size': 0,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': 'tests/data/Halicin_train.csv',
 'data_weights_path': None,
 'dataset_type': 'classification',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 3,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': ['accuracy'],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 3,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'loss_function': 'binary_cross_entropy',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'auc',
 'metrics': ['auc', 'accuracy'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_atom_descriptor_scaling': False,
 'no_bond_features_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 3,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': 'classification_checkpoints/self-attention/exp0',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 42,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_features_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_features_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'show_individual_scores': False,
 'smiles_columns': ['Smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['Active'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
{'activation': 'ReLU',
 'adding_h': False,
 'aggregation': 'self_attention',
 'aggregation_norm': 100,
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_feature_scaling': True,
 'bond_features_path': None,
 'bond_features_size': 0,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': 'tests/data/Halicin_train.csv',
 'data_weights_path': None,
 'dataset_type': 'classification',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 3,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': ['accuracy'],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 3,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'loss_function': 'binary_cross_entropy',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'auc',
 'metrics': ['auc', 'accuracy'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_atom_descriptor_scaling': False,
 'no_bond_features_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 3,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': 'classification_checkpoints/self-attention/exp0',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 42,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_features_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_features_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'show_individual_scores': False,
 'smiles_columns': ['Smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['Active'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
{'activation': 'ReLU',
 'adding_h': False,
 'aggregation': 'self_attention',
 'aggregation_norm': 100,
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_feature_scaling': True,
 'bond_features_path': None,
 'bond_features_size': 0,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': 'tests/data/Halicin_train.csv',
 'data_weights_path': None,
 'dataset_type': 'classification',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 3,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': ['accuracy'],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 3,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'loss_function': 'binary_cross_entropy',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'auc',
 'metrics': ['auc', 'accuracy'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_atom_descriptor_scaling': False,
 'no_bond_features_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 3,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': 'classification_checkpoints/self-attention/exp0',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 42,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_features_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_features_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'show_individual_scores': False,
 'smiles_columns': ['Smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['Active'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
{'activation': 'ReLU',
 'adding_h': False,
 'aggregation': 'self_attention',
 'aggregation_norm': 100,
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_feature_scaling': True,
 'bond_features_path': None,
 'bond_features_size': 0,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': 'tests/data/Halicin_train.csv',
 'data_weights_path': None,
 'dataset_type': 'classification',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 3,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': ['accuracy'],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 3,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'loss_function': 'binary_cross_entropy',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'auc',
 'metrics': ['auc', 'accuracy'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_atom_descriptor_scaling': False,
 'no_bond_features_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 3,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': 'classification_checkpoints/self-attention/exp0',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 42,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_features_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_features_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'show_individual_scores': False,
 'smiles_columns': ['Smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['Active'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Command line
python /Users/anastasiakuznecova/PycharmProjects/chemprop-master/Testing Chemprop for project.py
Args
Command line
python /Users/anastasiakuznecova/PycharmProjects/chemprop-master/Testing Chemprop for project.py
Args
Command line
python /Users/anastasiakuznecova/PycharmProjects/chemprop-master/Testing Chemprop for project.py
Args
{'activation': 'ReLU',
 'adding_h': False,
 'aggregation': 'self_attention',
 'aggregation_norm': 100,
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_feature_scaling': True,
 'bond_features_path': None,
 'bond_features_size': 0,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': 'tests/data/Halicin_train.csv',
 'data_weights_path': None,
 'dataset_type': 'classification',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 3,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': ['accuracy'],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 3,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'loss_function': 'binary_cross_entropy',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'auc',
 'metrics': ['auc', 'accuracy'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_atom_descriptor_scaling': False,
 'no_bond_features_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 3,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': 'classification_checkpoints/self-attention/exp0',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 42,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_features_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_features_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'show_individual_scores': False,
 'smiles_columns': ['Smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['Active'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
{'activation': 'ReLU',
 'adding_h': False,
 'aggregation': 'self_attention',
 'aggregation_norm': 100,
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_feature_scaling': True,
 'bond_features_path': None,
 'bond_features_size': 0,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': 'tests/data/Halicin_train.csv',
 'data_weights_path': None,
 'dataset_type': 'classification',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 3,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': ['accuracy'],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 3,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'loss_function': 'binary_cross_entropy',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'auc',
 'metrics': ['auc', 'accuracy'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_atom_descriptor_scaling': False,
 'no_bond_features_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 3,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': 'classification_checkpoints/self-attention/exp0',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 42,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_features_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_features_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'show_individual_scores': False,
 'smiles_columns': ['Smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['Active'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
{'activation': 'ReLU',
 'adding_h': False,
 'aggregation': 'self_attention',
 'aggregation_norm': 100,
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_feature_scaling': True,
 'bond_features_path': None,
 'bond_features_size': 0,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': 'tests/data/Halicin_train.csv',
 'data_weights_path': None,
 'dataset_type': 'classification',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 3,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': ['accuracy'],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 3,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'loss_function': 'binary_cross_entropy',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'auc',
 'metrics': ['auc', 'accuracy'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_atom_descriptor_scaling': False,
 'no_bond_features_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 3,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': 'classification_checkpoints/self-attention/exp0',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 42,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_features_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_features_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'show_individual_scores': False,
 'smiles_columns': ['Smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['Active'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Could not write the reproducibility section of the arguments to file, thus omitting this section.
Could not write the reproducibility section of the arguments to file, thus omitting this section.
Could not write the reproducibility section of the arguments to file, thus omitting this section.
Could not write the reproducibility section of the arguments to file, thus omitting this section.
Could not write the reproducibility section of the arguments to file, thus omitting this section.
Setting molecule featurization parameters to default.
Loading data
Setting molecule featurization parameters to default.
Setting molecule featurization parameters to default.
Loading data
Loading data
Setting molecule featurization parameters to default.
Loading data
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Number of tasks = 1
Fold 0
Number of tasks = 1
Fold 0
Splitting data with seed 42
Splitting data with seed 42
Splitting data with seed 42
Class sizes
Active 0: 94.86%, 1: 5.14%
Class sizes
Active 0: 94.86%, 1: 5.14%
Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
Building model 0
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Number of tasks = 1
Fold 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Splitting data with seed 42
Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
Number of tasks = 1
Fold 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Splitting data with seed 42
Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Epoch 0
Epoch 0
Epoch 0
Epoch 0
Epoch 0
Could not write the reproducibility section of the arguments to file, thus omitting this section.
Setting molecule featurization parameters to default.
Loading data
Could not write the reproducibility section of the arguments to file, thus omitting this section.
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 42
Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Epoch 0
Could not write the reproducibility section of the arguments to file, thus omitting this section.
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 42
Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Epoch 0
Number of tasks = 1
Fold 0
Splitting data with seed 42
Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Epoch 0
Loss = 4.2931e-01, PNorm = 38.1783, GNorm = 0.2635, lr_0 = 2.5000e-04
Loss = 4.2931e-01, PNorm = 38.1783, GNorm = 0.2635, lr_0 = 2.5000e-04
Loss = 4.2931e-01, PNorm = 38.1783, GNorm = 0.2635, lr_0 = 2.5000e-04
Loss = 4.2931e-01, PNorm = 38.1783, GNorm = 0.2635, lr_0 = 2.5000e-04
Loss = 4.2931e-01, PNorm = 38.1783, GNorm = 0.2635, lr_0 = 2.5000e-04
Loss = 4.2931e-01, PNorm = 38.1783, GNorm = 0.2635, lr_0 = 2.5000e-04
Loss = 4.2931e-01, PNorm = 38.1783, GNorm = 0.2635, lr_0 = 2.5000e-04
Loss = 4.2931e-01, PNorm = 38.1783, GNorm = 0.2635, lr_0 = 2.5000e-04
Loss = 1.9386e-01, PNorm = 38.1896, GNorm = 1.2399, lr_0 = 3.8636e-04
Loss = 1.9386e-01, PNorm = 38.1896, GNorm = 1.2399, lr_0 = 3.8636e-04
Loss = 1.9386e-01, PNorm = 38.1896, GNorm = 1.2399, lr_0 = 3.8636e-04
Loss = 1.9386e-01, PNorm = 38.1896, GNorm = 1.2399, lr_0 = 3.8636e-04
Loss = 1.9386e-01, PNorm = 38.1896, GNorm = 1.2399, lr_0 = 3.8636e-04
Loss = 1.9386e-01, PNorm = 38.1896, GNorm = 1.2399, lr_0 = 3.8636e-04
Loss = 1.9386e-01, PNorm = 38.1896, GNorm = 1.2399, lr_0 = 3.8636e-04
Loss = 1.9386e-01, PNorm = 38.1896, GNorm = 1.2399, lr_0 = 3.8636e-04
Loss = 2.7720e-01, PNorm = 38.1941, GNorm = 1.6067, lr_0 = 5.2273e-04
Loss = 2.7720e-01, PNorm = 38.1941, GNorm = 1.6067, lr_0 = 5.2273e-04
Loss = 2.7720e-01, PNorm = 38.1941, GNorm = 1.6067, lr_0 = 5.2273e-04
Loss = 2.7720e-01, PNorm = 38.1941, GNorm = 1.6067, lr_0 = 5.2273e-04
Loss = 2.7720e-01, PNorm = 38.1941, GNorm = 1.6067, lr_0 = 5.2273e-04
Loss = 2.7720e-01, PNorm = 38.1941, GNorm = 1.6067, lr_0 = 5.2273e-04
Loss = 2.7720e-01, PNorm = 38.1941, GNorm = 1.6067, lr_0 = 5.2273e-04
Validation auc = 0.513162
Validation accuracy = 0.928571
Loss = 2.7720e-01, PNorm = 38.1941, GNorm = 1.6067, lr_0 = 5.2273e-04
Epoch 1
Validation auc = 0.513162
Validation accuracy = 0.928571
Validation auc = 0.513162
Validation accuracy = 0.928571
Epoch 1
Epoch 1
Validation auc = 0.513162
Validation accuracy = 0.928571
Epoch 1
Validation auc = 0.513162
Validation accuracy = 0.928571
Epoch 1
Validation auc = 0.513162
Validation accuracy = 0.928571
Epoch 1
Loss = 2.1455e-01, PNorm = 38.2111, GNorm = 0.4061, lr_0 = 6.7273e-04
Loss = 2.1455e-01, PNorm = 38.2111, GNorm = 0.4061, lr_0 = 6.7273e-04
Loss = 2.1455e-01, PNorm = 38.2111, GNorm = 0.4061, lr_0 = 6.7273e-04
Validation auc = 0.513162
Validation accuracy = 0.928571
Loss = 2.1455e-01, PNorm = 38.2111, GNorm = 0.4061, lr_0 = 6.7273e-04
Epoch 1
Validation auc = 0.513162
Validation accuracy = 0.928571
Epoch 1
Loss = 2.1455e-01, PNorm = 38.2111, GNorm = 0.4061, lr_0 = 6.7273e-04
Loss = 2.1455e-01, PNorm = 38.2111, GNorm = 0.4061, lr_0 = 6.7273e-04
Loss = 2.1455e-01, PNorm = 38.2111, GNorm = 0.4061, lr_0 = 6.7273e-04
Loss = 2.1455e-01, PNorm = 38.2111, GNorm = 0.4061, lr_0 = 6.7273e-04
Loss = 2.1046e-01, PNorm = 38.2228, GNorm = 0.6154, lr_0 = 8.0909e-04
Loss = 2.1046e-01, PNorm = 38.2228, GNorm = 0.6155, lr_0 = 8.0909e-04
Loss = 2.1046e-01, PNorm = 38.2228, GNorm = 0.6154, lr_0 = 8.0909e-04
Loss = 2.1046e-01, PNorm = 38.2228, GNorm = 0.6154, lr_0 = 8.0909e-04
Loss = 2.1046e-01, PNorm = 38.2228, GNorm = 0.6156, lr_0 = 8.0909e-04
Loss = 2.1046e-01, PNorm = 38.2228, GNorm = 0.6154, lr_0 = 8.0909e-04
Loss = 2.1046e-01, PNorm = 38.2228, GNorm = 0.6154, lr_0 = 8.0909e-04
Loss = 2.1046e-01, PNorm = 38.2228, GNorm = 0.6154, lr_0 = 8.0909e-04
Loss = 2.1205e-01, PNorm = 38.2451, GNorm = 0.4171, lr_0 = 9.4545e-04
Loss = 2.1205e-01, PNorm = 38.2452, GNorm = 0.4169, lr_0 = 9.4545e-04
Loss = 2.1204e-01, PNorm = 38.2453, GNorm = 0.4117, lr_0 = 9.4545e-04
Loss = 2.1205e-01, PNorm = 38.2452, GNorm = 0.4170, lr_0 = 9.4545e-04
Loss = 2.1205e-01, PNorm = 38.2451, GNorm = 0.4140, lr_0 = 9.4545e-04
Loss = 2.1205e-01, PNorm = 38.2451, GNorm = 0.4171, lr_0 = 9.4545e-04
Validation auc = 0.793846
Validation accuracy = 0.928571
Epoch 2
Loss = 2.1205e-01, PNorm = 38.2451, GNorm = 0.4168, lr_0 = 9.4545e-04
Validation auc = 0.792821
Validation accuracy = 0.928571
Validation auc = 0.794188
Epoch 2
Validation accuracy = 0.928571
Validation auc = 0.793504
Validation accuracy = 0.928571
Epoch 2
Epoch 2
Loss = 2.1205e-01, PNorm = 38.2452, GNorm = 0.4168, lr_0 = 9.4545e-04
Validation auc = 0.793504
Validation accuracy = 0.928571
Epoch 2
Loss = 3.1311e-01, PNorm = 38.2661, GNorm = 1.0309, lr_0 = 6.5793e-04
Validation auc = 0.793846
Validation accuracy = 0.928571
Epoch 2
Loss = 3.1310e-01, PNorm = 38.2662, GNorm = 1.0308, lr_0 = 6.5793e-04
Loss = 3.1310e-01, PNorm = 38.2663, GNorm = 1.0314, lr_0 = 6.5793e-04
Loss = 3.1194e-01, PNorm = 38.2665, GNorm = 1.0227, lr_0 = 6.5793e-04
Loss = 3.1210e-01, PNorm = 38.2658, GNorm = 1.0187, lr_0 = 6.5793e-04
Loss = 3.1311e-01, PNorm = 38.2661, GNorm = 1.0309, lr_0 = 6.5793e-04
Validation auc = 0.793846
Validation accuracy = 0.928571
Epoch 2
Validation auc = 0.794188
Validation accuracy = 0.928571
Epoch 2
Loss = 3.1311e-01, PNorm = 38.2661, GNorm = 1.0307, lr_0 = 6.5793e-04
Loss = 3.1320e-01, PNorm = 38.2663, GNorm = 1.0322, lr_0 = 6.5793e-04
Loss = 2.1274e-01, PNorm = 38.2775, GNorm = 0.1715, lr_0 = 3.2745e-04
Loss = 2.1235e-01, PNorm = 38.2777, GNorm = 0.1648, lr_0 = 3.2745e-04
Loss = 2.1265e-01, PNorm = 38.2777, GNorm = 0.1673, lr_0 = 3.2745e-04
Loss = 2.1283e-01, PNorm = 38.2776, GNorm = 0.1684, lr_0 = 3.2745e-04
Loss = 2.1271e-01, PNorm = 38.2782, GNorm = 0.1642, lr_0 = 3.2745e-04
Loss = 2.1273e-01, PNorm = 38.2775, GNorm = 0.1714, lr_0 = 3.2745e-04
Loss = 2.1277e-01, PNorm = 38.2774, GNorm = 0.1708, lr_0 = 3.2745e-04
Loss = 1.7526e-01, PNorm = 38.2842, GNorm = 0.9733, lr_0 = 1.6298e-04
Loss = 2.1233e-01, PNorm = 38.2775, GNorm = 0.1588, lr_0 = 3.2745e-04
Loss = 1.7527e-01, PNorm = 38.2839, GNorm = 0.9729, lr_0 = 1.6298e-04
Loss = 1.7548e-01, PNorm = 38.2843, GNorm = 0.9708, lr_0 = 1.6298e-04
Loss = 1.7497e-01, PNorm = 38.2845, GNorm = 0.9644, lr_0 = 1.6298e-04
Loss = 1.7480e-01, PNorm = 38.2852, GNorm = 0.9719, lr_0 = 1.6298e-04
Loss = 1.7526e-01, PNorm = 38.2843, GNorm = 0.9733, lr_0 = 1.6298e-04
Loss = 1.7522e-01, PNorm = 38.2842, GNorm = 0.9755, lr_0 = 1.6298e-04
Loss = 1.5552e-01, PNorm = 38.2837, GNorm = 0.1549, lr_0 = 1.0000e-04
Loss = 1.4081e-01, PNorm = 38.2840, GNorm = 0.2082, lr_0 = 1.0000e-04
Loss = 1.7535e-01, PNorm = 38.2837, GNorm = 0.9804, lr_0 = 1.6298e-04
Loss = 1.5583e-01, PNorm = 38.2835, GNorm = 0.1587, lr_0 = 1.0000e-04
Loss = 1.5583e-01, PNorm = 38.2838, GNorm = 0.1569, lr_0 = 1.0000e-04
Validation auc = 0.848205
Validation accuracy = 0.928571
Loss = 1.4045e-01, PNorm = 38.2837, GNorm = 0.2164, lr_0 = 1.0000e-04
Loss = 1.4030e-01, PNorm = 38.2841, GNorm = 0.2083, lr_0 = 1.0000e-04
Model 0 best validation auc = 0.848205 on epoch 2
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Loss = 1.5517e-01, PNorm = 38.2842, GNorm = 0.1553, lr_0 = 1.0000e-04
Loss = 1.5549e-01, PNorm = 38.2848, GNorm = 0.1564, lr_0 = 1.0000e-04
Validation auc = 0.850940
Validation accuracy = 0.928571
Model 0 best validation auc = 0.850940 on epoch 2
Loss = 1.4101e-01, PNorm = 38.2845, GNorm = 0.2128, lr_0 = 1.0000e-04
Loss = 1.4130e-01, PNorm = 38.2850, GNorm = 0.2108, lr_0 = 1.0000e-04
Validation auc = 0.848547
Validation accuracy = 0.928571
Model 0 best validation auc = 0.848547 on epoch 2
Loss = 1.5552e-01, PNorm = 38.2838, GNorm = 0.1547, lr_0 = 1.0000e-04
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Loss = 1.4081e-01, PNorm = 38.2840, GNorm = 0.2080, lr_0 = 1.0000e-04
Validation auc = 0.845812
Validation accuracy = 0.928571
Validation auc = 0.844786
Validation accuracy = 0.928571
Model 0 best validation auc = 0.845812 on epoch 2
Model 0 best validation auc = 0.844786 on epoch 2
Model 0 test auc = 0.930419
Model 0 test accuracy = 0.962085
Ensemble test auc = 0.930419
Ensemble test accuracy = 0.962085
Fold 1
Splitting data with seed 43
Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Epoch 0
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Validation auc = 0.848889
Validation accuracy = 0.928571
Model 0 best validation auc = 0.848889 on epoch 2
Model 0 test auc = 0.937192
Model 0 test accuracy = 0.962085
Ensemble test auc = 0.937192
Ensemble test accuracy = 0.962085
Fold 1
Splitting data with seed 43
Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Model 0 test auc = 0.931650
Model 0 test accuracy = 0.962085
Ensemble test auc = 0.931650
Ensemble test accuracy = 0.962085
Fold 1
Splitting data with seed 43
Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Epoch 0
Epoch 0
Loss = 1.5547e-01, PNorm = 38.2837, GNorm = 0.1555, lr_0 = 1.0000e-04
Model 0 test auc = 0.929803
Model 0 test accuracy = 0.962085
Ensemble test auc = 0.929803
Ensemble test accuracy = 0.962085
Fold 1
Splitting data with seed 43
Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Model 0 test auc = 0.929803
Number of parameters = 445,501
Model 0 test accuracy = 0.962085
Ensemble test auc = 0.929803
Ensemble test accuracy = 0.962085
Fold 1
Splitting data with seed 43
Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Epoch 0
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Loss = 1.4084e-01, PNorm = 38.2839, GNorm = 0.2079, lr_0 = 1.0000e-04
Epoch 0
Loss = 1.5571e-01, PNorm = 38.2831, GNorm = 0.1597, lr_0 = 1.0000e-04
Model 0 test auc = 0.930419
Model 0 test accuracy = 0.962085
Ensemble test auc = 0.930419
Ensemble test accuracy = 0.962085
Fold 1
Splitting data with seed 43
Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Epoch 0
Loss = 1.4060e-01, PNorm = 38.2833, GNorm = 0.2153, lr_0 = 1.0000e-04
Validation auc = 0.846838
Validation accuracy = 0.928571
Model 0 best validation auc = 0.846838 on epoch 2
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Validation auc = 0.850598
Validation accuracy = 0.928571
Model 0 best validation auc = 0.850598 on epoch 2
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Model 0 test auc = 0.929187
Model 0 test accuracy = 0.962085
Ensemble test auc = 0.929187
Ensemble test accuracy = 0.962085
Fold 1
Splitting data with seed 43
Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Epoch 0
Loss = 4.3906e-01, PNorm = 38.1786, GNorm = 0.4530, lr_0 = 2.5000e-04
Model 0 test auc = 0.935961
Model 0 test accuracy = 0.962085
Ensemble test auc = 0.935961
Ensemble test accuracy = 0.962085
Fold 1
Splitting data with seed 43
Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Epoch 0
Loss = 4.3906e-01, PNorm = 38.1786, GNorm = 0.4530, lr_0 = 2.5000e-04
Loss = 4.3906e-01, PNorm = 38.1786, GNorm = 0.4530, lr_0 = 2.5000e-04
Loss = 4.3906e-01, PNorm = 38.1786, GNorm = 0.4530, lr_0 = 2.5000e-04
Loss = 4.3906e-01, PNorm = 38.1786, GNorm = 0.4530, lr_0 = 2.5000e-04
Loss = 4.3906e-01, PNorm = 38.1786, GNorm = 0.4530, lr_0 = 2.5000e-04
Loss = 4.3906e-01, PNorm = 38.1786, GNorm = 0.4530, lr_0 = 2.5000e-04
Loss = 2.3332e-01, PNorm = 38.1876, GNorm = 0.1307, lr_0 = 3.8636e-04
Loss = 4.3906e-01, PNorm = 38.1786, GNorm = 0.4530, lr_0 = 2.5000e-04
Loss = 2.3332e-01, PNorm = 38.1876, GNorm = 0.1307, lr_0 = 3.8636e-04
Loss = 2.3332e-01, PNorm = 38.1876, GNorm = 0.1307, lr_0 = 3.8636e-04
Loss = 2.3332e-01, PNorm = 38.1876, GNorm = 0.1307, lr_0 = 3.8636e-04
Loss = 2.3332e-01, PNorm = 38.1876, GNorm = 0.1307, lr_0 = 3.8636e-04
Loss = 2.3332e-01, PNorm = 38.1876, GNorm = 0.1307, lr_0 = 3.8636e-04
Loss = 2.3332e-01, PNorm = 38.1876, GNorm = 0.1307, lr_0 = 3.8636e-04
Loss = 2.2616e-01, PNorm = 38.1988, GNorm = 0.4589, lr_0 = 5.2273e-04
Loss = 2.3332e-01, PNorm = 38.1876, GNorm = 0.1307, lr_0 = 3.8636e-04
Loss = 2.2616e-01, PNorm = 38.1988, GNorm = 0.4589, lr_0 = 5.2273e-04
Loss = 2.2616e-01, PNorm = 38.1988, GNorm = 0.4589, lr_0 = 5.2273e-04
Loss = 2.2616e-01, PNorm = 38.1988, GNorm = 0.4589, lr_0 = 5.2273e-04
Loss = 2.2616e-01, PNorm = 38.1988, GNorm = 0.4589, lr_0 = 5.2273e-04
Loss = 2.2616e-01, PNorm = 38.1988, GNorm = 0.4589, lr_0 = 5.2273e-04
Validation auc = 0.564400
Validation accuracy = 0.957143
Epoch 1
Validation auc = 0.564400
Validation accuracy = 0.957143
Epoch 1
Validation auc = 0.564400
Validation accuracy = 0.957143
Epoch 1
Validation auc = 0.564400
Validation accuracy = 0.957143
Validation auc = 0.564400
Validation accuracy = 0.957143
Epoch 1
Epoch 1
Loss = 2.2616e-01, PNorm = 38.1988, GNorm = 0.4589, lr_0 = 5.2273e-04
Validation auc = 0.564400
Validation accuracy = 0.957143
Epoch 1
Loss = 2.2616e-01, PNorm = 38.1988, GNorm = 0.4589, lr_0 = 5.2273e-04
Loss = 2.0295e-01, PNorm = 38.2176, GNorm = 0.5655, lr_0 = 6.7273e-04
Loss = 2.0295e-01, PNorm = 38.2176, GNorm = 0.5655, lr_0 = 6.7273e-04
Loss = 2.0295e-01, PNorm = 38.2176, GNorm = 0.5655, lr_0 = 6.7273e-04
Validation auc = 0.564400
Validation accuracy = 0.957143
Epoch 1
Validation auc = 0.564400
Validation accuracy = 0.957143
Loss = 2.0299e-01, PNorm = 38.2176, GNorm = 0.5668, lr_0 = 6.7273e-04
Epoch 1
Loss = 2.0299e-01, PNorm = 38.2176, GNorm = 0.5668, lr_0 = 6.7273e-04
Loss = 2.0299e-01, PNorm = 38.2176, GNorm = 0.5668, lr_0 = 6.7273e-04
Loss = 2.0295e-01, PNorm = 38.2176, GNorm = 0.5655, lr_0 = 6.7273e-04
Loss = 1.9505e-01, PNorm = 38.2370, GNorm = 0.2445, lr_0 = 8.0909e-04
Loss = 2.0295e-01, PNorm = 38.2176, GNorm = 0.5655, lr_0 = 6.7273e-04
Loss = 1.9505e-01, PNorm = 38.2370, GNorm = 0.2446, lr_0 = 8.0909e-04
Loss = 1.9505e-01, PNorm = 38.2370, GNorm = 0.2446, lr_0 = 8.0909e-04
Loss = 1.9508e-01, PNorm = 38.2368, GNorm = 0.2472, lr_0 = 8.0909e-04
Loss = 1.9508e-01, PNorm = 38.2368, GNorm = 0.2474, lr_0 = 8.0909e-04
Loss = 1.9508e-01, PNorm = 38.2368, GNorm = 0.2474, lr_0 = 8.0909e-04
Loss = 1.9505e-01, PNorm = 38.2370, GNorm = 0.2446, lr_0 = 8.0909e-04
Loss = 2.0999e-01, PNorm = 38.2659, GNorm = 0.3265, lr_0 = 9.4545e-04
Loss = 1.9505e-01, PNorm = 38.2370, GNorm = 0.2446, lr_0 = 8.0909e-04
Loss = 2.0999e-01, PNorm = 38.2659, GNorm = 0.3269, lr_0 = 9.4545e-04
Loss = 2.0999e-01, PNorm = 38.2659, GNorm = 0.3244, lr_0 = 9.4545e-04
Loss = 2.0997e-01, PNorm = 38.2663, GNorm = 0.3234, lr_0 = 9.4545e-04
Loss = 2.0998e-01, PNorm = 38.2663, GNorm = 0.3245, lr_0 = 9.4545e-04
Loss = 2.0998e-01, PNorm = 38.2663, GNorm = 0.3245, lr_0 = 9.4545e-04
Loss = 2.0999e-01, PNorm = 38.2659, GNorm = 0.3250, lr_0 = 9.4545e-04
Validation auc = 0.742952
Validation accuracy = 0.957143
Epoch 2
Validation auc = 0.742952
Validation accuracy = 0.957143
Epoch 2
Loss = 2.0999e-01, PNorm = 38.2659, GNorm = 0.3250, lr_0 = 9.4545e-04
Validation auc = 0.742952
Validation accuracy = 0.957143
Epoch 2
Validation auc = 0.742399
Validation accuracy = 0.957143
Epoch 2
Validation auc = 0.742399
Validation accuracy = 0.957143
Validation auc = 0.742399
Validation accuracy = 0.957143
Loss = 1.4531e-01, PNorm = 38.2949, GNorm = 0.6853, lr_0 = 6.5793e-04
Epoch 2
Epoch 2
Loss = 1.4552e-01, PNorm = 38.2950, GNorm = 0.6799, lr_0 = 6.5793e-04
Loss = 1.4547e-01, PNorm = 38.2950, GNorm = 0.6851, lr_0 = 6.5793e-04
Loss = 1.4544e-01, PNorm = 38.2944, GNorm = 0.7211, lr_0 = 6.5793e-04
Loss = 1.4579e-01, PNorm = 38.2948, GNorm = 0.7068, lr_0 = 6.5793e-04
Loss = 1.4579e-01, PNorm = 38.2948, GNorm = 0.7068, lr_0 = 6.5793e-04
Validation auc = 0.742952
Validation accuracy = 0.957143
Epoch 2
Validation auc = 0.743505
Validation accuracy = 0.957143
Epoch 2
Loss = 1.4547e-01, PNorm = 38.2950, GNorm = 0.6818, lr_0 = 6.5793e-04
Loss = 1.3834e-01, PNorm = 38.3173, GNorm = 0.8506, lr_0 = 3.2745e-04
Loss = 1.4549e-01, PNorm = 38.2950, GNorm = 0.6828, lr_0 = 6.5793e-04
Loss = 1.3827e-01, PNorm = 38.3171, GNorm = 0.8627, lr_0 = 3.2745e-04
Loss = 1.3825e-01, PNorm = 38.3172, GNorm = 0.8849, lr_0 = 3.2745e-04
Loss = 1.3766e-01, PNorm = 38.3162, GNorm = 0.8439, lr_0 = 3.2745e-04
Loss = 1.3787e-01, PNorm = 38.3167, GNorm = 0.7834, lr_0 = 3.2745e-04
Loss = 1.3787e-01, PNorm = 38.3167, GNorm = 0.7831, lr_0 = 3.2745e-04
Loss = 1.3816e-01, PNorm = 38.3172, GNorm = 0.8788, lr_0 = 3.2745e-04
Loss = 1.3816e-01, PNorm = 38.3173, GNorm = 0.8771, lr_0 = 3.2745e-04
Loss = 2.3591e-01, PNorm = 38.3203, GNorm = 1.5321, lr_0 = 1.6298e-04
Loss = 2.3579e-01, PNorm = 38.3195, GNorm = 1.5329, lr_0 = 1.6298e-04
Loss = 2.3579e-01, PNorm = 38.3197, GNorm = 1.5489, lr_0 = 1.6298e-04
Loss = 2.3615e-01, PNorm = 38.3182, GNorm = 1.5324, lr_0 = 1.6298e-04
Loss = 2.3631e-01, PNorm = 38.3192, GNorm = 1.5714, lr_0 = 1.6298e-04
Loss = 2.3632e-01, PNorm = 38.3192, GNorm = 1.5715, lr_0 = 1.6298e-04
Loss = 2.3553e-01, PNorm = 38.3197, GNorm = 1.5263, lr_0 = 1.6298e-04
Loss = 2.3563e-01, PNorm = 38.3196, GNorm = 1.5216, lr_0 = 1.6298e-04
Loss = 2.0776e-01, PNorm = 38.3236, GNorm = 0.5553, lr_0 = 1.0000e-04
Loss = 2.3116e-01, PNorm = 38.3236, GNorm = 0.7510, lr_0 = 1.0000e-04
Loss = 2.0775e-01, PNorm = 38.3227, GNorm = 0.5559, lr_0 = 1.0000e-04
Loss = 2.0759e-01, PNorm = 38.3230, GNorm = 0.5490, lr_0 = 1.0000e-04
Loss = 2.3184e-01, PNorm = 38.3227, GNorm = 0.7557, lr_0 = 1.0000e-04
Loss = 2.3227e-01, PNorm = 38.3230, GNorm = 0.7569, lr_0 = 1.0000e-04
Validation auc = 0.760088
Validation accuracy = 0.957143
Loss = 2.0702e-01, PNorm = 38.3213, GNorm = 0.5468, lr_0 = 1.0000e-04
Model 0 best validation auc = 0.760088 on epoch 2
Validation auc = 0.760088
Validation accuracy = 0.957143
Loss = 2.0707e-01, PNorm = 38.3227, GNorm = 0.5472, lr_0 = 1.0000e-04
Loss = 2.3027e-01, PNorm = 38.3213, GNorm = 0.7594, lr_0 = 1.0000e-04
Model 0 best validation auc = 0.760088 on epoch 2
Loss = 2.0707e-01, PNorm = 38.3227, GNorm = 0.5466, lr_0 = 1.0000e-04
Validation auc = 0.760088
Validation accuracy = 0.957143
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Loss = 2.3058e-01, PNorm = 38.3228, GNorm = 0.7599, lr_0 = 1.0000e-04
Model 0 best validation auc = 0.760088 on epoch 2
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Loss = 2.3059e-01, PNorm = 38.3228, GNorm = 0.7594, lr_0 = 1.0000e-04
Validation auc = 0.761194
Validation accuracy = 0.957143
Model 0 best validation auc = 0.761194 on epoch 2
Validation auc = 0.762300
Validation accuracy = 0.957143
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Model 0 best validation auc = 0.762300 on epoch 2
Model 0 test auc = 0.786179
Model 0 test accuracy = 0.971564
Ensemble test auc = 0.786179
Ensemble test accuracy = 0.971564
Fold 2
Splitting data with seed 44
Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Validation auc = 0.762852
Validation accuracy = 0.957143
Model 0 test auc = 0.785366
Model 0 test accuracy = 0.971564
Ensemble test auc = 0.785366
Ensemble test accuracy = 0.971564
Fold 2
Splitting data with seed 44
Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Epoch 0
Model 0 test auc = 0.786179
Model 0 test accuracy = 0.971564
Building model 0
Ensemble test auc = 0.786179
Ensemble test accuracy = 0.971564
Fold 2
Splitting data with seed 44
Class sizes
Active 0: 94.86%, 1: 5.14%
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Model 0 best validation auc = 0.762852 on epoch 2
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Epoch 0
Epoch 0
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Loss = 2.0794e-01, PNorm = 38.3229, GNorm = 0.5562, lr_0 = 1.0000e-04
Model 0 test auc = 0.786992
Model 0 test accuracy = 0.971564
Ensemble test auc = 0.786992
Ensemble test accuracy = 0.971564
Fold 2
Splitting data with seed 44
Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Epoch 0
Model 0 test auc = 0.787805
Model 0 test accuracy = 0.971564
Ensemble test auc = 0.787805
Ensemble test accuracy = 0.971564
Loss = 2.3175e-01, PNorm = 38.3229, GNorm = 0.7674, lr_0 = 1.0000e-04
Fold 2
Splitting data with seed 44
Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Epoch 0
Model 0 test auc = 0.787805
Model 0 test accuracy = 0.971564
Ensemble test auc = 0.787805
Ensemble test accuracy = 0.971564
Fold 2
Splitting data with seed 44
Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Epoch 0
Loss = 2.0791e-01, PNorm = 38.3227, GNorm = 0.5588, lr_0 = 1.0000e-04
Validation auc = 0.761194
Validation accuracy = 0.957143
Loss = 2.3206e-01, PNorm = 38.3227, GNorm = 0.7694, lr_0 = 1.0000e-04
Model 0 best validation auc = 0.761194 on epoch 2
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Validation auc = 0.761747
Validation accuracy = 0.957143
Model 0 best validation auc = 0.761747 on epoch 2
Model 0 test auc = 0.785366
Model 0 test accuracy = 0.971564
Ensemble test auc = 0.785366
Ensemble test accuracy = 0.971564
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Fold 2
Splitting data with seed 44
Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Epoch 0
Model 0 test auc = 0.786179
Model 0 test accuracy = 0.971564
Ensemble test auc = 0.786179
Ensemble test accuracy = 0.971564
Fold 2
Splitting data with seed 44
Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Epoch 0
Loss = 4.6295e-01, PNorm = 38.1779, GNorm = 1.2361, lr_0 = 2.5000e-04
Loss = 4.6295e-01, PNorm = 38.1779, GNorm = 1.2361, lr_0 = 2.5000e-04
Loss = 4.6295e-01, PNorm = 38.1779, GNorm = 1.2360, lr_0 = 2.5000e-04
Loss = 4.6295e-01, PNorm = 38.1779, GNorm = 1.2360, lr_0 = 2.5000e-04
Loss = 4.6295e-01, PNorm = 38.1779, GNorm = 1.2361, lr_0 = 2.5000e-04
Loss = 4.6295e-01, PNorm = 38.1779, GNorm = 1.2360, lr_0 = 2.5000e-04
Loss = 4.6295e-01, PNorm = 38.1779, GNorm = 1.2361, lr_0 = 2.5000e-04
Loss = 4.6295e-01, PNorm = 38.1779, GNorm = 1.2360, lr_0 = 2.5000e-04
Loss = 2.6434e-01, PNorm = 38.1862, GNorm = 0.3759, lr_0 = 3.8636e-04
Loss = 2.6434e-01, PNorm = 38.1862, GNorm = 0.3759, lr_0 = 3.8636e-04
Loss = 2.6434e-01, PNorm = 38.1862, GNorm = 0.3759, lr_0 = 3.8636e-04
Loss = 2.6434e-01, PNorm = 38.1862, GNorm = 0.3759, lr_0 = 3.8636e-04
Loss = 2.6434e-01, PNorm = 38.1862, GNorm = 0.3759, lr_0 = 3.8636e-04
Loss = 2.6434e-01, PNorm = 38.1862, GNorm = 0.3759, lr_0 = 3.8636e-04
Loss = 2.6434e-01, PNorm = 38.1862, GNorm = 0.3759, lr_0 = 3.8636e-04
Loss = 2.6434e-01, PNorm = 38.1862, GNorm = 0.3759, lr_0 = 3.8636e-04
Loss = 2.2232e-01, PNorm = 38.2013, GNorm = 0.3788, lr_0 = 5.2273e-04
Loss = 2.2230e-01, PNorm = 38.2013, GNorm = 0.3780, lr_0 = 5.2273e-04
Loss = 2.2232e-01, PNorm = 38.2013, GNorm = 0.3788, lr_0 = 5.2273e-04
Loss = 2.2230e-01, PNorm = 38.2013, GNorm = 0.3780, lr_0 = 5.2273e-04
Loss = 2.2232e-01, PNorm = 38.2013, GNorm = 0.3788, lr_0 = 5.2273e-04
Loss = 2.2230e-01, PNorm = 38.2013, GNorm = 0.3780, lr_0 = 5.2273e-04
Loss = 2.2232e-01, PNorm = 38.2013, GNorm = 0.3788, lr_0 = 5.2273e-04
Validation auc = 0.638648
Validation accuracy = 0.947619
Epoch 1
Validation auc = 0.640018
Validation accuracy = 0.947619
Validation auc = 0.638648
Validation accuracy = 0.947619
Epoch 1
Validation auc = 0.640018
Validation accuracy = 0.947619
Epoch 1
Epoch 1
Validation auc = 0.638648
Validation accuracy = 0.947619
Epoch 1
Loss = 2.2230e-01, PNorm = 38.2013, GNorm = 0.3780, lr_0 = 5.2273e-04
Validation auc = 0.640018
Validation accuracy = 0.947619
Epoch 1
Validation auc = 0.638648
Validation accuracy = 0.947619
Epoch 1
Validation auc = 0.640018
Validation accuracy = 0.947619
Loss = 2.0577e-01, PNorm = 38.2184, GNorm = 0.5114, lr_0 = 6.7273e-04
Epoch 1
Loss = 2.0570e-01, PNorm = 38.2184, GNorm = 0.5107, lr_0 = 6.7273e-04
Loss = 2.0577e-01, PNorm = 38.2184, GNorm = 0.5114, lr_0 = 6.7273e-04
Loss = 2.0570e-01, PNorm = 38.2184, GNorm = 0.5107, lr_0 = 6.7273e-04
Loss = 2.0577e-01, PNorm = 38.2184, GNorm = 0.5114, lr_0 = 6.7273e-04
Loss = 2.0570e-01, PNorm = 38.2184, GNorm = 0.5107, lr_0 = 6.7273e-04
Loss = 2.0577e-01, PNorm = 38.2184, GNorm = 0.5114, lr_0 = 6.7273e-04
Loss = 2.0570e-01, PNorm = 38.2184, GNorm = 0.5107, lr_0 = 6.7273e-04
Loss = 1.7811e-01, PNorm = 38.2427, GNorm = 0.1698, lr_0 = 8.0909e-04
Loss = 1.7811e-01, PNorm = 38.2427, GNorm = 0.1698, lr_0 = 8.0909e-04
Loss = 1.7824e-01, PNorm = 38.2419, GNorm = 0.1823, lr_0 = 8.0909e-04
Loss = 1.7824e-01, PNorm = 38.2419, GNorm = 0.1823, lr_0 = 8.0909e-04
Loss = 1.7811e-01, PNorm = 38.2427, GNorm = 0.1698, lr_0 = 8.0909e-04
Loss = 1.7824e-01, PNorm = 38.2419, GNorm = 0.1823, lr_0 = 8.0909e-04
Loss = 1.7811e-01, PNorm = 38.2427, GNorm = 0.1698, lr_0 = 8.0909e-04
Loss = 1.7824e-01, PNorm = 38.2419, GNorm = 0.1823, lr_0 = 8.0909e-04
Loss = 2.1657e-01, PNorm = 38.2666, GNorm = 0.1987, lr_0 = 9.4545e-04
Loss = 2.1616e-01, PNorm = 38.2648, GNorm = 0.2262, lr_0 = 9.4545e-04
Loss = 2.1616e-01, PNorm = 38.2648, GNorm = 0.2262, lr_0 = 9.4545e-04
Loss = 2.1658e-01, PNorm = 38.2665, GNorm = 0.1979, lr_0 = 9.4545e-04
Loss = 2.1658e-01, PNorm = 38.2665, GNorm = 0.1979, lr_0 = 9.4545e-04
Loss = 2.1616e-01, PNorm = 38.2648, GNorm = 0.2262, lr_0 = 9.4545e-04
Loss = 2.1657e-01, PNorm = 38.2666, GNorm = 0.1987, lr_0 = 9.4545e-04
Validation auc = 0.553677
Validation accuracy = 0.947619
Epoch 2
Loss = 2.1616e-01, PNorm = 38.2648, GNorm = 0.2262, lr_0 = 9.4545e-04
Validation auc = 0.546368
Validation accuracy = 0.947619
Epoch 2
Validation auc = 0.546368
Validation accuracy = 0.947619
Epoch 2
Validation auc = 0.554134
Validation accuracy = 0.947619
Epoch 2
Validation auc = 0.554134
Validation accuracy = 0.947619
Epoch 2
Loss = 2.4764e-01, PNorm = 38.2789, GNorm = 0.3640, lr_0 = 6.5793e-04
Validation auc = 0.553677
Validation accuracy = 0.947619
Epoch 2
Validation auc = 0.546368
Validation accuracy = 0.947619
Epoch 2
Loss = 2.4790e-01, PNorm = 38.2766, GNorm = 0.3501, lr_0 = 6.5793e-04
Loss = 2.4763e-01, PNorm = 38.2787, GNorm = 0.3636, lr_0 = 6.5793e-04
Loss = 2.4790e-01, PNorm = 38.2766, GNorm = 0.3501, lr_0 = 6.5793e-04
Loss = 2.4763e-01, PNorm = 38.2787, GNorm = 0.3636, lr_0 = 6.5793e-04
Loss = 2.4764e-01, PNorm = 38.2789, GNorm = 0.3640, lr_0 = 6.5793e-04
Loss = 2.4790e-01, PNorm = 38.2766, GNorm = 0.3501, lr_0 = 6.5793e-04
Validation auc = 0.546368
Validation accuracy = 0.947619
Epoch 2
Loss = 2.4795e-01, PNorm = 38.2766, GNorm = 0.3501, lr_0 = 6.5793e-04
Loss = 1.7625e-01, PNorm = 38.3079, GNorm = 0.5669, lr_0 = 3.2745e-04
Loss = 1.7672e-01, PNorm = 38.3040, GNorm = 0.6319, lr_0 = 3.2745e-04
Loss = 1.7626e-01, PNorm = 38.3076, GNorm = 0.5656, lr_0 = 3.2745e-04
Loss = 1.7672e-01, PNorm = 38.3040, GNorm = 0.6319, lr_0 = 3.2745e-04
Loss = 1.7626e-01, PNorm = 38.3076, GNorm = 0.5656, lr_0 = 3.2745e-04
Loss = 1.7625e-01, PNorm = 38.3080, GNorm = 0.5670, lr_0 = 3.2745e-04
Loss = 1.7672e-01, PNorm = 38.3040, GNorm = 0.6319, lr_0 = 3.2745e-04
Loss = 1.7667e-01, PNorm = 38.3040, GNorm = 0.6279, lr_0 = 3.2745e-04
Loss = 1.4906e-01, PNorm = 38.3107, GNorm = 0.2093, lr_0 = 1.6298e-04
Loss = 1.4933e-01, PNorm = 38.3057, GNorm = 0.1629, lr_0 = 1.6298e-04
Loss = 1.4910e-01, PNorm = 38.3103, GNorm = 0.2080, lr_0 = 1.6298e-04
Loss = 1.4933e-01, PNorm = 38.3057, GNorm = 0.1629, lr_0 = 1.6298e-04
Loss = 1.4910e-01, PNorm = 38.3103, GNorm = 0.2080, lr_0 = 1.6298e-04
Loss = 1.4906e-01, PNorm = 38.3108, GNorm = 0.2092, lr_0 = 1.6298e-04
Loss = 1.4933e-01, PNorm = 38.3057, GNorm = 0.1629, lr_0 = 1.6298e-04
Loss = 1.4933e-01, PNorm = 38.3057, GNorm = 0.1642, lr_0 = 1.6298e-04
Loss = 2.5785e-01, PNorm = 38.3088, GNorm = 0.2408, lr_0 = 1.0000e-04
Loss = 2.0386e-01, PNorm = 38.3087, GNorm = 0.1523, lr_0 = 1.0000e-04
Loss = 2.5792e-01, PNorm = 38.3085, GNorm = 0.2391, lr_0 = 1.0000e-04
Validation auc = 0.531293
Validation accuracy = 0.947619
Model 0 best validation auc = 0.638648 on epoch 0
Loss = 2.5562e-01, PNorm = 38.3045, GNorm = 0.2602, lr_0 = 1.0000e-04
Loss = 2.0447e-01, PNorm = 38.3046, GNorm = 0.1586, lr_0 = 1.0000e-04
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Loss = 2.5792e-01, PNorm = 38.3085, GNorm = 0.2391, lr_0 = 1.0000e-04
Loss = 2.5562e-01, PNorm = 38.3045, GNorm = 0.2602, lr_0 = 1.0000e-04
Loss = 2.0404e-01, PNorm = 38.3085, GNorm = 0.1486, lr_0 = 1.0000e-04
Loss = 2.0447e-01, PNorm = 38.3046, GNorm = 0.1586, lr_0 = 1.0000e-04
Loss = 2.0404e-01, PNorm = 38.3085, GNorm = 0.1486, lr_0 = 1.0000e-04
Validation auc = 0.527638
Validation accuracy = 0.947619
Model 0 best validation auc = 0.640018 on epoch 0
Model 0 test auc = 0.579675
Model 0 test accuracy = 0.971564
Ensemble test auc = 0.579675
Ensemble test accuracy = 0.971564
3-fold cross validation
	Seed 42 ==> test auc = 0.930419
	Seed 42 ==> test accuracy = 0.962085
	Seed 43 ==> test auc = 0.786179
	Seed 43 ==> test accuracy = 0.971564
	Seed 44 ==> test auc = 0.579675
	Seed 44 ==> test accuracy = 0.971564
Validation auc = 0.531750
Validation accuracy = 0.947619
Overall test auc = 0.765424 +/- 0.143941
Overall test accuracy = 0.968404 +/- 0.004468
Model 0 best validation auc = 0.638648 on epoch 0
Elapsed time = 0:11:00
Loss = 2.5562e-01, PNorm = 38.3045, GNorm = 0.2602, lr_0 = 1.0000e-04
Loss = 2.5784e-01, PNorm = 38.3089, GNorm = 0.2406, lr_0 = 1.0000e-04
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Validation auc = 0.527638
Validation accuracy = 0.947619
Model 0 best validation auc = 0.640018 on epoch 0
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Validation auc = 0.531750
Validation accuracy = 0.947619
Model 0 best validation auc = 0.638648 on epoch 0
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Loss = 2.0386e-01, PNorm = 38.3089, GNorm = 0.1533, lr_0 = 1.0000e-04
Loss = 2.0447e-01, PNorm = 38.3046, GNorm = 0.1585, lr_0 = 1.0000e-04
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Model 0 test auc = 0.579675
Model 0 test accuracy = 0.971564
Ensemble test auc = 0.579675
Ensemble test accuracy = 0.971564
3-fold cross validation
	Seed 42 ==> test auc = 0.929803
	Seed 42 ==> test accuracy = 0.962085
	Seed 43 ==> test auc = 0.786992
	Seed 43 ==> test accuracy = 0.971564
	Seed 44 ==> test auc = 0.579675
	Seed 44 ==> test accuracy = 0.971564
Overall test auc = 0.765490 +/- 0.143746
Overall test accuracy = 0.968404 +/- 0.004468
Model 0 test auc = 0.579675
Model 0 test accuracy = 0.971564
Ensemble test auc = 0.579675
Ensemble test accuracy = 0.971564
3-fold cross validation
	Seed 42 ==> test auc = 0.931650
	Seed 42 ==> test accuracy = 0.962085
	Seed 43 ==> test auc = 0.786179
	Seed 43 ==> test accuracy = 0.971564
	Seed 44 ==> test auc = 0.579675
	Seed 44 ==> test accuracy = 0.971564
Overall test auc = 0.765835 +/- 0.144412
Overall test accuracy = 0.968404 +/- 0.004468
Elapsed time = 0:11:04
Elapsed time = 0:11:04
Model 0 test auc = 0.579675
Model 0 test accuracy = 0.971564
Ensemble test auc = 0.579675
Ensemble test accuracy = 0.971564
3-fold cross validation
	Seed 42 ==> test auc = 0.937192
	Seed 42 ==> test accuracy = 0.962085
	Seed 43 ==> test auc = 0.785366
	Seed 43 ==> test accuracy = 0.971564
	Seed 44 ==> test auc = 0.579675
	Seed 44 ==> test accuracy = 0.971564
Overall test auc = 0.767411 +/- 0.146507
Overall test accuracy = 0.968404 +/- 0.004468
Elapsed time = 0:11:04
Validation auc = 0.531293
Validation accuracy = 0.947619
Model 0 best validation auc = 0.638648 on epoch 0
Validation auc = 0.527638
Validation accuracy = 0.947619
Model 0 best validation auc = 0.640018 on epoch 0
Model 0 test auc = 0.579675
Model 0 test accuracy = 0.971564
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Ensemble test auc = 0.579675
Ensemble test accuracy = 0.971564
3-fold cross validation
	Seed 42 ==> test auc = 0.930419
	Seed 42 ==> test accuracy = 0.962085
	Seed 43 ==> test auc = 0.787805
	Seed 43 ==> test accuracy = 0.971564
	Seed 44 ==> test auc = 0.579675
	Seed 44 ==> test accuracy = 0.971564
Overall test auc = 0.765966 +/- 0.144021
Overall test accuracy = 0.968404 +/- 0.004468
Elapsed time = 0:11:05
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Model 0 test auc = 0.579675
Model 0 test accuracy = 0.971564
Ensemble test auc = 0.579675
Ensemble test accuracy = 0.971564
Loss = 2.5570e-01, PNorm = 38.3046, GNorm = 0.2585, lr_0 = 1.0000e-04
3-fold cross validation
	Seed 42 ==> test auc = 0.929187
	Seed 42 ==> test accuracy = 0.962085
	Seed 43 ==> test auc = 0.785366
	Seed 43 ==> test accuracy = 0.971564
	Seed 44 ==> test auc = 0.579675
	Seed 44 ==> test accuracy = 0.971564
Overall test auc = 0.764743 +/- 0.143431
Overall test accuracy = 0.968404 +/- 0.004468
Model 0 test auc = 0.579675
Model 0 test accuracy = 0.971564
Elapsed time = 0:11:07
Ensemble test auc = 0.579675
Ensemble test accuracy = 0.971564
3-fold cross validation
	Seed 42 ==> test auc = 0.929803
	Seed 42 ==> test accuracy = 0.962085
	Seed 43 ==> test auc = 0.787805
	Seed 43 ==> test accuracy = 0.971564
	Seed 44 ==> test auc = 0.579675
	Seed 44 ==> test accuracy = 0.971564
Overall test auc = 0.765761 +/- 0.143787
Overall test accuracy = 0.968404 +/- 0.004468
Elapsed time = 0:11:07
Loss = 2.0457e-01, PNorm = 38.3046, GNorm = 0.1533, lr_0 = 1.0000e-04
Validation auc = 0.527181
Validation accuracy = 0.947619
Model 0 best validation auc = 0.640018 on epoch 0
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Model 0 test auc = 0.579675
Model 0 test accuracy = 0.971564
Ensemble test auc = 0.579675
Ensemble test accuracy = 0.971564
3-fold cross validation
	Seed 42 ==> test auc = 0.935961
	Seed 42 ==> test accuracy = 0.962085
	Seed 43 ==> test auc = 0.786179
	Seed 43 ==> test accuracy = 0.971564
	Seed 44 ==> test auc = 0.579675
	Seed 44 ==> test accuracy = 0.971564
Overall test auc = 0.767271 +/- 0.146066
Overall test accuracy = 0.968404 +/- 0.004468
Elapsed time = 0:11:14
Command line
python /Users/anastasiakuznecova/PycharmProjects/chemprop-master/Testing Chemprop for project.py
Args
{'activation': 'ReLU',
 'adding_h': False,
 'aggregation': 'self_attention',
 'aggregation_norm': 100,
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_feature_scaling': True,
 'bond_features_path': None,
 'bond_features_size': 0,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': 'tests/data/Halicin_train.csv',
 'data_weights_path': None,
 'dataset_type': 'classification',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': ['accuracy'],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 3,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'loss_function': 'binary_cross_entropy',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'auc',
 'metrics': ['auc', 'accuracy'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_atom_descriptor_scaling': False,
 'no_bond_features_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 3,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': 'classification_checkpoints/self-attention/exp0/',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 42,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_features_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_features_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'show_individual_scores': False,
 'smiles_columns': ['Smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['Active'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Could not write the reproducibility section of the arguments to file, thus omitting this section.
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 42
Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Epoch 0
Loss = 4.2931e-01, PNorm = 38.1783, GNorm = 0.2635, lr_0 = 2.5000e-04
Loss = 1.9386e-01, PNorm = 38.1896, GNorm = 1.2399, lr_0 = 3.8636e-04
Loss = 2.7720e-01, PNorm = 38.1941, GNorm = 1.6067, lr_0 = 5.2273e-04
Validation auc = 0.513162
Validation accuracy = 0.928571
Epoch 1
Loss = 2.1455e-01, PNorm = 38.2111, GNorm = 0.4061, lr_0 = 6.7273e-04
Loss = 2.1046e-01, PNorm = 38.2228, GNorm = 0.6154, lr_0 = 8.0909e-04
Loss = 2.1205e-01, PNorm = 38.2452, GNorm = 0.4168, lr_0 = 9.4545e-04
Validation auc = 0.794188
Validation accuracy = 0.928571
Epoch 2
Loss = 3.1080e-01, PNorm = 38.2674, GNorm = 0.9371, lr_0 = 9.8516e-04
Loss = 2.1748e-01, PNorm = 38.2932, GNorm = 0.3901, lr_0 = 9.6091e-04
Loss = 1.6860e-01, PNorm = 38.3102, GNorm = 0.5038, lr_0 = 9.3726e-04
Loss = 1.5832e-01, PNorm = 38.3453, GNorm = 0.3109, lr_0 = 9.1420e-04
Loss = 1.4621e-01, PNorm = 38.3494, GNorm = 0.3616, lr_0 = 9.1192e-04
Validation auc = 0.830427
Validation accuracy = 0.928571
Epoch 3
Loss = 1.9173e-01, PNorm = 38.3723, GNorm = 0.4029, lr_0 = 8.8948e-04
Loss = 2.0828e-01, PNorm = 38.3996, GNorm = 0.4576, lr_0 = 8.6758e-04
Loss = 1.5641e-01, PNorm = 38.4366, GNorm = 0.3601, lr_0 = 8.4623e-04
Validation auc = 0.855726
Validation accuracy = 0.928571
Epoch 4
Loss = 2.0940e-01, PNorm = 38.4588, GNorm = 0.4550, lr_0 = 8.2540e-04
Loss = 1.8118e-01, PNorm = 38.5006, GNorm = 0.2579, lr_0 = 8.0509e-04
Loss = 1.6413e-01, PNorm = 38.5308, GNorm = 0.3052, lr_0 = 7.8527e-04
Validation auc = 0.901538
Validation accuracy = 0.928571
Epoch 5
Loss = 1.7240e-01, PNorm = 38.5584, GNorm = 0.6544, lr_0 = 7.6595e-04
Loss = 1.8095e-01, PNorm = 38.5996, GNorm = 0.5158, lr_0 = 7.4710e-04
Loss = 1.8632e-01, PNorm = 38.6456, GNorm = 0.2960, lr_0 = 7.2871e-04
Loss = 1.8748e-01, PNorm = 38.6719, GNorm = 0.4275, lr_0 = 7.1077e-04
Validation auc = 0.901538
Validation accuracy = 0.928571
Epoch 6
Loss = 1.7350e-01, PNorm = 38.7155, GNorm = 0.4679, lr_0 = 6.9156e-04
Loss = 1.5086e-01, PNorm = 38.7717, GNorm = 0.3473, lr_0 = 6.7453e-04
Loss = 1.9624e-01, PNorm = 38.8084, GNorm = 0.6757, lr_0 = 6.5793e-04
Validation auc = 0.925812
Validation accuracy = 0.928571
Epoch 7
Loss = 1.7489e-01, PNorm = 38.8601, GNorm = 0.5954, lr_0 = 6.4174e-04
Loss = 1.5201e-01, PNorm = 38.8903, GNorm = 0.2423, lr_0 = 6.2595e-04
Loss = 1.7939e-01, PNorm = 38.9307, GNorm = 0.3296, lr_0 = 6.1054e-04
Validation auc = 0.924786
Validation accuracy = 0.928571
Epoch 8
Loss = 1.4999e-01, PNorm = 38.9863, GNorm = 0.3083, lr_0 = 5.9403e-04
Loss = 1.3069e-01, PNorm = 39.0455, GNorm = 0.2824, lr_0 = 5.7941e-04
Loss = 1.5131e-01, PNorm = 39.0899, GNorm = 0.5742, lr_0 = 5.6515e-04
Loss = 1.6253e-01, PNorm = 39.1284, GNorm = 0.3361, lr_0 = 5.5124e-04
Validation auc = 0.923419
Validation accuracy = 0.928571
Epoch 9
Loss = 1.4256e-01, PNorm = 39.1754, GNorm = 0.4005, lr_0 = 5.3767e-04
Loss = 1.7827e-01, PNorm = 39.2167, GNorm = 0.4112, lr_0 = 5.2444e-04
Loss = 1.3165e-01, PNorm = 39.2741, GNorm = 0.2735, lr_0 = 5.1153e-04
Validation auc = 0.930256
Validation accuracy = 0.928571
Epoch 10
Loss = 1.0354e-01, PNorm = 39.3235, GNorm = 0.2425, lr_0 = 4.9894e-04
Loss = 1.6968e-01, PNorm = 39.3487, GNorm = 0.3370, lr_0 = 4.8666e-04
Loss = 1.5531e-01, PNorm = 39.4054, GNorm = 0.5618, lr_0 = 4.7469e-04
Validation auc = 0.922393
Validation accuracy = 0.938095
Epoch 11
Loss = 2.8243e-01, PNorm = 39.4525, GNorm = 0.6837, lr_0 = 4.6185e-04
Loss = 1.1444e-01, PNorm = 39.5142, GNorm = 0.6983, lr_0 = 4.5048e-04
Loss = 1.1990e-01, PNorm = 39.5474, GNorm = 0.5594, lr_0 = 4.3940e-04
Loss = 1.5412e-01, PNorm = 39.5687, GNorm = 0.7957, lr_0 = 4.2858e-04
Validation auc = 0.904957
Validation accuracy = 0.957143
Epoch 12
Loss = 1.2503e-01, PNorm = 39.6138, GNorm = 0.2883, lr_0 = 4.1803e-04
Loss = 1.4050e-01, PNorm = 39.6475, GNorm = 0.7079, lr_0 = 4.0775e-04
Loss = 1.1282e-01, PNorm = 39.6851, GNorm = 0.3019, lr_0 = 3.9771e-04
Validation auc = 0.898120
Validation accuracy = 0.961905
Epoch 13
Loss = 8.4421e-02, PNorm = 39.7224, GNorm = 0.3811, lr_0 = 3.8696e-04
Loss = 1.5162e-01, PNorm = 39.7460, GNorm = 0.6860, lr_0 = 3.7743e-04
Loss = 1.0436e-01, PNorm = 39.7861, GNorm = 0.2647, lr_0 = 3.6814e-04
Loss = 1.3635e-01, PNorm = 39.8174, GNorm = 0.3084, lr_0 = 3.5908e-04
Validation auc = 0.884786
Validation accuracy = 0.947619
Epoch 14
Loss = 1.2926e-01, PNorm = 39.8550, GNorm = 0.4263, lr_0 = 3.5025e-04
Loss = 1.5943e-01, PNorm = 39.8823, GNorm = 0.6515, lr_0 = 3.4163e-04
Loss = 7.0889e-02, PNorm = 39.9043, GNorm = 0.2718, lr_0 = 3.3322e-04
Validation auc = 0.891966
Validation accuracy = 0.938095
Epoch 15
Loss = 1.0914e-01, PNorm = 39.9316, GNorm = 0.9714, lr_0 = 3.2502e-04
Loss = 1.3960e-01, PNorm = 39.9642, GNorm = 0.5695, lr_0 = 3.1702e-04
Loss = 9.4812e-02, PNorm = 39.9935, GNorm = 0.8170, lr_0 = 3.0921e-04
Validation auc = 0.867009
Validation accuracy = 0.938095
Epoch 16
Loss = 1.1410e-01, PNorm = 40.0188, GNorm = 0.8465, lr_0 = 3.0085e-04
Loss = 1.2317e-01, PNorm = 40.0328, GNorm = 1.0449, lr_0 = 2.9345e-04
Loss = 8.3251e-02, PNorm = 40.0601, GNorm = 1.7795, lr_0 = 2.8623e-04
Loss = 1.3307e-01, PNorm = 40.0817, GNorm = 0.6798, lr_0 = 2.7918e-04
Validation auc = 0.893675
Validation accuracy = 0.957143
Epoch 17
Loss = 8.7855e-02, PNorm = 40.1042, GNorm = 0.2412, lr_0 = 2.7231e-04
Loss = 1.1679e-01, PNorm = 40.1252, GNorm = 0.6910, lr_0 = 2.6561e-04
Loss = 1.1512e-01, PNorm = 40.1505, GNorm = 0.9123, lr_0 = 2.5907e-04
Validation auc = 0.904615
Validation accuracy = 0.957143
Epoch 18
Loss = 1.1013e-01, PNorm = 40.1710, GNorm = 0.4307, lr_0 = 2.5207e-04
Loss = 1.0991e-01, PNorm = 40.1857, GNorm = 0.3657, lr_0 = 2.4586e-04
Loss = 1.0255e-01, PNorm = 40.2107, GNorm = 0.3328, lr_0 = 2.3981e-04
Validation auc = 0.899145
Validation accuracy = 0.923810
Epoch 19
Loss = 5.4778e-02, PNorm = 40.2266, GNorm = 0.4569, lr_0 = 2.3391e-04
Loss = 1.2296e-01, PNorm = 40.2525, GNorm = 0.5240, lr_0 = 2.2815e-04
Loss = 9.2615e-02, PNorm = 40.2727, GNorm = 0.5171, lr_0 = 2.2254e-04
Loss = 9.4731e-02, PNorm = 40.2797, GNorm = 0.4850, lr_0 = 2.1706e-04
Validation auc = 0.898120
Validation accuracy = 0.957143
Epoch 20
Loss = 7.9959e-02, PNorm = 40.2990, GNorm = 0.7312, lr_0 = 2.1172e-04
Loss = 1.0683e-01, PNorm = 40.3171, GNorm = 1.0987, lr_0 = 2.0651e-04
Loss = 9.3419e-02, PNorm = 40.3339, GNorm = 3.6474, lr_0 = 2.0142e-04
Validation auc = 0.883077
Validation accuracy = 0.961905
Epoch 21
Loss = 1.0719e-01, PNorm = 40.3453, GNorm = 1.1294, lr_0 = 1.9598e-04
Loss = 1.0266e-01, PNorm = 40.3693, GNorm = 0.6847, lr_0 = 1.9115e-04
Loss = 7.9602e-02, PNorm = 40.3839, GNorm = 0.6065, lr_0 = 1.8645e-04
Validation auc = 0.883077
Validation accuracy = 0.961905
Epoch 22
Loss = 2.4180e-02, PNorm = 40.3969, GNorm = 0.4083, lr_0 = 1.8186e-04
Loss = 6.6524e-02, PNorm = 40.4098, GNorm = 0.4760, lr_0 = 1.7739e-04
Loss = 7.4900e-02, PNorm = 40.4202, GNorm = 0.3499, lr_0 = 1.7302e-04
Loss = 1.0749e-01, PNorm = 40.4359, GNorm = 1.0869, lr_0 = 1.6876e-04
Validation auc = 0.887521
Validation accuracy = 0.947619
Epoch 23
Loss = 5.9950e-02, PNorm = 40.4544, GNorm = 0.5586, lr_0 = 1.6420e-04
Loss = 9.5432e-02, PNorm = 40.4617, GNorm = 0.4221, lr_0 = 1.6016e-04
Loss = 9.4447e-02, PNorm = 40.4765, GNorm = 0.6632, lr_0 = 1.5622e-04
Validation auc = 0.887521
Validation accuracy = 0.961905
Epoch 24
Loss = 6.1129e-02, PNorm = 40.4862, GNorm = 0.8277, lr_0 = 1.5237e-04
Loss = 8.9678e-02, PNorm = 40.4994, GNorm = 1.3866, lr_0 = 1.4862e-04
Loss = 6.7613e-02, PNorm = 40.5077, GNorm = 0.7005, lr_0 = 1.4496e-04
Loss = 8.3708e-02, PNorm = 40.5224, GNorm = 1.3686, lr_0 = 1.4139e-04
Validation auc = 0.887179
Validation accuracy = 0.957143
Epoch 25
Loss = 7.3167e-02, PNorm = 40.5383, GNorm = 0.4594, lr_0 = 1.3791e-04
Loss = 6.5978e-02, PNorm = 40.5506, GNorm = 0.8055, lr_0 = 1.3452e-04
Loss = 8.7018e-02, PNorm = 40.5581, GNorm = 0.7376, lr_0 = 1.3121e-04
Validation auc = 0.889231
Validation accuracy = 0.957143
Epoch 26
Loss = 8.4079e-02, PNorm = 40.5696, GNorm = 1.4561, lr_0 = 1.2766e-04
Loss = 6.6825e-02, PNorm = 40.5805, GNorm = 0.7576, lr_0 = 1.2452e-04
Loss = 6.5579e-02, PNorm = 40.5917, GNorm = 0.8667, lr_0 = 1.2146e-04
Validation auc = 0.894359
Validation accuracy = 0.938095
Epoch 27
Loss = 6.3889e-02, PNorm = 40.5955, GNorm = 0.6756, lr_0 = 1.1847e-04
Loss = 7.8474e-02, PNorm = 40.6052, GNorm = 1.2463, lr_0 = 1.1555e-04
Loss = 7.8789e-02, PNorm = 40.6142, GNorm = 0.8800, lr_0 = 1.1271e-04
Loss = 5.3032e-02, PNorm = 40.6221, GNorm = 1.0801, lr_0 = 1.0993e-04
Loss = 3.4890e-02, PNorm = 40.6225, GNorm = 0.5334, lr_0 = 1.0966e-04
Validation auc = 0.891624
Validation accuracy = 0.966667
Epoch 28
Loss = 6.2938e-02, PNorm = 40.6287, GNorm = 0.9425, lr_0 = 1.0696e-04
Loss = 7.6254e-02, PNorm = 40.6373, GNorm = 1.0467, lr_0 = 1.0433e-04
Loss = 5.3849e-02, PNorm = 40.6489, GNorm = 0.7999, lr_0 = 1.0176e-04
Validation auc = 0.890598
Validation accuracy = 0.957143
Epoch 29
Loss = 1.0420e-01, PNorm = 40.6544, GNorm = 1.3825, lr_0 = 1.0000e-04
Loss = 5.2007e-02, PNorm = 40.6636, GNorm = 0.6363, lr_0 = 1.0000e-04
Loss = 4.3509e-02, PNorm = 40.6722, GNorm = 1.1859, lr_0 = 1.0000e-04
Validation auc = 0.887179
Validation accuracy = 0.961905
Model 0 best validation auc = 0.930256 on epoch 9
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Model 0 test auc = 0.982759
Model 0 test accuracy = 0.962085
Ensemble test auc = 0.982759
Ensemble test accuracy = 0.962085
Fold 1
Splitting data with seed 43
Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Epoch 0
Loss = 4.3906e-01, PNorm = 38.1786, GNorm = 0.4530, lr_0 = 2.5000e-04
Loss = 2.3332e-01, PNorm = 38.1876, GNorm = 0.1307, lr_0 = 3.8636e-04
Loss = 2.2616e-01, PNorm = 38.1988, GNorm = 0.4589, lr_0 = 5.2273e-04
Validation auc = 0.564400
Validation accuracy = 0.957143
Epoch 1
Loss = 2.0295e-01, PNorm = 38.2176, GNorm = 0.5655, lr_0 = 6.7273e-04
Loss = 1.9505e-01, PNorm = 38.2370, GNorm = 0.2445, lr_0 = 8.0909e-04
Loss = 2.0999e-01, PNorm = 38.2659, GNorm = 0.3253, lr_0 = 9.4545e-04
Validation auc = 0.743505
Validation accuracy = 0.957143
Epoch 2
Loss = 1.4544e-01, PNorm = 38.2980, GNorm = 0.7193, lr_0 = 9.8516e-04
Loss = 1.4851e-01, PNorm = 38.3403, GNorm = 1.4251, lr_0 = 9.6091e-04
Loss = 2.2822e-01, PNorm = 38.3658, GNorm = 0.5279, lr_0 = 9.3726e-04
Loss = 2.1823e-01, PNorm = 38.3898, GNorm = 0.2443, lr_0 = 9.1420e-04
Loss = 2.1702e-01, PNorm = 38.3945, GNorm = 0.2657, lr_0 = 9.1192e-04
Validation auc = 0.773908
Validation accuracy = 0.957143
Epoch 3
Loss = 1.7245e-01, PNorm = 38.4245, GNorm = 0.3630, lr_0 = 8.8948e-04
Loss = 1.9040e-01, PNorm = 38.4669, GNorm = 0.5324, lr_0 = 8.6758e-04
Loss = 1.7292e-01, PNorm = 38.5097, GNorm = 0.7681, lr_0 = 8.4623e-04
Validation auc = 0.761194
Validation accuracy = 0.957143
Epoch 4
Loss = 1.6592e-01, PNorm = 38.5455, GNorm = 0.3150, lr_0 = 8.2540e-04
Loss = 1.5231e-01, PNorm = 38.6017, GNorm = 0.4472, lr_0 = 8.0509e-04
Loss = 1.9245e-01, PNorm = 38.6253, GNorm = 2.4286, lr_0 = 7.8527e-04
Validation auc = 0.825871
Validation accuracy = 0.957143
Epoch 5
Loss = 1.9931e-01, PNorm = 38.6508, GNorm = 0.2742, lr_0 = 7.6595e-04
Loss = 1.4562e-01, PNorm = 38.7065, GNorm = 0.2916, lr_0 = 7.4710e-04
Loss = 1.8918e-01, PNorm = 38.7414, GNorm = 0.3112, lr_0 = 7.2871e-04
Loss = 1.8918e-01, PNorm = 38.7927, GNorm = 0.3981, lr_0 = 7.1077e-04
Validation auc = 0.794914
Validation accuracy = 0.942857
Epoch 6
Loss = 1.5132e-01, PNorm = 38.8521, GNorm = 0.3127, lr_0 = 6.9156e-04
Loss = 1.4253e-01, PNorm = 38.8900, GNorm = 0.4347, lr_0 = 6.7453e-04
Loss = 1.7242e-01, PNorm = 38.9288, GNorm = 0.2770, lr_0 = 6.5793e-04
Validation auc = 0.781647
Validation accuracy = 0.952381
Epoch 7
Loss = 1.8128e-01, PNorm = 38.9641, GNorm = 0.6486, lr_0 = 6.4174e-04
Loss = 1.6701e-01, PNorm = 39.0052, GNorm = 0.3644, lr_0 = 6.2595e-04
Loss = 1.2610e-01, PNorm = 39.0636, GNorm = 0.5504, lr_0 = 6.1054e-04
Validation auc = 0.833057
Validation accuracy = 0.942857
Epoch 8
Loss = 1.3367e-01, PNorm = 39.1057, GNorm = 0.4594, lr_0 = 5.9403e-04
Loss = 1.3300e-01, PNorm = 39.1367, GNorm = 0.4595, lr_0 = 5.7941e-04
Loss = 1.3577e-01, PNorm = 39.1744, GNorm = 0.3566, lr_0 = 5.6515e-04
Loss = 1.7687e-01, PNorm = 39.2121, GNorm = 0.6472, lr_0 = 5.5124e-04
Validation auc = 0.860144
Validation accuracy = 0.952381
Epoch 9
Loss = 1.2331e-01, PNorm = 39.2501, GNorm = 0.6540, lr_0 = 5.3767e-04
Loss = 1.5428e-01, PNorm = 39.2871, GNorm = 0.7440, lr_0 = 5.2444e-04
Loss = 1.1725e-01, PNorm = 39.3192, GNorm = 0.6277, lr_0 = 5.1153e-04
Validation auc = 0.852405
Validation accuracy = 0.938095
Epoch 10
Loss = 1.0198e-01, PNorm = 39.3575, GNorm = 0.7525, lr_0 = 4.9894e-04
Loss = 1.8859e-01, PNorm = 39.3931, GNorm = 0.8687, lr_0 = 4.8666e-04
Loss = 1.1014e-01, PNorm = 39.4278, GNorm = 0.3077, lr_0 = 4.7469e-04
Validation auc = 0.875069
Validation accuracy = 0.942857
Epoch 11
Loss = 6.2405e-02, PNorm = 39.4594, GNorm = 0.7316, lr_0 = 4.6185e-04
Loss = 1.0846e-01, PNorm = 39.5023, GNorm = 0.3405, lr_0 = 4.5048e-04
Loss = 1.3442e-01, PNorm = 39.5261, GNorm = 0.8790, lr_0 = 4.3940e-04
Loss = 1.4094e-01, PNorm = 39.5507, GNorm = 0.4764, lr_0 = 4.2858e-04
Validation auc = 0.884467
Validation accuracy = 0.947619
Epoch 12
Loss = 1.5677e-01, PNorm = 39.5882, GNorm = 0.7943, lr_0 = 4.1803e-04
Loss = 8.5309e-02, PNorm = 39.6167, GNorm = 0.2626, lr_0 = 4.0775e-04
Loss = 1.1533e-01, PNorm = 39.6457, GNorm = 0.2364, lr_0 = 3.9771e-04
Validation auc = 0.885019
Validation accuracy = 0.938095
Epoch 13
Loss = 7.9429e-02, PNorm = 39.6803, GNorm = 0.7216, lr_0 = 3.8696e-04
Loss = 1.3825e-01, PNorm = 39.7086, GNorm = 1.0032, lr_0 = 3.7743e-04
Loss = 1.3643e-01, PNorm = 39.7392, GNorm = 0.3616, lr_0 = 3.6814e-04
Loss = 1.0524e-01, PNorm = 39.7650, GNorm = 0.1842, lr_0 = 3.5908e-04
Validation auc = 0.911001
Validation accuracy = 0.966667
Epoch 14
Loss = 1.2214e-01, PNorm = 39.7800, GNorm = 0.6663, lr_0 = 3.5025e-04
Loss = 8.6761e-02, PNorm = 39.8091, GNorm = 1.1135, lr_0 = 3.4163e-04
Loss = 1.5376e-01, PNorm = 39.8166, GNorm = 0.7001, lr_0 = 3.3322e-04
Validation auc = 0.914870
Validation accuracy = 0.952381
Epoch 15
Loss = 1.1132e-01, PNorm = 39.8404, GNorm = 0.2873, lr_0 = 3.2502e-04
Loss = 1.3034e-01, PNorm = 39.8669, GNorm = 1.2321, lr_0 = 3.1702e-04
Loss = 9.3983e-02, PNorm = 39.8924, GNorm = 1.0156, lr_0 = 3.0921e-04
Validation auc = 0.928137
Validation accuracy = 0.947619
Epoch 16
Loss = 6.4340e-02, PNorm = 39.9175, GNorm = 0.5494, lr_0 = 3.0085e-04
Loss = 1.1796e-01, PNorm = 39.9344, GNorm = 0.3743, lr_0 = 2.9345e-04
Loss = 8.0720e-02, PNorm = 39.9526, GNorm = 0.3231, lr_0 = 2.8623e-04
Loss = 1.1398e-01, PNorm = 39.9697, GNorm = 0.4688, lr_0 = 2.7918e-04
Validation auc = 0.933665
Validation accuracy = 0.947619
Epoch 17
Loss = 7.4088e-02, PNorm = 39.9898, GNorm = 1.4922, lr_0 = 2.7231e-04
Loss = 1.0012e-01, PNorm = 40.0035, GNorm = 1.4792, lr_0 = 2.6561e-04
Loss = 9.6373e-02, PNorm = 40.0213, GNorm = 0.8087, lr_0 = 2.5907e-04
Validation auc = 0.940299
Validation accuracy = 0.952381
Epoch 18
Loss = 1.0341e-01, PNorm = 40.0369, GNorm = 1.0117, lr_0 = 2.5207e-04
Loss = 8.6642e-02, PNorm = 40.0676, GNorm = 0.9219, lr_0 = 2.4586e-04
Loss = 1.1294e-01, PNorm = 40.0769, GNorm = 0.8374, lr_0 = 2.3981e-04
Validation auc = 0.955224
Validation accuracy = 0.957143
Epoch 19
Loss = 6.2394e-02, PNorm = 40.0907, GNorm = 0.2971, lr_0 = 2.3391e-04
Loss = 1.3831e-01, PNorm = 40.1042, GNorm = 0.8131, lr_0 = 2.2815e-04
Loss = 8.4979e-02, PNorm = 40.1253, GNorm = 1.1476, lr_0 = 2.2254e-04
Loss = 9.8086e-02, PNorm = 40.1407, GNorm = 0.5441, lr_0 = 2.1706e-04
Validation auc = 0.941957
Validation accuracy = 0.947619
Epoch 20
Loss = 9.5406e-02, PNorm = 40.1558, GNorm = 1.6863, lr_0 = 2.1172e-04
Loss = 8.5532e-02, PNorm = 40.1742, GNorm = 0.5721, lr_0 = 2.0651e-04
Loss = 1.1102e-01, PNorm = 40.1796, GNorm = 0.5889, lr_0 = 2.0142e-04
Validation auc = 0.943615
Validation accuracy = 0.947619
Epoch 21
Loss = 1.3040e-01, PNorm = 40.1955, GNorm = 1.3062, lr_0 = 1.9598e-04
Loss = 1.2442e-01, PNorm = 40.2053, GNorm = 0.5401, lr_0 = 1.9115e-04
Loss = 8.3810e-02, PNorm = 40.2268, GNorm = 0.4601, lr_0 = 1.8645e-04
Validation auc = 0.948038
Validation accuracy = 0.947619
Epoch 22
Loss = 7.2173e-02, PNorm = 40.2431, GNorm = 0.5306, lr_0 = 1.8186e-04
Loss = 7.4967e-02, PNorm = 40.2541, GNorm = 0.9711, lr_0 = 1.7739e-04
Loss = 8.2631e-02, PNorm = 40.2604, GNorm = 1.7600, lr_0 = 1.7302e-04
Loss = 1.2010e-01, PNorm = 40.2662, GNorm = 1.1865, lr_0 = 1.6876e-04
Validation auc = 0.957435
Validation accuracy = 0.957143
Epoch 23
Loss = 6.9870e-02, PNorm = 40.2807, GNorm = 0.2523, lr_0 = 1.6420e-04
Loss = 1.2067e-01, PNorm = 40.2935, GNorm = 0.9109, lr_0 = 1.6016e-04
Loss = 6.7051e-02, PNorm = 40.3068, GNorm = 0.8116, lr_0 = 1.5622e-04
Validation auc = 0.945826
Validation accuracy = 0.947619
Epoch 24
Loss = 1.0019e-01, PNorm = 40.3150, GNorm = 0.5797, lr_0 = 1.5237e-04
Loss = 1.1104e-01, PNorm = 40.3299, GNorm = 0.3614, lr_0 = 1.4862e-04
Loss = 5.6594e-02, PNorm = 40.3433, GNorm = 0.7482, lr_0 = 1.4496e-04
Loss = 7.6792e-02, PNorm = 40.3528, GNorm = 0.7976, lr_0 = 1.4139e-04
Validation auc = 0.953013
Validation accuracy = 0.947619
Epoch 25
Loss = 9.1294e-02, PNorm = 40.3643, GNorm = 0.7902, lr_0 = 1.3791e-04
Loss = 9.2009e-02, PNorm = 40.3743, GNorm = 0.4390, lr_0 = 1.3452e-04
Loss = 7.4288e-02, PNorm = 40.3793, GNorm = 0.7640, lr_0 = 1.3121e-04
Validation auc = 0.942510
Validation accuracy = 0.952381
Epoch 26
Loss = 6.2286e-02, PNorm = 40.3924, GNorm = 0.4957, lr_0 = 1.2766e-04
Loss = 9.8913e-02, PNorm = 40.3989, GNorm = 1.0262, lr_0 = 1.2452e-04
Loss = 7.4898e-02, PNorm = 40.4141, GNorm = 1.7510, lr_0 = 1.2146e-04
Validation auc = 0.933665
Validation accuracy = 0.952381
Epoch 27
Loss = 5.0111e-02, PNorm = 40.4205, GNorm = 0.7178, lr_0 = 1.1847e-04
Loss = 8.0297e-02, PNorm = 40.4285, GNorm = 1.2060, lr_0 = 1.1555e-04
Loss = 9.3806e-02, PNorm = 40.4366, GNorm = 2.0577, lr_0 = 1.1271e-04
Loss = 5.0590e-02, PNorm = 40.4441, GNorm = 0.8174, lr_0 = 1.0993e-04
Loss = 1.9151e-01, PNorm = 40.4451, GNorm = 1.0402, lr_0 = 1.0966e-04
Validation auc = 0.935323
Validation accuracy = 0.952381
Epoch 28
Loss = 6.4747e-02, PNorm = 40.4541, GNorm = 0.9115, lr_0 = 1.0696e-04
Loss = 6.7663e-02, PNorm = 40.4613, GNorm = 0.7814, lr_0 = 1.0433e-04
Loss = 6.6617e-02, PNorm = 40.4700, GNorm = 0.3191, lr_0 = 1.0176e-04
Validation auc = 0.944721
Validation accuracy = 0.957143
Epoch 29
Loss = 7.2876e-02, PNorm = 40.4748, GNorm = 0.4488, lr_0 = 1.0000e-04
Loss = 7.1520e-02, PNorm = 40.4838, GNorm = 1.1862, lr_0 = 1.0000e-04
Loss = 7.0655e-02, PNorm = 40.4923, GNorm = 0.3021, lr_0 = 1.0000e-04
Validation auc = 0.952460
Validation accuracy = 0.952381
Model 0 best validation auc = 0.957435 on epoch 22
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Model 0 test auc = 0.960976
Model 0 test accuracy = 0.985782
Ensemble test auc = 0.960976
Ensemble test accuracy = 0.985782
Fold 2
Splitting data with seed 44
Class sizes
Active 0: 94.86%, 1: 5.14%
Total size = 2,101 | train size = 1,680 | val size = 210 | test size = 211
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.0, inplace=False)
    (7): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 445,501
Epoch 0
Loss = 4.6295e-01, PNorm = 38.1779, GNorm = 1.2361, lr_0 = 2.5000e-04
Loss = 2.6434e-01, PNorm = 38.1862, GNorm = 0.3759, lr_0 = 3.8636e-04
Loss = 2.2232e-01, PNorm = 38.2013, GNorm = 0.3794, lr_0 = 5.2273e-04
Validation auc = 0.639105
Validation accuracy = 0.947619
Epoch 1
Loss = 2.0575e-01, PNorm = 38.2183, GNorm = 0.5082, lr_0 = 6.7273e-04
Loss = 1.7838e-01, PNorm = 38.2426, GNorm = 0.1697, lr_0 = 8.0909e-04
Loss = 2.1711e-01, PNorm = 38.2661, GNorm = 0.1823, lr_0 = 9.4545e-04
Validation auc = 0.547739
Validation accuracy = 0.947619
Epoch 2
Loss = 2.5022e-01, PNorm = 38.2819, GNorm = 0.3727, lr_0 = 9.8516e-04
Loss = 1.8910e-01, PNorm = 38.3262, GNorm = 0.5818, lr_0 = 9.6091e-04
Loss = 1.6344e-01, PNorm = 38.3563, GNorm = 0.1500, lr_0 = 9.3726e-04
Loss = 2.6442e-01, PNorm = 38.3737, GNorm = 0.5384, lr_0 = 9.1420e-04
Loss = 2.1017e-01, PNorm = 38.3766, GNorm = 0.3636, lr_0 = 9.1192e-04
Validation auc = 0.552764
Validation accuracy = 0.947619
Epoch 3
Loss = 1.7418e-01, PNorm = 38.4143, GNorm = 1.1334, lr_0 = 8.8948e-04
Loss = 1.9654e-01, PNorm = 38.4356, GNorm = 0.5322, lr_0 = 8.6758e-04
Loss = 1.9104e-01, PNorm = 38.4646, GNorm = 0.2805, lr_0 = 8.4623e-04
Validation auc = 0.515761
Validation accuracy = 0.947619
Epoch 4
Loss = 1.7253e-01, PNorm = 38.5052, GNorm = 0.3436, lr_0 = 8.2540e-04
Loss = 1.7095e-01, PNorm = 38.5404, GNorm = 0.4699, lr_0 = 8.0509e-04
Loss = 2.1724e-01, PNorm = 38.5858, GNorm = 1.0308, lr_0 = 7.8527e-04
Validation auc = 0.490635
Validation accuracy = 0.947619
Epoch 5
Loss = 2.2466e-01, PNorm = 38.6108, GNorm = 0.2164, lr_0 = 7.6595e-04
Loss = 1.8322e-01, PNorm = 38.6584, GNorm = 0.2112, lr_0 = 7.4710e-04
Loss = 1.8274e-01, PNorm = 38.6955, GNorm = 0.5721, lr_0 = 7.2871e-04
Loss = 1.5808e-01, PNorm = 38.7383, GNorm = 0.2615, lr_0 = 7.1077e-04
Validation auc = 0.568296
Validation accuracy = 0.947619
Epoch 6
Loss = 1.4497e-01, PNorm = 38.7800, GNorm = 0.3646, lr_0 = 6.9156e-04
Loss = 1.6664e-01, PNorm = 38.8185, GNorm = 0.2151, lr_0 = 6.7453e-04
Loss = 1.8345e-01, PNorm = 38.8551, GNorm = 0.6234, lr_0 = 6.5793e-04
Validation auc = 0.666514
Validation accuracy = 0.947619
Epoch 7
Loss = 1.6244e-01, PNorm = 38.8972, GNorm = 1.0180, lr_0 = 6.4174e-04
Loss = 1.5348e-01, PNorm = 38.9560, GNorm = 0.2112, lr_0 = 6.2595e-04
Loss = 1.7076e-01, PNorm = 38.9896, GNorm = 1.0750, lr_0 = 6.1054e-04
Validation auc = 0.660119
Validation accuracy = 0.947619
Epoch 8
Loss = 2.8331e-01, PNorm = 39.0283, GNorm = 0.4284, lr_0 = 5.9403e-04
Loss = 1.4898e-01, PNorm = 39.0760, GNorm = 0.5482, lr_0 = 5.7941e-04
Loss = 1.2446e-01, PNorm = 39.1266, GNorm = 0.4146, lr_0 = 5.6515e-04
Loss = 1.4230e-01, PNorm = 39.1737, GNorm = 0.6539, lr_0 = 5.5124e-04
Validation auc = 0.669712
Validation accuracy = 0.942857
Epoch 9
Loss = 9.8225e-02, PNorm = 39.2167, GNorm = 0.8301, lr_0 = 5.3767e-04
Loss = 2.0357e-01, PNorm = 39.2423, GNorm = 0.5262, lr_0 = 5.2444e-04
Loss = 1.1908e-01, PNorm = 39.2833, GNorm = 0.2755, lr_0 = 5.1153e-04
Validation auc = 0.743262
Validation accuracy = 0.947619
Epoch 10
Loss = 1.7245e-01, PNorm = 39.3322, GNorm = 0.5273, lr_0 = 4.9894e-04
Loss = 1.2151e-01, PNorm = 39.3730, GNorm = 0.5765, lr_0 = 4.8666e-04
Loss = 1.2104e-01, PNorm = 39.4095, GNorm = 1.0337, lr_0 = 4.7469e-04
Validation auc = 0.734582
Validation accuracy = 0.942857
Epoch 11
Loss = 6.7949e-02, PNorm = 39.4536, GNorm = 0.4020, lr_0 = 4.6185e-04
Loss = 1.4285e-01, PNorm = 39.4825, GNorm = 0.4387, lr_0 = 4.5048e-04
Loss = 1.2260e-01, PNorm = 39.5100, GNorm = 0.2694, lr_0 = 4.3940e-04
Loss = 1.5778e-01, PNorm = 39.5508, GNorm = 0.2717, lr_0 = 4.2858e-04
Validation auc = 0.713568
Validation accuracy = 0.947619
Epoch 12
Loss = 1.1113e-01, PNorm = 39.5845, GNorm = 0.7963, lr_0 = 4.1803e-04
Loss = 1.1358e-01, PNorm = 39.6084, GNorm = 0.2853, lr_0 = 4.0775e-04
Loss = 1.5797e-01, PNorm = 39.6405, GNorm = 0.9181, lr_0 = 3.9771e-04
Validation auc = 0.737780
Validation accuracy = 0.947619
Epoch 13
Loss = 1.1662e-01, PNorm = 39.6716, GNorm = 0.3489, lr_0 = 3.8696e-04
Loss = 7.7796e-02, PNorm = 39.7050, GNorm = 0.3264, lr_0 = 3.7743e-04
Loss = 1.6982e-01, PNorm = 39.7217, GNorm = 0.8843, lr_0 = 3.6814e-04
Loss = 1.1647e-01, PNorm = 39.7412, GNorm = 1.0769, lr_0 = 3.5908e-04
Validation auc = 0.745546
Validation accuracy = 0.942857
Epoch 14
Loss = 1.1324e-01, PNorm = 39.7681, GNorm = 0.6933, lr_0 = 3.5025e-04
Loss = 1.0859e-01, PNorm = 39.8023, GNorm = 0.4067, lr_0 = 3.4163e-04
Loss = 1.0604e-01, PNorm = 39.8262, GNorm = 0.5310, lr_0 = 3.3322e-04
Validation auc = 0.754226
Validation accuracy = 0.947619
Epoch 15
Loss = 9.6259e-02, PNorm = 39.8531, GNorm = 0.5936, lr_0 = 3.2502e-04
Loss = 7.1708e-02, PNorm = 39.8692, GNorm = 0.6608, lr_0 = 3.1702e-04
Loss = 1.1781e-01, PNorm = 39.8922, GNorm = 0.8859, lr_0 = 3.0921e-04
Validation auc = 0.751485
Validation accuracy = 0.876190
Epoch 16
Loss = 1.7483e-01, PNorm = 39.9155, GNorm = 0.6818, lr_0 = 3.0085e-04
Loss = 9.2297e-02, PNorm = 39.9444, GNorm = 0.7091, lr_0 = 2.9345e-04
Loss = 9.9383e-02, PNorm = 39.9664, GNorm = 0.5568, lr_0 = 2.8623e-04
Loss = 1.0543e-01, PNorm = 39.9952, GNorm = 0.6299, lr_0 = 2.7918e-04
Validation auc = 0.780265
Validation accuracy = 0.938095
Epoch 17
Loss = 1.2808e-01, PNorm = 40.0126, GNorm = 0.3910, lr_0 = 2.7231e-04
Loss = 1.0670e-01, PNorm = 40.0318, GNorm = 0.9083, lr_0 = 2.6561e-04
Loss = 7.7112e-02, PNorm = 40.0495, GNorm = 0.2525, lr_0 = 2.5907e-04
Validation auc = 0.798995
Validation accuracy = 0.947619
Epoch 18
Loss = 9.0727e-02, PNorm = 40.0696, GNorm = 0.3155, lr_0 = 2.5207e-04
Loss = 8.9232e-02, PNorm = 40.0909, GNorm = 0.4523, lr_0 = 2.4586e-04
Loss = 8.6998e-02, PNorm = 40.1123, GNorm = 1.0628, lr_0 = 2.3981e-04
Validation auc = 0.805847
Validation accuracy = 0.923810
Epoch 19
Loss = 3.8831e-02, PNorm = 40.1271, GNorm = 0.3793, lr_0 = 2.3391e-04
Loss = 9.2646e-02, PNorm = 40.1492, GNorm = 1.3015, lr_0 = 2.2815e-04
Loss = 9.4983e-02, PNorm = 40.1691, GNorm = 0.3507, lr_0 = 2.2254e-04
Loss = 7.5529e-02, PNorm = 40.1890, GNorm = 1.7712, lr_0 = 2.1706e-04
Validation auc = 0.817725
Validation accuracy = 0.942857
Epoch 20
Loss = 9.5645e-02, PNorm = 40.2022, GNorm = 1.1401, lr_0 = 2.1172e-04
Loss = 8.5422e-02, PNorm = 40.2197, GNorm = 1.3315, lr_0 = 2.0651e-04
Loss = 9.1681e-02, PNorm = 40.2342, GNorm = 0.2481, lr_0 = 2.0142e-04
Validation auc = 0.807675
Validation accuracy = 0.938095
Epoch 21
Loss = 9.0302e-02, PNorm = 40.2522, GNorm = 0.3277, lr_0 = 1.9598e-04
Loss = 6.9094e-02, PNorm = 40.2677, GNorm = 0.3024, lr_0 = 1.9115e-04
Loss = 8.6978e-02, PNorm = 40.2802, GNorm = 0.9452, lr_0 = 1.8645e-04
Validation auc = 0.806761
Validation accuracy = 0.947619
Epoch 22
Loss = 1.6025e-01, PNorm = 40.2972, GNorm = 0.8559, lr_0 = 1.8186e-04
Loss = 9.1929e-02, PNorm = 40.3061, GNorm = 1.0071, lr_0 = 1.7739e-04
Loss = 6.3566e-02, PNorm = 40.3180, GNorm = 1.0137, lr_0 = 1.7302e-04
Loss = 6.8390e-02, PNorm = 40.3297, GNorm = 0.7833, lr_0 = 1.6876e-04
Validation auc = 0.811329
Validation accuracy = 0.933333
Epoch 23
Loss = 7.9607e-02, PNorm = 40.3487, GNorm = 0.8179, lr_0 = 1.6420e-04
Loss = 7.1465e-02, PNorm = 40.3570, GNorm = 1.4811, lr_0 = 1.6016e-04
Loss = 6.8554e-02, PNorm = 40.3741, GNorm = 0.4228, lr_0 = 1.5622e-04
Validation auc = 0.805391
Validation accuracy = 0.947619
Epoch 24
Loss = 9.2880e-02, PNorm = 40.3850, GNorm = 1.4274, lr_0 = 1.5237e-04
Loss = 6.2834e-02, PNorm = 40.3963, GNorm = 0.7690, lr_0 = 1.4862e-04
Loss = 6.9444e-02, PNorm = 40.4070, GNorm = 0.7633, lr_0 = 1.4496e-04
Loss = 5.7287e-02, PNorm = 40.4172, GNorm = 0.5578, lr_0 = 1.4139e-04
Validation auc = 0.827775
Validation accuracy = 0.952381
Epoch 25
Loss = 7.2001e-02, PNorm = 40.4275, GNorm = 2.5679, lr_0 = 1.3791e-04
Loss = 7.1089e-02, PNorm = 40.4396, GNorm = 0.8384, lr_0 = 1.3452e-04
Loss = 5.5687e-02, PNorm = 40.4518, GNorm = 0.9671, lr_0 = 1.3121e-04
Validation auc = 0.821380
Validation accuracy = 0.947619
Epoch 26
Loss = 5.5365e-02, PNorm = 40.4603, GNorm = 0.7507, lr_0 = 1.2766e-04
Loss = 5.8891e-02, PNorm = 40.4684, GNorm = 0.4445, lr_0 = 1.2452e-04
Loss = 6.0322e-02, PNorm = 40.4784, GNorm = 0.6315, lr_0 = 1.2146e-04
Validation auc = 0.825491
Validation accuracy = 0.938095
Epoch 27
Loss = 3.7181e-02, PNorm = 40.4893, GNorm = 0.7847, lr_0 = 1.1847e-04
Loss = 8.3246e-02, PNorm = 40.4977, GNorm = 0.3184, lr_0 = 1.1555e-04
Loss = 5.0658e-02, PNorm = 40.5102, GNorm = 1.1385, lr_0 = 1.1271e-04
Loss = 5.4787e-02, PNorm = 40.5190, GNorm = 0.5147, lr_0 = 1.0993e-04
Loss = 1.7143e-01, PNorm = 40.5197, GNorm = 1.0844, lr_0 = 1.0966e-04
Validation auc = 0.834171
Validation accuracy = 0.952381
Epoch 28
Loss = 6.7136e-02, PNorm = 40.5234, GNorm = 0.5863, lr_0 = 1.0696e-04
Loss = 5.3516e-02, PNorm = 40.5345, GNorm = 1.2999, lr_0 = 1.0433e-04
Loss = 6.7025e-02, PNorm = 40.5384, GNorm = 0.5047, lr_0 = 1.0176e-04
Validation auc = 0.826405
Validation accuracy = 0.938095
Epoch 29
Loss = 3.1685e-02, PNorm = 40.5499, GNorm = 0.5561, lr_0 = 1.0000e-04
Loss = 5.1104e-02, PNorm = 40.5559, GNorm = 1.1937, lr_0 = 1.0000e-04
Loss = 5.4588e-02, PNorm = 40.5649, GNorm = 1.9576, lr_0 = 1.0000e-04
Validation auc = 0.824577
Validation accuracy = 0.952381
Model 0 best validation auc = 0.834171 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Loading pretrained parameter "ffn.7.weight".
Loading pretrained parameter "ffn.7.bias".
Model 0 test auc = 0.842276
Model 0 test accuracy = 0.976303
Ensemble test auc = 0.842276
Ensemble test accuracy = 0.976303
3-fold cross validation
	Seed 42 ==> test auc = 0.982759
	Seed 42 ==> test accuracy = 0.962085
	Seed 43 ==> test auc = 0.960976
	Seed 43 ==> test accuracy = 0.985782
	Seed 44 ==> test auc = 0.842276
	Seed 44 ==> test accuracy = 0.976303
Overall test auc = 0.928670 +/- 0.061734
Overall test accuracy = 0.974724 +/- 0.009738
Elapsed time = 0:13:43
